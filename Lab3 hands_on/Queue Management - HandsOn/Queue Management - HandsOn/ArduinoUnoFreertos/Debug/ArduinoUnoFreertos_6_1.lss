
ArduinoUnoFreertos_6_1.elf:     file format elf32-avr

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .data         000000b4  00800100  000016f6  0000178a  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  1 .text         000016f6  00000000  00000000  00000094  2**1
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  2 .bss          0000064d  008001b4  008001b4  0000183e  2**0
                  ALLOC
  3 .comment      00000030  00000000  00000000  0000183e  2**0
                  CONTENTS, READONLY
  4 .note.gnu.avr.deviceinfo 00000040  00000000  00000000  00001870  2**2
                  CONTENTS, READONLY
  5 .debug_aranges 00000378  00000000  00000000  000018b0  2**0
                  CONTENTS, READONLY, DEBUGGING
  6 .debug_info   000041cd  00000000  00000000  00001c28  2**0
                  CONTENTS, READONLY, DEBUGGING
  7 .debug_abbrev 00000e00  00000000  00000000  00005df5  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_line   000014bc  00000000  00000000  00006bf5  2**0
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_frame  00000ad0  00000000  00000000  000080b4  2**2
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_str    00001452  00000000  00000000  00008b84  2**0
                  CONTENTS, READONLY, DEBUGGING
 11 .debug_loc    00003fa2  00000000  00000000  00009fd6  2**0
                  CONTENTS, READONLY, DEBUGGING
 12 .debug_ranges 00000370  00000000  00000000  0000df78  2**0
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

00000000 <__vectors>:
       0:	0c 94 34 00 	jmp	0x68	; 0x68 <__ctors_end>
       4:	0c 94 f3 0a 	jmp	0x15e6	; 0x15e6 <__vector_1>
       8:	0c 94 20 0b 	jmp	0x1640	; 0x1640 <__vector_2>
       c:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      10:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      14:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      18:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      1c:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      20:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      24:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      28:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      2c:	0c 94 d7 02 	jmp	0x5ae	; 0x5ae <__vector_11>
      30:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      34:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      38:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      3c:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      40:	0c 94 71 02 	jmp	0x4e2	; 0x4e2 <__vector_16>
      44:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      48:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      4c:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      50:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      54:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      58:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      5c:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      60:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>
      64:	0c 94 51 00 	jmp	0xa2	; 0xa2 <__bad_interrupt>

00000068 <__ctors_end>:
      68:	11 24       	eor	r1, r1
      6a:	1f be       	out	0x3f, r1	; 63
      6c:	cf ef       	ldi	r28, 0xFF	; 255
      6e:	d8 e0       	ldi	r29, 0x08	; 8
      70:	de bf       	out	0x3e, r29	; 62
      72:	cd bf       	out	0x3d, r28	; 61

00000074 <__do_copy_data>:
      74:	11 e0       	ldi	r17, 0x01	; 1
      76:	a0 e0       	ldi	r26, 0x00	; 0
      78:	b1 e0       	ldi	r27, 0x01	; 1
      7a:	e6 ef       	ldi	r30, 0xF6	; 246
      7c:	f6 e1       	ldi	r31, 0x16	; 22
      7e:	02 c0       	rjmp	.+4      	; 0x84 <__do_copy_data+0x10>
      80:	05 90       	lpm	r0, Z+
      82:	0d 92       	st	X+, r0
      84:	a4 3b       	cpi	r26, 0xB4	; 180
      86:	b1 07       	cpc	r27, r17
      88:	d9 f7       	brne	.-10     	; 0x80 <__do_copy_data+0xc>

0000008a <__do_clear_bss>:
      8a:	28 e0       	ldi	r18, 0x08	; 8
      8c:	a4 eb       	ldi	r26, 0xB4	; 180
      8e:	b1 e0       	ldi	r27, 0x01	; 1
      90:	01 c0       	rjmp	.+2      	; 0x94 <.do_clear_bss_start>

00000092 <.do_clear_bss_loop>:
      92:	1d 92       	st	X+, r1

00000094 <.do_clear_bss_start>:
      94:	a1 30       	cpi	r26, 0x01	; 1
      96:	b2 07       	cpc	r27, r18
      98:	e1 f7       	brne	.-8      	; 0x92 <.do_clear_bss_loop>
      9a:	0e 94 ad 00 	call	0x15a	; 0x15a <main>
      9e:	0c 94 79 0b 	jmp	0x16f2	; 0x16f2 <_exit>

000000a2 <__bad_interrupt>:
      a2:	0c 94 00 00 	jmp	0	; 0x0 <__vectors>

000000a6 <vReceiverTask>:
	}
}
/*-----------------------------------------------------------*/

static void vReceiverTask( void *pvParameters )
{
      a6:	cf 93       	push	r28
      a8:	df 93       	push	r29
      aa:	00 d0       	rcall	.+0      	; 0xac <vReceiverTask+0x6>
      ac:	cd b7       	in	r28, 0x3d	; 61
      ae:	de b7       	in	r29, 0x3e	; 62
	/* This task is also defined within an infinite loop. */
	for( ;; )
	{
		///* As this task unblocks immediately that data is written to the queue this
		//call should always find the queue empty. */
		if( uxQueueMessagesWaiting( xQueue ) != 0 )
      b0:	80 91 ff 07 	lds	r24, 0x07FF
      b4:	90 91 00 08 	lds	r25, 0x0800
      b8:	0e 94 61 06 	call	0xcc2	; 0xcc2 <uxQueueMessagesWaiting>
      bc:	88 23       	and	r24, r24
      be:	21 f0       	breq	.+8      	; 0xc8 <vReceiverTask+0x22>
		{
		   USART_sendstr("Queue should be empty!\r\n");
      c0:	84 e0       	ldi	r24, 0x04	; 4
      c2:	91 e0       	ldi	r25, 0x01	; 1
      c4:	0e 94 61 0b 	call	0x16c2	; 0x16c2 <USART_sendstr>

		////////////////////// To Do 4//////////////////////////////
		/*
		   Receive the next element in the Queue and wait for a xTicksToWait for arriving at least one element.
		*/
		xStatus=xQueueReceive(xQueue,&lReceivedValue,xTicksToWait);
      c8:	20 e0       	ldi	r18, 0x00	; 0
      ca:	41 e2       	ldi	r20, 0x21	; 33
      cc:	50 e0       	ldi	r21, 0x00	; 0
      ce:	be 01       	movw	r22, r28
      d0:	6f 5f       	subi	r22, 0xFF	; 255
      d2:	7f 4f       	sbci	r23, 0xFF	; 255
      d4:	80 91 ff 07 	lds	r24, 0x07FF
      d8:	90 91 00 08 	lds	r25, 0x0800
      dc:	0e 94 b5 05 	call	0xb6a	; 0xb6a <xQueueGenericReceive>
		if( xStatus == pdPASS )
      e0:	81 30       	cpi	r24, 0x01	; 1
      e2:	69 f4       	brne	.+26     	; 0xfe <vReceiverTask+0x58>
		{
			/* Data was successfully received from the queue, print out the received
			value. */
			USART_sendstr( "Received = ");
      e4:	8d e1       	ldi	r24, 0x1D	; 29
      e6:	91 e0       	ldi	r25, 0x01	; 1
      e8:	0e 94 61 0b 	call	0x16c2	; 0x16c2 <USART_sendstr>
			USART_sendstr(lReceivedValue);
      ec:	89 81       	ldd	r24, Y+1	; 0x01
      ee:	9a 81       	ldd	r25, Y+2	; 0x02
      f0:	0e 94 61 0b 	call	0x16c2	; 0x16c2 <USART_sendstr>
			USART_sendstr( "\r\n");
      f4:	84 e5       	ldi	r24, 0x54	; 84
      f6:	91 e0       	ldi	r25, 0x01	; 1
      f8:	0e 94 61 0b 	call	0x16c2	; 0x16c2 <USART_sendstr>
      fc:	d9 cf       	rjmp	.-78     	; 0xb0 <vReceiverTask+0xa>
		else
		{
			/* We did not receive anything from the queue even after waiting for 100ms.
			This must be an error as the sending tasks are free running and will be
			continuously writing to the queue. */
			USART_sendstr("Could not receive from the queue.\r\n" );
      fe:	89 e2       	ldi	r24, 0x29	; 41
     100:	91 e0       	ldi	r25, 0x01	; 1
     102:	0e 94 61 0b 	call	0x16c2	; 0x16c2 <USART_sendstr>
     106:	d4 cf       	rjmp	.-88     	; 0xb0 <vReceiverTask+0xa>

00000108 <vSenderTask>:
	return 0;
}
/*-----------------------------------------------------------*/

static void vSenderTask( void *pvParameters )
{
     108:	cf 93       	push	r28
     10a:	df 93       	push	r29
     10c:	00 d0       	rcall	.+0      	; 0x10e <vSenderTask+0x6>
     10e:	00 d0       	rcall	.+0      	; 0x110 <vSenderTask+0x8>
     110:	cd b7       	in	r28, 0x3d	; 61
     112:	de b7       	in	r29, 0x3e	; 62

	/* Two instances are created of this task so the value that is sent to the
	queue is passed in via the task parameter rather than be hard coded.  This way
	each instance can use a different value.  Cast the parameter to the required
	type. */
	lValueToSend =(char *)pvParameters;
     114:	9a 83       	std	Y+2, r25	; 0x02
     116:	89 83       	std	Y+1, r24	; 0x01

	/* As per most tasks, this task is implemented within an infinite loop. */
		USART_sendstr("sender \r\n");
     118:	8d e4       	ldi	r24, 0x4D	; 77
     11a:	91 e0       	ldi	r25, 0x01	; 1
     11c:	0e 94 61 0b 	call	0x16c2	; 0x16c2 <USART_sendstr>
		TickType_t xLastWakeTime = xTaskGetTickCount();
     120:	0e 94 01 08 	call	0x1002	; 0x1002 <xTaskGetTickCount>
     124:	9c 83       	std	Y+4, r25	; 0x04
     126:	8b 83       	std	Y+3, r24	; 0x03
	{
		////////////////////// To Do 3//////////////////////////////
		/*
		   Insert back the element in the Queue without waiting for available space.
		*/
		xStatus=xQueueSendToBack(xQueue,&lValueToSend,0);
     128:	20 e0       	ldi	r18, 0x00	; 0
     12a:	40 e0       	ldi	r20, 0x00	; 0
     12c:	50 e0       	ldi	r21, 0x00	; 0
     12e:	be 01       	movw	r22, r28
     130:	6f 5f       	subi	r22, 0xFF	; 255
     132:	7f 4f       	sbci	r23, 0xFF	; 255
     134:	80 91 ff 07 	lds	r24, 0x07FF
     138:	90 91 00 08 	lds	r25, 0x0800
     13c:	0e 94 06 05 	call	0xa0c	; 0xa0c <xQueueGenericSend>
		if( xStatus != pdPASS )
     140:	81 30       	cpi	r24, 0x01	; 1
     142:	21 f0       	breq	.+8      	; 0x14c <vSenderTask+0x44>
		{
			/* We could not write to the queue because it was full – this must
			be an error as the queue should never contain more than one item! */
			USART_sendstr("Could not send to the queue.");
     144:	87 e5       	ldi	r24, 0x57	; 87
     146:	91 e0       	ldi	r25, 0x01	; 1
     148:	0e 94 61 0b 	call	0x16c2	; 0x16c2 <USART_sendstr>
		}
			vTaskDelayUntil(&xLastWakeTime, (100 / portTICK_PERIOD_MS));
     14c:	64 e6       	ldi	r22, 0x64	; 100
     14e:	70 e0       	ldi	r23, 0x00	; 0
     150:	ce 01       	movw	r24, r28
     152:	03 96       	adiw	r24, 0x03	; 3
     154:	0e 94 4a 09 	call	0x1294	; 0x1294 <vTaskDelayUntil>
	}
     158:	e7 cf       	rjmp	.-50     	; 0x128 <vSenderTask+0x20>

0000015a <main>:
QueueHandle_t xQueue;


int main( void )
{
	USART_init();
     15a:	0e 94 4d 0b 	call	0x169a	; 0x169a <USART_init>
	////////////////////// To Do 1//////////////////////////////
	
    /* The queue is created to hold a maximum of 5 long values. 
    Create A Suitable Queue
     */
	xQueue=xQueueCreate(5,sizeof(void*));
     15e:	40 e0       	ldi	r20, 0x00	; 0
     160:	62 e0       	ldi	r22, 0x02	; 2
     162:	85 e0       	ldi	r24, 0x05	; 5
     164:	0e 94 d8 04 	call	0x9b0	; 0x9b0 <xQueueGenericCreate>
     168:	90 93 00 08 	sts	0x0800, r25
     16c:	80 93 ff 07 	sts	0x07FF, r24
	if( xQueue != NULL ) // Queue Handler
     170:	89 2b       	or	r24, r25
     172:	49 f1       	breq	.+82     	; 0x1c6 <main+0x6c>
		/* 1. Create two instances of the task that will write to the queue.  The
		parameter is used to pass the value that the task should write to the queue,
		so one task will continuously write 100 to the queue while the other task
		will continuously write 200 to the queue.  Both tasks are created at
		priority 1. */
		xTaskCreate(vSenderTask,"send1",100,"t1",1,NULL);
     174:	a1 2c       	mov	r10, r1
     176:	b1 2c       	mov	r11, r1
     178:	c1 2c       	mov	r12, r1
     17a:	d1 2c       	mov	r13, r1
     17c:	e1 2c       	mov	r14, r1
     17e:	f1 2c       	mov	r15, r1
     180:	01 e0       	ldi	r16, 0x01	; 1
     182:	24 e7       	ldi	r18, 0x74	; 116
     184:	31 e0       	ldi	r19, 0x01	; 1
     186:	44 e6       	ldi	r20, 0x64	; 100
     188:	50 e0       	ldi	r21, 0x00	; 0
     18a:	67 e7       	ldi	r22, 0x77	; 119
     18c:	71 e0       	ldi	r23, 0x01	; 1
     18e:	84 e8       	ldi	r24, 0x84	; 132
     190:	90 e0       	ldi	r25, 0x00	; 0
     192:	0e 94 bf 06 	call	0xd7e	; 0xd7e <xTaskGenericCreate>
		xTaskCreate(vSenderTask,"send2",100,"t2",1,NULL);
     196:	2d e7       	ldi	r18, 0x7D	; 125
     198:	31 e0       	ldi	r19, 0x01	; 1
     19a:	44 e6       	ldi	r20, 0x64	; 100
     19c:	50 e0       	ldi	r21, 0x00	; 0
     19e:	60 e8       	ldi	r22, 0x80	; 128
     1a0:	71 e0       	ldi	r23, 0x01	; 1
     1a2:	84 e8       	ldi	r24, 0x84	; 132
     1a4:	90 e0       	ldi	r25, 0x00	; 0
     1a6:	0e 94 bf 06 	call	0xd7e	; 0xd7e <xTaskGenericCreate>
		/*2. Create the task that will read from the queue.  The task is created with
		priority 2, so above the priority of the sender tasks. */
	    xTaskCreate(vReceiverTask,"rec1",100,NULL,2,NULL);
     1aa:	02 e0       	ldi	r16, 0x02	; 2
     1ac:	20 e0       	ldi	r18, 0x00	; 0
     1ae:	30 e0       	ldi	r19, 0x00	; 0
     1b0:	44 e6       	ldi	r20, 0x64	; 100
     1b2:	50 e0       	ldi	r21, 0x00	; 0
     1b4:	66 e8       	ldi	r22, 0x86	; 134
     1b6:	71 e0       	ldi	r23, 0x01	; 1
     1b8:	83 e5       	ldi	r24, 0x53	; 83
     1ba:	90 e0       	ldi	r25, 0x00	; 0
     1bc:	0e 94 bf 06 	call	0xd7e	; 0xd7e <xTaskGenericCreate>
		/* Start the scheduler so the created tasks start executing. */
		vTaskStartScheduler();
     1c0:	0e 94 d0 07 	call	0xfa0	; 0xfa0 <vTaskStartScheduler>
     1c4:	04 c0       	rjmp	.+8      	; 0x1ce <main+0x74>
	}
	else
	{
		/* The queue could not be created. */
		USART_sendstr("The queue could not be created \r \n");
     1c6:	8b e8       	ldi	r24, 0x8B	; 139
     1c8:	91 e0       	ldi	r25, 0x01	; 1
     1ca:	0e 94 61 0b 	call	0x16c2	; 0x16c2 <USART_sendstr>

	/* The following line should never be reached because vTaskStartScheduler()
	will only return if there was not enough FreeRTOS heap memory available to
	create the Idle and (if configured) Timer tasks.  Heap management, and
	techniques for trapping heap exhaustion, are described in the book text. */
	for( ;; );
     1ce:	ff cf       	rjmp	.-2      	; 0x1ce <main+0x74>

000001d0 <vListInitialise>:
/*-----------------------------------------------------------
 * PUBLIC LIST API documented in list.h
 *----------------------------------------------------------*/

void vListInitialise( List_t * const pxList )
{
     1d0:	fc 01       	movw	r30, r24
	/* The list structure contains a list item which is used to mark the
	end of the list.  To initialise the list the list end is inserted
	as the only list entry. */
	pxList->pxIndex = ( ListItem_t * ) &( pxList->xListEnd );			/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     1d2:	03 96       	adiw	r24, 0x03	; 3
     1d4:	92 83       	std	Z+2, r25	; 0x02
     1d6:	81 83       	std	Z+1, r24	; 0x01

	/* The list end value is the highest possible value in the list to
	ensure it remains at the end of the list. */
	pxList->xListEnd.xItemValue = portMAX_DELAY;
     1d8:	2f ef       	ldi	r18, 0xFF	; 255
     1da:	3f ef       	ldi	r19, 0xFF	; 255
     1dc:	34 83       	std	Z+4, r19	; 0x04
     1de:	23 83       	std	Z+3, r18	; 0x03

	/* The list end next and previous pointers point to itself so we know
	when the list is empty. */
	pxList->xListEnd.pxNext = ( ListItem_t * ) &( pxList->xListEnd );	/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     1e0:	96 83       	std	Z+6, r25	; 0x06
     1e2:	85 83       	std	Z+5, r24	; 0x05
	pxList->xListEnd.pxPrevious = ( ListItem_t * ) &( pxList->xListEnd );/*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     1e4:	90 87       	std	Z+8, r25	; 0x08
     1e6:	87 83       	std	Z+7, r24	; 0x07

	pxList->uxNumberOfItems = ( UBaseType_t ) 0U;
     1e8:	10 82       	st	Z, r1
     1ea:	08 95       	ret

000001ec <vListInitialiseItem>:
/*-----------------------------------------------------------*/

void vListInitialiseItem( ListItem_t * const pxItem )
{
	/* Make sure the list item is not recorded as being on a list. */
	pxItem->pvContainer = NULL;
     1ec:	fc 01       	movw	r30, r24
     1ee:	11 86       	std	Z+9, r1	; 0x09
     1f0:	10 86       	std	Z+8, r1	; 0x08
     1f2:	08 95       	ret

000001f4 <vListInsertEnd>:
	listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );
}
/*-----------------------------------------------------------*/

void vListInsertEnd( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     1f4:	cf 93       	push	r28
     1f6:	df 93       	push	r29
     1f8:	9c 01       	movw	r18, r24
     1fa:	fb 01       	movw	r30, r22
ListItem_t * const pxIndex = pxList->pxIndex;
     1fc:	dc 01       	movw	r26, r24
     1fe:	11 96       	adiw	r26, 0x01	; 1
     200:	cd 91       	ld	r28, X+
     202:	dc 91       	ld	r29, X
     204:	12 97       	sbiw	r26, 0x02	; 2
	listTEST_LIST_ITEM_INTEGRITY( pxNewListItem );

	/* Insert a new list item into pxList, but rather than sort the list,
	makes the new list item the last item to be removed by a call to
	listGET_OWNER_OF_NEXT_ENTRY(). */
	pxNewListItem->pxNext = pxIndex;
     206:	d3 83       	std	Z+3, r29	; 0x03
     208:	c2 83       	std	Z+2, r28	; 0x02
	pxNewListItem->pxPrevious = pxIndex->pxPrevious;
     20a:	8c 81       	ldd	r24, Y+4	; 0x04
     20c:	9d 81       	ldd	r25, Y+5	; 0x05
     20e:	95 83       	std	Z+5, r25	; 0x05
     210:	84 83       	std	Z+4, r24	; 0x04

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	pxIndex->pxPrevious->pxNext = pxNewListItem;
     212:	8c 81       	ldd	r24, Y+4	; 0x04
     214:	9d 81       	ldd	r25, Y+5	; 0x05
     216:	dc 01       	movw	r26, r24
     218:	13 96       	adiw	r26, 0x03	; 3
     21a:	7c 93       	st	X, r23
     21c:	6e 93       	st	-X, r22
     21e:	12 97       	sbiw	r26, 0x02	; 2
	pxIndex->pxPrevious = pxNewListItem;
     220:	7d 83       	std	Y+5, r23	; 0x05
     222:	6c 83       	std	Y+4, r22	; 0x04

	/* Remember which list the item is in. */
	pxNewListItem->pvContainer = ( void * ) pxList;
     224:	31 87       	std	Z+9, r19	; 0x09
     226:	20 87       	std	Z+8, r18	; 0x08

	( pxList->uxNumberOfItems )++;
     228:	f9 01       	movw	r30, r18
     22a:	80 81       	ld	r24, Z
     22c:	8f 5f       	subi	r24, 0xFF	; 255
     22e:	80 83       	st	Z, r24
}
     230:	df 91       	pop	r29
     232:	cf 91       	pop	r28
     234:	08 95       	ret

00000236 <vListInsert>:
/*-----------------------------------------------------------*/

void vListInsert( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     236:	cf 93       	push	r28
     238:	df 93       	push	r29
     23a:	eb 01       	movw	r28, r22
ListItem_t *pxIterator;
const TickType_t xValueOfInsertion = pxNewListItem->xItemValue;
     23c:	48 81       	ld	r20, Y
     23e:	59 81       	ldd	r21, Y+1	; 0x01
	new list item should be placed after it.  This ensures that TCB's which are
	stored in ready lists (all of which have the same xItemValue value) get a
	share of the CPU.  However, if the xItemValue is the same as the back marker
	the iteration loop below will not end.  Therefore the value is checked
	first, and the algorithm slightly modified if necessary. */
	if( xValueOfInsertion == portMAX_DELAY )
     240:	4f 3f       	cpi	r20, 0xFF	; 255
     242:	2f ef       	ldi	r18, 0xFF	; 255
     244:	52 07       	cpc	r21, r18
     246:	21 f4       	brne	.+8      	; 0x250 <vListInsert+0x1a>
	{
		pxIterator = pxList->xListEnd.pxPrevious;
     248:	fc 01       	movw	r30, r24
     24a:	a7 81       	ldd	r26, Z+7	; 0x07
     24c:	b0 85       	ldd	r27, Z+8	; 0x08
     24e:	0d c0       	rjmp	.+26     	; 0x26a <vListInsert+0x34>
			4) Using a queue or semaphore before it has been initialised or
			   before the scheduler has been started (are interrupts firing
			   before vTaskStartScheduler() has been called?).
		**********************************************************************/

		for( pxIterator = ( ListItem_t * ) &( pxList->xListEnd ); pxIterator->pxNext->xItemValue <= xValueOfInsertion; pxIterator = pxIterator->pxNext ) /*lint !e826 !e740 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     250:	dc 01       	movw	r26, r24
     252:	13 96       	adiw	r26, 0x03	; 3
     254:	01 c0       	rjmp	.+2      	; 0x258 <vListInsert+0x22>
     256:	df 01       	movw	r26, r30
     258:	12 96       	adiw	r26, 0x02	; 2
     25a:	ed 91       	ld	r30, X+
     25c:	fc 91       	ld	r31, X
     25e:	13 97       	sbiw	r26, 0x03	; 3
     260:	20 81       	ld	r18, Z
     262:	31 81       	ldd	r19, Z+1	; 0x01
     264:	42 17       	cp	r20, r18
     266:	53 07       	cpc	r21, r19
     268:	b0 f7       	brcc	.-20     	; 0x256 <vListInsert+0x20>
			/* There is nothing to do here, just iterating to the wanted
			insertion position. */
		}
	}

	pxNewListItem->pxNext = pxIterator->pxNext;
     26a:	12 96       	adiw	r26, 0x02	; 2
     26c:	ed 91       	ld	r30, X+
     26e:	fc 91       	ld	r31, X
     270:	13 97       	sbiw	r26, 0x03	; 3
     272:	fb 83       	std	Y+3, r31	; 0x03
     274:	ea 83       	std	Y+2, r30	; 0x02
	pxNewListItem->pxNext->pxPrevious = pxNewListItem;
     276:	d5 83       	std	Z+5, r29	; 0x05
     278:	c4 83       	std	Z+4, r28	; 0x04
	pxNewListItem->pxPrevious = pxIterator;
     27a:	bd 83       	std	Y+5, r27	; 0x05
     27c:	ac 83       	std	Y+4, r26	; 0x04
	pxIterator->pxNext = pxNewListItem;
     27e:	13 96       	adiw	r26, 0x03	; 3
     280:	dc 93       	st	X, r29
     282:	ce 93       	st	-X, r28
     284:	12 97       	sbiw	r26, 0x02	; 2

	/* Remember which list the item is in.  This allows fast removal of the
	item later. */
	pxNewListItem->pvContainer = ( void * ) pxList;
     286:	99 87       	std	Y+9, r25	; 0x09
     288:	88 87       	std	Y+8, r24	; 0x08

	( pxList->uxNumberOfItems )++;
     28a:	fc 01       	movw	r30, r24
     28c:	20 81       	ld	r18, Z
     28e:	2f 5f       	subi	r18, 0xFF	; 255
     290:	20 83       	st	Z, r18
}
     292:	df 91       	pop	r29
     294:	cf 91       	pop	r28
     296:	08 95       	ret

00000298 <uxListRemove>:
/*-----------------------------------------------------------*/

UBaseType_t uxListRemove( ListItem_t * const pxItemToRemove )
{
     298:	cf 93       	push	r28
     29a:	df 93       	push	r29
     29c:	fc 01       	movw	r30, r24
/* The list item knows which list it is in.  Obtain the list from the list
item. */
List_t * const pxList = ( List_t * ) pxItemToRemove->pvContainer;
     29e:	a0 85       	ldd	r26, Z+8	; 0x08
     2a0:	b1 85       	ldd	r27, Z+9	; 0x09

	pxItemToRemove->pxNext->pxPrevious = pxItemToRemove->pxPrevious;
     2a2:	c2 81       	ldd	r28, Z+2	; 0x02
     2a4:	d3 81       	ldd	r29, Z+3	; 0x03
     2a6:	84 81       	ldd	r24, Z+4	; 0x04
     2a8:	95 81       	ldd	r25, Z+5	; 0x05
     2aa:	9d 83       	std	Y+5, r25	; 0x05
     2ac:	8c 83       	std	Y+4, r24	; 0x04
	pxItemToRemove->pxPrevious->pxNext = pxItemToRemove->pxNext;
     2ae:	c4 81       	ldd	r28, Z+4	; 0x04
     2b0:	d5 81       	ldd	r29, Z+5	; 0x05
     2b2:	82 81       	ldd	r24, Z+2	; 0x02
     2b4:	93 81       	ldd	r25, Z+3	; 0x03
     2b6:	9b 83       	std	Y+3, r25	; 0x03
     2b8:	8a 83       	std	Y+2, r24	; 0x02

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	/* Make sure the index is left pointing to a valid item. */
	if( pxList->pxIndex == pxItemToRemove )
     2ba:	11 96       	adiw	r26, 0x01	; 1
     2bc:	cd 91       	ld	r28, X+
     2be:	dc 91       	ld	r29, X
     2c0:	12 97       	sbiw	r26, 0x02	; 2
     2c2:	ce 17       	cp	r28, r30
     2c4:	df 07       	cpc	r29, r31
     2c6:	31 f4       	brne	.+12     	; 0x2d4 <uxListRemove+0x3c>
	{
		pxList->pxIndex = pxItemToRemove->pxPrevious;
     2c8:	8c 81       	ldd	r24, Y+4	; 0x04
     2ca:	9d 81       	ldd	r25, Y+5	; 0x05
     2cc:	12 96       	adiw	r26, 0x02	; 2
     2ce:	9c 93       	st	X, r25
     2d0:	8e 93       	st	-X, r24
     2d2:	11 97       	sbiw	r26, 0x01	; 1
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxItemToRemove->pvContainer = NULL;
     2d4:	11 86       	std	Z+9, r1	; 0x09
     2d6:	10 86       	std	Z+8, r1	; 0x08
	( pxList->uxNumberOfItems )--;
     2d8:	8c 91       	ld	r24, X
     2da:	81 50       	subi	r24, 0x01	; 1
     2dc:	8c 93       	st	X, r24

	return pxList->uxNumberOfItems;
}
     2de:	df 91       	pop	r29
     2e0:	cf 91       	pop	r28
     2e2:	08 95       	ret

000002e4 <pxPortInitialiseStack>:
uint16_t usAddress;

	/* Place a few bytes of known values on the bottom of the stack. 
	This is just useful for debugging. */

	*pxTopOfStack = 0x11;
     2e4:	31 e1       	ldi	r19, 0x11	; 17
     2e6:	fc 01       	movw	r30, r24
     2e8:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = 0x22;
     2ea:	31 97       	sbiw	r30, 0x01	; 1
     2ec:	22 e2       	ldi	r18, 0x22	; 34
     2ee:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = 0x33;
     2f0:	31 97       	sbiw	r30, 0x01	; 1
     2f2:	a3 e3       	ldi	r26, 0x33	; 51
     2f4:	a0 83       	st	Z, r26
	/*lint -e950 -e611 -e923 Lint doesn't like this much - but nothing I can do about it. */

	/* The start of the task code will be popped off the stack last, so place
	it on first. */
	usAddress = ( uint16_t ) pxCode;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     2f6:	31 97       	sbiw	r30, 0x01	; 1
     2f8:	60 83       	st	Z, r22
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     2fa:	31 97       	sbiw	r30, 0x01	; 1
     2fc:	70 83       	st	Z, r23

	/* Next simulate the stack as if after a call to portSAVE_CONTEXT().  
	portSAVE_CONTEXT places the flags on the stack immediately after r0
	to ensure the interrupts get disabled as soon as possible, and so ensuring
	the stack use is minimal should a context switch interrupt occur. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R0 */
     2fe:	31 97       	sbiw	r30, 0x01	; 1
     300:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = portFLAGS_INT_ENABLED;
     302:	31 97       	sbiw	r30, 0x01	; 1
     304:	60 e8       	ldi	r22, 0x80	; 128
     306:	60 83       	st	Z, r22
	pxTopOfStack--;


	/* Now the remaining registers.   The compiler expects R1 to be 0. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R1 */
     308:	31 97       	sbiw	r30, 0x01	; 1
     30a:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x02;	/* R2 */
     30c:	31 97       	sbiw	r30, 0x01	; 1
     30e:	62 e0       	ldi	r22, 0x02	; 2
     310:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x03;	/* R3 */
     312:	31 97       	sbiw	r30, 0x01	; 1
     314:	63 e0       	ldi	r22, 0x03	; 3
     316:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x04;	/* R4 */
     318:	31 97       	sbiw	r30, 0x01	; 1
     31a:	64 e0       	ldi	r22, 0x04	; 4
     31c:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x05;	/* R5 */
     31e:	31 97       	sbiw	r30, 0x01	; 1
     320:	65 e0       	ldi	r22, 0x05	; 5
     322:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x06;	/* R6 */
     324:	31 97       	sbiw	r30, 0x01	; 1
     326:	66 e0       	ldi	r22, 0x06	; 6
     328:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x07;	/* R7 */
     32a:	31 97       	sbiw	r30, 0x01	; 1
     32c:	67 e0       	ldi	r22, 0x07	; 7
     32e:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x08;	/* R8 */
     330:	31 97       	sbiw	r30, 0x01	; 1
     332:	68 e0       	ldi	r22, 0x08	; 8
     334:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x09;	/* R9 */
     336:	31 97       	sbiw	r30, 0x01	; 1
     338:	69 e0       	ldi	r22, 0x09	; 9
     33a:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x10;	/* R10 */
     33c:	31 97       	sbiw	r30, 0x01	; 1
     33e:	60 e1       	ldi	r22, 0x10	; 16
     340:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x11;	/* R11 */
     342:	31 97       	sbiw	r30, 0x01	; 1
     344:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x12;	/* R12 */
     346:	31 97       	sbiw	r30, 0x01	; 1
     348:	32 e1       	ldi	r19, 0x12	; 18
     34a:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x13;	/* R13 */
     34c:	31 97       	sbiw	r30, 0x01	; 1
     34e:	33 e1       	ldi	r19, 0x13	; 19
     350:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x14;	/* R14 */
     352:	31 97       	sbiw	r30, 0x01	; 1
     354:	34 e1       	ldi	r19, 0x14	; 20
     356:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x15;	/* R15 */
     358:	31 97       	sbiw	r30, 0x01	; 1
     35a:	35 e1       	ldi	r19, 0x15	; 21
     35c:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x16;	/* R16 */
     35e:	31 97       	sbiw	r30, 0x01	; 1
     360:	36 e1       	ldi	r19, 0x16	; 22
     362:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x17;	/* R17 */
     364:	31 97       	sbiw	r30, 0x01	; 1
     366:	37 e1       	ldi	r19, 0x17	; 23
     368:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x18;	/* R18 */
     36a:	31 97       	sbiw	r30, 0x01	; 1
     36c:	38 e1       	ldi	r19, 0x18	; 24
     36e:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x19;	/* R19 */
     370:	31 97       	sbiw	r30, 0x01	; 1
     372:	39 e1       	ldi	r19, 0x19	; 25
     374:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x20;	/* R20 */
     376:	31 97       	sbiw	r30, 0x01	; 1
     378:	30 e2       	ldi	r19, 0x20	; 32
     37a:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x21;	/* R21 */
     37c:	31 97       	sbiw	r30, 0x01	; 1
     37e:	31 e2       	ldi	r19, 0x21	; 33
     380:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x22;	/* R22 */
     382:	31 97       	sbiw	r30, 0x01	; 1
     384:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x23;	/* R23 */
     386:	31 97       	sbiw	r30, 0x01	; 1
     388:	23 e2       	ldi	r18, 0x23	; 35
     38a:	20 83       	st	Z, r18
	pxTopOfStack--;

	/* Place the parameter on the stack in the expected location. */
	usAddress = ( uint16_t ) pvParameters;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     38c:	31 97       	sbiw	r30, 0x01	; 1
     38e:	40 83       	st	Z, r20
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     390:	31 97       	sbiw	r30, 0x01	; 1
     392:	50 83       	st	Z, r21
	pxTopOfStack--;

	*pxTopOfStack = ( StackType_t ) 0x26;	/* R26 X */
     394:	31 97       	sbiw	r30, 0x01	; 1
     396:	26 e2       	ldi	r18, 0x26	; 38
     398:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x27;	/* R27 */
     39a:	31 97       	sbiw	r30, 0x01	; 1
     39c:	27 e2       	ldi	r18, 0x27	; 39
     39e:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x28;	/* R28 Y */
     3a0:	31 97       	sbiw	r30, 0x01	; 1
     3a2:	28 e2       	ldi	r18, 0x28	; 40
     3a4:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x29;	/* R29 */
     3a6:	31 97       	sbiw	r30, 0x01	; 1
     3a8:	29 e2       	ldi	r18, 0x29	; 41
     3aa:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x30;	/* R30 Z */
     3ac:	31 97       	sbiw	r30, 0x01	; 1
     3ae:	20 e3       	ldi	r18, 0x30	; 48
     3b0:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x031;	/* R31 */
     3b2:	31 97       	sbiw	r30, 0x01	; 1
     3b4:	21 e3       	ldi	r18, 0x31	; 49
     3b6:	20 83       	st	Z, r18
	pxTopOfStack--;

	/*lint +e950 +e611 +e923 */

	return pxTopOfStack;
}
     3b8:	86 97       	sbiw	r24, 0x26	; 38
     3ba:	08 95       	ret

000003bc <xPortStartScheduler>:
	/* Setup compare match value for compare match A.  Interrupts are disabled 
	before this is called so we need not worry here. */
	ucLowByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	ulCompareMatch >>= 8;
	ucHighByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	OCR1AH = ucHighByte;
     3bc:	10 92 89 00 	sts	0x0089, r1
	OCR1AL = ucLowByte;
     3c0:	8c e7       	ldi	r24, 0x7C	; 124
     3c2:	80 93 88 00 	sts	0x0088, r24

	/* Setup clock source and compare match behaviour. */
	ucLowByte = portCLEAR_COUNTER_ON_MATCH | portPRESCALE_64;
	TCCR1B = ucLowByte;
     3c6:	8b e0       	ldi	r24, 0x0B	; 11
     3c8:	80 93 81 00 	sts	0x0081, r24

	/* Enable the interrupt - this is okay as interrupt are currently globally
	disabled. */
	ucLowByte = TIMSK1;
     3cc:	ef e6       	ldi	r30, 0x6F	; 111
     3ce:	f0 e0       	ldi	r31, 0x00	; 0
     3d0:	80 81       	ld	r24, Z
	ucLowByte |= portCOMPARE_MATCH_A_INTERRUPT_ENABLE;
     3d2:	82 60       	ori	r24, 0x02	; 2
	TIMSK1 = ucLowByte;
     3d4:	80 83       	st	Z, r24
{
	/* Setup the hardware to generate the tick. */
	prvSetupTimerInterrupt();

	/* Restore the context of the first task that is going to run. */
	portRESTORE_CONTEXT();
     3d6:	a0 91 f9 07 	lds	r26, 0x07F9
     3da:	b0 91 fa 07 	lds	r27, 0x07FA
     3de:	cd 91       	ld	r28, X+
     3e0:	cd bf       	out	0x3d, r28	; 61
     3e2:	dd 91       	ld	r29, X+
     3e4:	de bf       	out	0x3e, r29	; 62
     3e6:	ff 91       	pop	r31
     3e8:	ef 91       	pop	r30
     3ea:	df 91       	pop	r29
     3ec:	cf 91       	pop	r28
     3ee:	bf 91       	pop	r27
     3f0:	af 91       	pop	r26
     3f2:	9f 91       	pop	r25
     3f4:	8f 91       	pop	r24
     3f6:	7f 91       	pop	r23
     3f8:	6f 91       	pop	r22
     3fa:	5f 91       	pop	r21
     3fc:	4f 91       	pop	r20
     3fe:	3f 91       	pop	r19
     400:	2f 91       	pop	r18
     402:	1f 91       	pop	r17
     404:	0f 91       	pop	r16
     406:	ff 90       	pop	r15
     408:	ef 90       	pop	r14
     40a:	df 90       	pop	r13
     40c:	cf 90       	pop	r12
     40e:	bf 90       	pop	r11
     410:	af 90       	pop	r10
     412:	9f 90       	pop	r9
     414:	8f 90       	pop	r8
     416:	7f 90       	pop	r7
     418:	6f 90       	pop	r6
     41a:	5f 90       	pop	r5
     41c:	4f 90       	pop	r4
     41e:	3f 90       	pop	r3
     420:	2f 90       	pop	r2
     422:	1f 90       	pop	r1
     424:	0f 90       	pop	r0
     426:	0f be       	out	0x3f, r0	; 63
     428:	0f 90       	pop	r0

	/* Simulate a function call end as generated by the compiler.  We will now
	jump to the start of the task the context of which we have just restored. */
	asm volatile ( "ret" );
     42a:	08 95       	ret

	/* Should not get here. */
	return pdTRUE;
}
     42c:	81 e0       	ldi	r24, 0x01	; 1
     42e:	08 95       	ret

00000430 <vPortYield>:
 * can use a naked attribute.
 */
void vPortYield( void ) __attribute__ ( ( naked ) );
void vPortYield( void )
{
	portSAVE_CONTEXT();
     430:	0f 92       	push	r0
     432:	0f b6       	in	r0, 0x3f	; 63
     434:	f8 94       	cli
     436:	0f 92       	push	r0
     438:	1f 92       	push	r1
     43a:	11 24       	eor	r1, r1
     43c:	2f 92       	push	r2
     43e:	3f 92       	push	r3
     440:	4f 92       	push	r4
     442:	5f 92       	push	r5
     444:	6f 92       	push	r6
     446:	7f 92       	push	r7
     448:	8f 92       	push	r8
     44a:	9f 92       	push	r9
     44c:	af 92       	push	r10
     44e:	bf 92       	push	r11
     450:	cf 92       	push	r12
     452:	df 92       	push	r13
     454:	ef 92       	push	r14
     456:	ff 92       	push	r15
     458:	0f 93       	push	r16
     45a:	1f 93       	push	r17
     45c:	2f 93       	push	r18
     45e:	3f 93       	push	r19
     460:	4f 93       	push	r20
     462:	5f 93       	push	r21
     464:	6f 93       	push	r22
     466:	7f 93       	push	r23
     468:	8f 93       	push	r24
     46a:	9f 93       	push	r25
     46c:	af 93       	push	r26
     46e:	bf 93       	push	r27
     470:	cf 93       	push	r28
     472:	df 93       	push	r29
     474:	ef 93       	push	r30
     476:	ff 93       	push	r31
     478:	a0 91 f9 07 	lds	r26, 0x07F9
     47c:	b0 91 fa 07 	lds	r27, 0x07FA
     480:	0d b6       	in	r0, 0x3d	; 61
     482:	0d 92       	st	X+, r0
     484:	0e b6       	in	r0, 0x3e	; 62
     486:	0d 92       	st	X+, r0
	vTaskSwitchContext();
     488:	0e 94 c9 09 	call	0x1392	; 0x1392 <vTaskSwitchContext>
	portRESTORE_CONTEXT();
     48c:	a0 91 f9 07 	lds	r26, 0x07F9
     490:	b0 91 fa 07 	lds	r27, 0x07FA
     494:	cd 91       	ld	r28, X+
     496:	cd bf       	out	0x3d, r28	; 61
     498:	dd 91       	ld	r29, X+
     49a:	de bf       	out	0x3e, r29	; 62
     49c:	ff 91       	pop	r31
     49e:	ef 91       	pop	r30
     4a0:	df 91       	pop	r29
     4a2:	cf 91       	pop	r28
     4a4:	bf 91       	pop	r27
     4a6:	af 91       	pop	r26
     4a8:	9f 91       	pop	r25
     4aa:	8f 91       	pop	r24
     4ac:	7f 91       	pop	r23
     4ae:	6f 91       	pop	r22
     4b0:	5f 91       	pop	r21
     4b2:	4f 91       	pop	r20
     4b4:	3f 91       	pop	r19
     4b6:	2f 91       	pop	r18
     4b8:	1f 91       	pop	r17
     4ba:	0f 91       	pop	r16
     4bc:	ff 90       	pop	r15
     4be:	ef 90       	pop	r14
     4c0:	df 90       	pop	r13
     4c2:	cf 90       	pop	r12
     4c4:	bf 90       	pop	r11
     4c6:	af 90       	pop	r10
     4c8:	9f 90       	pop	r9
     4ca:	8f 90       	pop	r8
     4cc:	7f 90       	pop	r7
     4ce:	6f 90       	pop	r6
     4d0:	5f 90       	pop	r5
     4d2:	4f 90       	pop	r4
     4d4:	3f 90       	pop	r3
     4d6:	2f 90       	pop	r2
     4d8:	1f 90       	pop	r1
     4da:	0f 90       	pop	r0
     4dc:	0f be       	out	0x3f, r0	; 63
     4de:	0f 90       	pop	r0

	asm volatile ( "ret" );
     4e0:	08 95       	ret

000004e2 <__vector_16>:
}


ISR(TIMER0_OVF_vect)				//ISR for timer0 overflow
{
     4e2:	1f 92       	push	r1
     4e4:	0f 92       	push	r0
     4e6:	0f b6       	in	r0, 0x3f	; 63
     4e8:	0f 92       	push	r0
     4ea:	11 24       	eor	r1, r1
  ulIsrHandler[0];	
}
     4ec:	0f 90       	pop	r0
     4ee:	0f be       	out	0x3f, r0	; 63
     4f0:	0f 90       	pop	r0
     4f2:	1f 90       	pop	r1
     4f4:	18 95       	reti

000004f6 <vPortYieldFromTick>:
 * call comes from the tick ISR.
 */
void vPortYieldFromTick( void ) __attribute__ ( ( naked ) );
void vPortYieldFromTick( void )
{
	portSAVE_CONTEXT();
     4f6:	0f 92       	push	r0
     4f8:	0f b6       	in	r0, 0x3f	; 63
     4fa:	f8 94       	cli
     4fc:	0f 92       	push	r0
     4fe:	1f 92       	push	r1
     500:	11 24       	eor	r1, r1
     502:	2f 92       	push	r2
     504:	3f 92       	push	r3
     506:	4f 92       	push	r4
     508:	5f 92       	push	r5
     50a:	6f 92       	push	r6
     50c:	7f 92       	push	r7
     50e:	8f 92       	push	r8
     510:	9f 92       	push	r9
     512:	af 92       	push	r10
     514:	bf 92       	push	r11
     516:	cf 92       	push	r12
     518:	df 92       	push	r13
     51a:	ef 92       	push	r14
     51c:	ff 92       	push	r15
     51e:	0f 93       	push	r16
     520:	1f 93       	push	r17
     522:	2f 93       	push	r18
     524:	3f 93       	push	r19
     526:	4f 93       	push	r20
     528:	5f 93       	push	r21
     52a:	6f 93       	push	r22
     52c:	7f 93       	push	r23
     52e:	8f 93       	push	r24
     530:	9f 93       	push	r25
     532:	af 93       	push	r26
     534:	bf 93       	push	r27
     536:	cf 93       	push	r28
     538:	df 93       	push	r29
     53a:	ef 93       	push	r30
     53c:	ff 93       	push	r31
     53e:	a0 91 f9 07 	lds	r26, 0x07F9
     542:	b0 91 fa 07 	lds	r27, 0x07FA
     546:	0d b6       	in	r0, 0x3d	; 61
     548:	0d 92       	st	X+, r0
     54a:	0e b6       	in	r0, 0x3e	; 62
     54c:	0d 92       	st	X+, r0
	if( xTaskIncrementTick() != pdFALSE )
     54e:	0e 94 0b 08 	call	0x1016	; 0x1016 <xTaskIncrementTick>
     552:	81 11       	cpse	r24, r1
	{
		vTaskSwitchContext();
     554:	0e 94 c9 09 	call	0x1392	; 0x1392 <vTaskSwitchContext>
	}
	portRESTORE_CONTEXT();
     558:	a0 91 f9 07 	lds	r26, 0x07F9
     55c:	b0 91 fa 07 	lds	r27, 0x07FA
     560:	cd 91       	ld	r28, X+
     562:	cd bf       	out	0x3d, r28	; 61
     564:	dd 91       	ld	r29, X+
     566:	de bf       	out	0x3e, r29	; 62
     568:	ff 91       	pop	r31
     56a:	ef 91       	pop	r30
     56c:	df 91       	pop	r29
     56e:	cf 91       	pop	r28
     570:	bf 91       	pop	r27
     572:	af 91       	pop	r26
     574:	9f 91       	pop	r25
     576:	8f 91       	pop	r24
     578:	7f 91       	pop	r23
     57a:	6f 91       	pop	r22
     57c:	5f 91       	pop	r21
     57e:	4f 91       	pop	r20
     580:	3f 91       	pop	r19
     582:	2f 91       	pop	r18
     584:	1f 91       	pop	r17
     586:	0f 91       	pop	r16
     588:	ff 90       	pop	r15
     58a:	ef 90       	pop	r14
     58c:	df 90       	pop	r13
     58e:	cf 90       	pop	r12
     590:	bf 90       	pop	r11
     592:	af 90       	pop	r10
     594:	9f 90       	pop	r9
     596:	8f 90       	pop	r8
     598:	7f 90       	pop	r7
     59a:	6f 90       	pop	r6
     59c:	5f 90       	pop	r5
     59e:	4f 90       	pop	r4
     5a0:	3f 90       	pop	r3
     5a2:	2f 90       	pop	r2
     5a4:	1f 90       	pop	r1
     5a6:	0f 90       	pop	r0
     5a8:	0f be       	out	0x3f, r0	; 63
     5aa:	0f 90       	pop	r0

	asm volatile ( "ret" );
     5ac:	08 95       	ret

000005ae <__vector_11>:
	 * count is incremented after the context is saved.
	 */
	void TIMER1_COMPA_vect(void) __attribute__ ((signal, naked));
	void TIMER1_COMPA_vect(void)
	{
		vPortYieldFromTick();
     5ae:	0e 94 7b 02 	call	0x4f6	; 0x4f6 <vPortYieldFromTick>
		asm volatile ( "reti" );
     5b2:	18 95       	reti

000005b4 <pvPortMalloc>:
	pxIterator->pxNextFreeBlock = pxBlockToInsert;									\
}
/*-----------------------------------------------------------*/

void *pvPortMalloc( size_t xWantedSize )
{
     5b4:	0f 93       	push	r16
     5b6:	1f 93       	push	r17
     5b8:	cf 93       	push	r28
     5ba:	df 93       	push	r29
     5bc:	ec 01       	movw	r28, r24
BlockLink_t *pxBlock, *pxPreviousBlock, *pxNewBlockLink;
static BaseType_t xHeapHasBeenInitialised = pdFALSE;
void *pvReturn = NULL;

	vTaskSuspendAll();
     5be:	0e 94 fb 07 	call	0xff6	; 0xff6 <vTaskSuspendAll>
	{
		/* If this is the first call to malloc then the heap will require
		initialisation to setup the list of free blocks. */
		if( xHeapHasBeenInitialised == pdFALSE )
     5c2:	80 91 b4 01 	lds	r24, 0x01B4
     5c6:	81 11       	cpse	r24, r1
     5c8:	1d c0       	rjmp	.+58     	; 0x604 <pvPortMalloc+0x50>
	/* Ensure the heap starts on a correctly aligned boundary. */
	pucAlignedHeap = ( uint8_t * ) ( ( ( portPOINTER_SIZE_TYPE ) &ucHeap[ portBYTE_ALIGNMENT ] ) & ( ~( ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) ) );

	/* xStart is used to hold a pointer to the first item in the list of free
	blocks.  The void cast is used to prevent compiler warnings. */
	xStart.pxNextFreeBlock = ( void * ) pucAlignedHeap;
     5ca:	e9 eb       	ldi	r30, 0xB9	; 185
     5cc:	f1 e0       	ldi	r31, 0x01	; 1
     5ce:	8e eb       	ldi	r24, 0xBE	; 190
     5d0:	91 e0       	ldi	r25, 0x01	; 1
     5d2:	91 83       	std	Z+1, r25	; 0x01
     5d4:	80 83       	st	Z, r24
	xStart.xBlockSize = ( size_t ) 0;
     5d6:	13 82       	std	Z+3, r1	; 0x03
     5d8:	12 82       	std	Z+2, r1	; 0x02

	/* xEnd is used to mark the end of the list of free blocks. */
	xEnd.xBlockSize = configADJUSTED_HEAP_SIZE;
     5da:	e5 eb       	ldi	r30, 0xB5	; 181
     5dc:	f1 e0       	ldi	r31, 0x01	; 1
     5de:	8b ed       	ldi	r24, 0xDB	; 219
     5e0:	95 e0       	ldi	r25, 0x05	; 5
     5e2:	93 83       	std	Z+3, r25	; 0x03
     5e4:	82 83       	std	Z+2, r24	; 0x02
	xEnd.pxNextFreeBlock = NULL;
     5e6:	11 82       	std	Z+1, r1	; 0x01
     5e8:	10 82       	st	Z, r1

	/* To start with there is a single free block that is sized to take up the
	entire heap space. */
	pxFirstFreeBlock = ( void * ) pucAlignedHeap;
	pxFirstFreeBlock->xBlockSize = configADJUSTED_HEAP_SIZE;
     5ea:	ad eb       	ldi	r26, 0xBD	; 189
     5ec:	b1 e0       	ldi	r27, 0x01	; 1
     5ee:	14 96       	adiw	r26, 0x04	; 4
     5f0:	9c 93       	st	X, r25
     5f2:	8e 93       	st	-X, r24
     5f4:	13 97       	sbiw	r26, 0x03	; 3
	pxFirstFreeBlock->pxNextFreeBlock = &xEnd;
     5f6:	12 96       	adiw	r26, 0x02	; 2
     5f8:	fc 93       	st	X, r31
     5fa:	ee 93       	st	-X, r30
     5fc:	11 97       	sbiw	r26, 0x01	; 1
		/* If this is the first call to malloc then the heap will require
		initialisation to setup the list of free blocks. */
		if( xHeapHasBeenInitialised == pdFALSE )
		{
			prvHeapInit();
			xHeapHasBeenInitialised = pdTRUE;
     5fe:	81 e0       	ldi	r24, 0x01	; 1
     600:	80 93 b4 01 	sts	0x01B4, r24
		}

		/* The wanted size is increased so it can contain a BlockLink_t
		structure in addition to the requested amount of bytes. */
		if( xWantedSize > 0 )
     604:	20 97       	sbiw	r28, 0x00	; 0
     606:	09 f4       	brne	.+2      	; 0x60a <pvPortMalloc+0x56>
     608:	5f c0       	rjmp	.+190    	; 0x6c8 <pvPortMalloc+0x114>
		{
			xWantedSize += heapSTRUCT_SIZE;
     60a:	9e 01       	movw	r18, r28
     60c:	2c 5f       	subi	r18, 0xFC	; 252
     60e:	3f 4f       	sbci	r19, 0xFF	; 255
				/* Byte alignment required. */
				xWantedSize += ( portBYTE_ALIGNMENT - ( xWantedSize & portBYTE_ALIGNMENT_MASK ) );
			}
		}

		if( ( xWantedSize > 0 ) && ( xWantedSize < configADJUSTED_HEAP_SIZE ) )
     610:	23 96       	adiw	r28, 0x03	; 3
     612:	ca 3d       	cpi	r28, 0xDA	; 218
     614:	d5 40       	sbci	r29, 0x05	; 5
     616:	08 f0       	brcs	.+2      	; 0x61a <pvPortMalloc+0x66>
     618:	5a c0       	rjmp	.+180    	; 0x6ce <pvPortMalloc+0x11a>
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
			pxBlock = xStart.pxNextFreeBlock;
     61a:	e0 91 b9 01 	lds	r30, 0x01B9
     61e:	f0 91 ba 01 	lds	r31, 0x01BA

		if( ( xWantedSize > 0 ) && ( xWantedSize < configADJUSTED_HEAP_SIZE ) )
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
     622:	a9 eb       	ldi	r26, 0xB9	; 185
     624:	b1 e0       	ldi	r27, 0x01	; 1
			pxBlock = xStart.pxNextFreeBlock;
			while( ( pxBlock->xBlockSize < xWantedSize ) && ( pxBlock->pxNextFreeBlock != NULL ) )
     626:	02 c0       	rjmp	.+4      	; 0x62c <pvPortMalloc+0x78>
     628:	df 01       	movw	r26, r30
			{
				pxPreviousBlock = pxBlock;
				pxBlock = pxBlock->pxNextFreeBlock;
     62a:	fc 01       	movw	r30, r24
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
			pxBlock = xStart.pxNextFreeBlock;
			while( ( pxBlock->xBlockSize < xWantedSize ) && ( pxBlock->pxNextFreeBlock != NULL ) )
     62c:	82 81       	ldd	r24, Z+2	; 0x02
     62e:	93 81       	ldd	r25, Z+3	; 0x03
     630:	82 17       	cp	r24, r18
     632:	93 07       	cpc	r25, r19
     634:	20 f4       	brcc	.+8      	; 0x63e <pvPortMalloc+0x8a>
     636:	80 81       	ld	r24, Z
     638:	91 81       	ldd	r25, Z+1	; 0x01
     63a:	00 97       	sbiw	r24, 0x00	; 0
     63c:	a9 f7       	brne	.-22     	; 0x628 <pvPortMalloc+0x74>
				pxPreviousBlock = pxBlock;
				pxBlock = pxBlock->pxNextFreeBlock;
			}

			/* If we found the end marker then a block of adequate size was not found. */
			if( pxBlock != &xEnd )
     63e:	c1 e0       	ldi	r28, 0x01	; 1
     640:	e5 3b       	cpi	r30, 0xB5	; 181
     642:	fc 07       	cpc	r31, r28
     644:	09 f4       	brne	.+2      	; 0x648 <pvPortMalloc+0x94>
     646:	46 c0       	rjmp	.+140    	; 0x6d4 <pvPortMalloc+0x120>
			{
				/* Return the memory space - jumping over the BlockLink_t structure
				at its start. */
				pvReturn = ( void * ) ( ( ( uint8_t * ) pxPreviousBlock->pxNextFreeBlock ) + heapSTRUCT_SIZE );
     648:	cd 91       	ld	r28, X+
     64a:	dc 91       	ld	r29, X
     64c:	11 97       	sbiw	r26, 0x01	; 1
     64e:	8e 01       	movw	r16, r28
     650:	0c 5f       	subi	r16, 0xFC	; 252
     652:	1f 4f       	sbci	r17, 0xFF	; 255

				/* This block is being returned for use so must be taken out of the
				list of free blocks. */
				pxPreviousBlock->pxNextFreeBlock = pxBlock->pxNextFreeBlock;
     654:	80 81       	ld	r24, Z
     656:	91 81       	ldd	r25, Z+1	; 0x01
     658:	8d 93       	st	X+, r24
     65a:	9c 93       	st	X, r25

				/* If the block is larger than required it can be split into two. */
				if( ( pxBlock->xBlockSize - xWantedSize ) > heapMINIMUM_BLOCK_SIZE )
     65c:	82 81       	ldd	r24, Z+2	; 0x02
     65e:	93 81       	ldd	r25, Z+3	; 0x03
     660:	82 1b       	sub	r24, r18
     662:	93 0b       	sbc	r25, r19
     664:	89 30       	cpi	r24, 0x09	; 9
     666:	91 05       	cpc	r25, r1
     668:	10 f1       	brcs	.+68     	; 0x6ae <pvPortMalloc+0xfa>
				{
					/* This block is to be split into two.  Create a new block
					following the number of bytes requested. The void cast is
					used to prevent byte alignment warnings from the compiler. */
					pxNewBlockLink = ( void * ) ( ( ( uint8_t * ) pxBlock ) + xWantedSize );
     66a:	bf 01       	movw	r22, r30
     66c:	62 0f       	add	r22, r18
     66e:	73 1f       	adc	r23, r19

					/* Calculate the sizes of two blocks split from the single
					block. */
					pxNewBlockLink->xBlockSize = pxBlock->xBlockSize - xWantedSize;
     670:	db 01       	movw	r26, r22
     672:	13 96       	adiw	r26, 0x03	; 3
     674:	9c 93       	st	X, r25
     676:	8e 93       	st	-X, r24
     678:	12 97       	sbiw	r26, 0x02	; 2
					pxBlock->xBlockSize = xWantedSize;
     67a:	33 83       	std	Z+3, r19	; 0x03
     67c:	22 83       	std	Z+2, r18	; 0x02

					/* Insert the new block into the list of free blocks. */
					prvInsertBlockIntoFreeList( ( pxNewBlockLink ) );
     67e:	12 96       	adiw	r26, 0x02	; 2
     680:	4d 91       	ld	r20, X+
     682:	5c 91       	ld	r21, X
     684:	13 97       	sbiw	r26, 0x03	; 3
     686:	89 eb       	ldi	r24, 0xB9	; 185
     688:	91 e0       	ldi	r25, 0x01	; 1
     68a:	01 c0       	rjmp	.+2      	; 0x68e <pvPortMalloc+0xda>
     68c:	cd 01       	movw	r24, r26
     68e:	ec 01       	movw	r28, r24
     690:	a8 81       	ld	r26, Y
     692:	b9 81       	ldd	r27, Y+1	; 0x01
     694:	12 96       	adiw	r26, 0x02	; 2
     696:	2d 91       	ld	r18, X+
     698:	3c 91       	ld	r19, X
     69a:	13 97       	sbiw	r26, 0x03	; 3
     69c:	24 17       	cp	r18, r20
     69e:	35 07       	cpc	r19, r21
     6a0:	a8 f3       	brcs	.-22     	; 0x68c <pvPortMalloc+0xd8>
     6a2:	eb 01       	movw	r28, r22
     6a4:	b9 83       	std	Y+1, r27	; 0x01
     6a6:	a8 83       	st	Y, r26
     6a8:	dc 01       	movw	r26, r24
     6aa:	6d 93       	st	X+, r22
     6ac:	7c 93       	st	X, r23
				}

				xFreeBytesRemaining -= pxBlock->xBlockSize;
     6ae:	80 91 00 01 	lds	r24, 0x0100
     6b2:	90 91 01 01 	lds	r25, 0x0101
     6b6:	22 81       	ldd	r18, Z+2	; 0x02
     6b8:	33 81       	ldd	r19, Z+3	; 0x03
     6ba:	82 1b       	sub	r24, r18
     6bc:	93 0b       	sbc	r25, r19
     6be:	90 93 01 01 	sts	0x0101, r25
     6c2:	80 93 00 01 	sts	0x0100, r24
     6c6:	08 c0       	rjmp	.+16     	; 0x6d8 <pvPortMalloc+0x124>

void *pvPortMalloc( size_t xWantedSize )
{
BlockLink_t *pxBlock, *pxPreviousBlock, *pxNewBlockLink;
static BaseType_t xHeapHasBeenInitialised = pdFALSE;
void *pvReturn = NULL;
     6c8:	00 e0       	ldi	r16, 0x00	; 0
     6ca:	10 e0       	ldi	r17, 0x00	; 0
     6cc:	05 c0       	rjmp	.+10     	; 0x6d8 <pvPortMalloc+0x124>
     6ce:	00 e0       	ldi	r16, 0x00	; 0
     6d0:	10 e0       	ldi	r17, 0x00	; 0
     6d2:	02 c0       	rjmp	.+4      	; 0x6d8 <pvPortMalloc+0x124>
     6d4:	00 e0       	ldi	r16, 0x00	; 0
     6d6:	10 e0       	ldi	r17, 0x00	; 0
			}
		}

		traceMALLOC( pvReturn, xWantedSize );
	}
	( void ) xTaskResumeAll();
     6d8:	0e 94 c8 08 	call	0x1190	; 0x1190 <xTaskResumeAll>
		}
	}
	#endif

	return pvReturn;
}
     6dc:	c8 01       	movw	r24, r16
     6de:	df 91       	pop	r29
     6e0:	cf 91       	pop	r28
     6e2:	1f 91       	pop	r17
     6e4:	0f 91       	pop	r16
     6e6:	08 95       	ret

000006e8 <vPortFree>:
/*-----------------------------------------------------------*/

void vPortFree( void *pv )
{
     6e8:	0f 93       	push	r16
     6ea:	1f 93       	push	r17
     6ec:	cf 93       	push	r28
     6ee:	df 93       	push	r29
uint8_t *puc = ( uint8_t * ) pv;
BlockLink_t *pxLink;

	if( pv != NULL )
     6f0:	00 97       	sbiw	r24, 0x00	; 0
     6f2:	41 f1       	breq	.+80     	; 0x744 <vPortFree+0x5c>
     6f4:	ec 01       	movw	r28, r24
	{
		/* The memory being freed will have an BlockLink_t structure immediately
		before it. */
		puc -= heapSTRUCT_SIZE;
     6f6:	8c 01       	movw	r16, r24
     6f8:	04 50       	subi	r16, 0x04	; 4
     6fa:	11 09       	sbc	r17, r1

		/* This unexpected casting is to keep some compilers from issuing
		byte alignment warnings. */
		pxLink = ( void * ) puc;

		vTaskSuspendAll();
     6fc:	0e 94 fb 07 	call	0xff6	; 0xff6 <vTaskSuspendAll>
		{
			/* Add this block to the list of free blocks. */
			prvInsertBlockIntoFreeList( ( ( BlockLink_t * ) pxLink ) );
     700:	f8 01       	movw	r30, r16
     702:	42 81       	ldd	r20, Z+2	; 0x02
     704:	53 81       	ldd	r21, Z+3	; 0x03
     706:	a9 eb       	ldi	r26, 0xB9	; 185
     708:	b1 e0       	ldi	r27, 0x01	; 1
     70a:	01 c0       	rjmp	.+2      	; 0x70e <vPortFree+0x26>
     70c:	df 01       	movw	r26, r30
     70e:	ed 91       	ld	r30, X+
     710:	fc 91       	ld	r31, X
     712:	11 97       	sbiw	r26, 0x01	; 1
     714:	22 81       	ldd	r18, Z+2	; 0x02
     716:	33 81       	ldd	r19, Z+3	; 0x03
     718:	24 17       	cp	r18, r20
     71a:	35 07       	cpc	r19, r21
     71c:	b8 f3       	brcs	.-18     	; 0x70c <vPortFree+0x24>
     71e:	24 97       	sbiw	r28, 0x04	; 4
     720:	f9 83       	std	Y+1, r31	; 0x01
     722:	e8 83       	st	Y, r30
     724:	0d 93       	st	X+, r16
     726:	1c 93       	st	X, r17
			xFreeBytesRemaining += pxLink->xBlockSize;
     728:	20 91 00 01 	lds	r18, 0x0100
     72c:	30 91 01 01 	lds	r19, 0x0101
     730:	8a 81       	ldd	r24, Y+2	; 0x02
     732:	9b 81       	ldd	r25, Y+3	; 0x03
     734:	82 0f       	add	r24, r18
     736:	93 1f       	adc	r25, r19
     738:	90 93 01 01 	sts	0x0101, r25
     73c:	80 93 00 01 	sts	0x0100, r24
			traceFREE( pv, pxLink->xBlockSize );
		}
		( void ) xTaskResumeAll();
     740:	0e 94 c8 08 	call	0x1190	; 0x1190 <xTaskResumeAll>
	}
}
     744:	df 91       	pop	r29
     746:	cf 91       	pop	r28
     748:	1f 91       	pop	r17
     74a:	0f 91       	pop	r16
     74c:	08 95       	ret

0000074e <prvCopyDataToQueue>:

#endif /* configUSE_TRACE_FACILITY */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
     74e:	1f 93       	push	r17
     750:	cf 93       	push	r28
     752:	df 93       	push	r29
     754:	ec 01       	movw	r28, r24
     756:	14 2f       	mov	r17, r20
BaseType_t xReturn = pdFALSE;

	if( pxQueue->uxItemSize == ( UBaseType_t ) 0 )
     758:	8c 8d       	ldd	r24, Y+28	; 0x1c
     75a:	88 23       	and	r24, r24
     75c:	e9 f1       	breq	.+122    	; 0x7d8 <prvCopyDataToQueue+0x8a>
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configUSE_MUTEXES */
	}
	else if( xPosition == queueSEND_TO_BACK )
     75e:	41 11       	cpse	r20, r1
     760:	17 c0       	rjmp	.+46     	; 0x790 <prvCopyDataToQueue+0x42>
	{
		( void ) memcpy( ( void * ) pxQueue->pcWriteTo, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports, plus previous logic ensures a null pointer can only be passed to memcpy() if the copy size is 0. */
     762:	48 2f       	mov	r20, r24
     764:	50 e0       	ldi	r21, 0x00	; 0
     766:	8c 81       	ldd	r24, Y+4	; 0x04
     768:	9d 81       	ldd	r25, Y+5	; 0x05
     76a:	0e 94 70 0b 	call	0x16e0	; 0x16e0 <memcpy>
		pxQueue->pcWriteTo += pxQueue->uxItemSize;
     76e:	2c 8d       	ldd	r18, Y+28	; 0x1c
     770:	8c 81       	ldd	r24, Y+4	; 0x04
     772:	9d 81       	ldd	r25, Y+5	; 0x05
     774:	82 0f       	add	r24, r18
     776:	91 1d       	adc	r25, r1
     778:	9d 83       	std	Y+5, r25	; 0x05
     77a:	8c 83       	std	Y+4, r24	; 0x04
		if( pxQueue->pcWriteTo >= pxQueue->pcTail ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     77c:	2a 81       	ldd	r18, Y+2	; 0x02
     77e:	3b 81       	ldd	r19, Y+3	; 0x03
     780:	82 17       	cp	r24, r18
     782:	93 07       	cpc	r25, r19
     784:	48 f1       	brcs	.+82     	; 0x7d8 <prvCopyDataToQueue+0x8a>
		{
			pxQueue->pcWriteTo = pxQueue->pcHead;
     786:	88 81       	ld	r24, Y
     788:	99 81       	ldd	r25, Y+1	; 0x01
     78a:	9d 83       	std	Y+5, r25	; 0x05
     78c:	8c 83       	std	Y+4, r24	; 0x04
     78e:	24 c0       	rjmp	.+72     	; 0x7d8 <prvCopyDataToQueue+0x8a>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	else
	{
		( void ) memcpy( ( void * ) pxQueue->u.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     790:	48 2f       	mov	r20, r24
     792:	50 e0       	ldi	r21, 0x00	; 0
     794:	8e 81       	ldd	r24, Y+6	; 0x06
     796:	9f 81       	ldd	r25, Y+7	; 0x07
     798:	0e 94 70 0b 	call	0x16e0	; 0x16e0 <memcpy>
		pxQueue->u.pcReadFrom -= pxQueue->uxItemSize;
     79c:	8c 8d       	ldd	r24, Y+28	; 0x1c
     79e:	90 e0       	ldi	r25, 0x00	; 0
     7a0:	91 95       	neg	r25
     7a2:	81 95       	neg	r24
     7a4:	91 09       	sbc	r25, r1
     7a6:	2e 81       	ldd	r18, Y+6	; 0x06
     7a8:	3f 81       	ldd	r19, Y+7	; 0x07
     7aa:	28 0f       	add	r18, r24
     7ac:	39 1f       	adc	r19, r25
     7ae:	3f 83       	std	Y+7, r19	; 0x07
     7b0:	2e 83       	std	Y+6, r18	; 0x06
		if( pxQueue->u.pcReadFrom < pxQueue->pcHead ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     7b2:	48 81       	ld	r20, Y
     7b4:	59 81       	ldd	r21, Y+1	; 0x01
     7b6:	24 17       	cp	r18, r20
     7b8:	35 07       	cpc	r19, r21
     7ba:	30 f4       	brcc	.+12     	; 0x7c8 <prvCopyDataToQueue+0x7a>
		{
			pxQueue->u.pcReadFrom = ( pxQueue->pcTail - pxQueue->uxItemSize );
     7bc:	2a 81       	ldd	r18, Y+2	; 0x02
     7be:	3b 81       	ldd	r19, Y+3	; 0x03
     7c0:	82 0f       	add	r24, r18
     7c2:	93 1f       	adc	r25, r19
     7c4:	9f 83       	std	Y+7, r25	; 0x07
     7c6:	8e 83       	std	Y+6, r24	; 0x06
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		if( xPosition == queueOVERWRITE )
     7c8:	12 30       	cpi	r17, 0x02	; 2
     7ca:	31 f4       	brne	.+12     	; 0x7d8 <prvCopyDataToQueue+0x8a>
		{
			if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
     7cc:	8a 8d       	ldd	r24, Y+26	; 0x1a
     7ce:	88 23       	and	r24, r24
     7d0:	19 f0       	breq	.+6      	; 0x7d8 <prvCopyDataToQueue+0x8a>
			{
				/* An item is not being added but overwritten, so subtract
				one from the recorded number of items in the queue so when
				one is added again below the number of recorded items remains
				correct. */
				--( pxQueue->uxMessagesWaiting );
     7d2:	8a 8d       	ldd	r24, Y+26	; 0x1a
     7d4:	81 50       	subi	r24, 0x01	; 1
     7d6:	8a 8f       	std	Y+26, r24	; 0x1a
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}

	++( pxQueue->uxMessagesWaiting );
     7d8:	8a 8d       	ldd	r24, Y+26	; 0x1a
     7da:	8f 5f       	subi	r24, 0xFF	; 255
     7dc:	8a 8f       	std	Y+26, r24	; 0x1a

	return xReturn;
}
     7de:	80 e0       	ldi	r24, 0x00	; 0
     7e0:	df 91       	pop	r29
     7e2:	cf 91       	pop	r28
     7e4:	1f 91       	pop	r17
     7e6:	08 95       	ret

000007e8 <prvNotifyQueueSetContainer>:
/*-----------------------------------------------------------*/

#if ( configUSE_QUEUE_SETS == 1 )

	static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue, const BaseType_t xCopyPosition )
	{
     7e8:	ff 92       	push	r15
     7ea:	0f 93       	push	r16
     7ec:	1f 93       	push	r17
     7ee:	cf 93       	push	r28
     7f0:	df 93       	push	r29
     7f2:	00 d0       	rcall	.+0      	; 0x7f4 <prvNotifyQueueSetContainer+0xc>
     7f4:	cd b7       	in	r28, 0x3d	; 61
     7f6:	de b7       	in	r29, 0x3e	; 62
     7f8:	9a 83       	std	Y+2, r25	; 0x02
     7fa:	89 83       	std	Y+1, r24	; 0x01
	Queue_t *pxQueueSetContainer = pxQueue->pxQueueSetContainer;
     7fc:	fc 01       	movw	r30, r24
     7fe:	07 8d       	ldd	r16, Z+31	; 0x1f
     800:	10 a1       	ldd	r17, Z+32	; 0x20
		/* This function must be called form a critical section. */

		configASSERT( pxQueueSetContainer );
		configASSERT( pxQueueSetContainer->uxMessagesWaiting < pxQueueSetContainer->uxLength );

		if( pxQueueSetContainer->uxMessagesWaiting < pxQueueSetContainer->uxLength )
     802:	f8 01       	movw	r30, r16
     804:	92 8d       	ldd	r25, Z+26	; 0x1a
     806:	83 8d       	ldd	r24, Z+27	; 0x1b
     808:	98 17       	cp	r25, r24
     80a:	e8 f4       	brcc	.+58     	; 0x846 <prvNotifyQueueSetContainer+0x5e>
     80c:	46 2f       	mov	r20, r22
		{
			traceQUEUE_SEND( pxQueueSetContainer );

			/* The data copied is the handle of the queue that contains data. */
			xReturn = prvCopyDataToQueue( pxQueueSetContainer, &pxQueue, xCopyPosition );
     80e:	be 01       	movw	r22, r28
     810:	6f 5f       	subi	r22, 0xFF	; 255
     812:	7f 4f       	sbci	r23, 0xFF	; 255
     814:	c8 01       	movw	r24, r16
     816:	0e 94 a7 03 	call	0x74e	; 0x74e <prvCopyDataToQueue>
     81a:	f8 2e       	mov	r15, r24

			if( pxQueueSetContainer->xTxLock == queueUNLOCKED )
     81c:	f8 01       	movw	r30, r16
     81e:	86 8d       	ldd	r24, Z+30	; 0x1e
     820:	8f 3f       	cpi	r24, 0xFF	; 255
     822:	61 f4       	brne	.+24     	; 0x83c <prvNotifyQueueSetContainer+0x54>
			{
				if( listLIST_IS_EMPTY( &( pxQueueSetContainer->xTasksWaitingToReceive ) ) == pdFALSE )
     824:	81 89       	ldd	r24, Z+17	; 0x11
     826:	88 23       	and	r24, r24
     828:	79 f0       	breq	.+30     	; 0x848 <prvNotifyQueueSetContainer+0x60>
				{
					if( xTaskRemoveFromEventList( &( pxQueueSetContainer->xTasksWaitingToReceive ) ) != pdFALSE )
     82a:	c8 01       	movw	r24, r16
     82c:	41 96       	adiw	r24, 0x11	; 17
     82e:	0e 94 63 0a 	call	0x14c6	; 0x14c6 <xTaskRemoveFromEventList>
     832:	88 23       	and	r24, r24
     834:	49 f0       	breq	.+18     	; 0x848 <prvNotifyQueueSetContainer+0x60>
					{
						/* The task waiting has a higher priority. */
						xReturn = pdTRUE;
     836:	ff 24       	eor	r15, r15
     838:	f3 94       	inc	r15
     83a:	06 c0       	rjmp	.+12     	; 0x848 <prvNotifyQueueSetContainer+0x60>
					mtCOVERAGE_TEST_MARKER();
				}
			}
			else
			{
				( pxQueueSetContainer->xTxLock )++;
     83c:	f8 01       	movw	r30, r16
     83e:	86 8d       	ldd	r24, Z+30	; 0x1e
     840:	8f 5f       	subi	r24, 0xFF	; 255
     842:	86 8f       	std	Z+30, r24	; 0x1e
     844:	01 c0       	rjmp	.+2      	; 0x848 <prvNotifyQueueSetContainer+0x60>
#if ( configUSE_QUEUE_SETS == 1 )

	static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue, const BaseType_t xCopyPosition )
	{
	Queue_t *pxQueueSetContainer = pxQueue->pxQueueSetContainer;
	BaseType_t xReturn = pdFALSE;
     846:	f1 2c       	mov	r15, r1
		{
			mtCOVERAGE_TEST_MARKER();
		}

		return xReturn;
	}
     848:	8f 2d       	mov	r24, r15
     84a:	0f 90       	pop	r0
     84c:	0f 90       	pop	r0
     84e:	df 91       	pop	r29
     850:	cf 91       	pop	r28
     852:	1f 91       	pop	r17
     854:	0f 91       	pop	r16
     856:	ff 90       	pop	r15
     858:	08 95       	ret

0000085a <prvCopyDataFromQueue>:
	return xReturn;
}
/*-----------------------------------------------------------*/

static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer )
{
     85a:	fc 01       	movw	r30, r24
	if( pxQueue->uxItemSize != ( UBaseType_t ) 0 )
     85c:	44 8d       	ldd	r20, Z+28	; 0x1c
     85e:	44 23       	and	r20, r20
     860:	a9 f0       	breq	.+42     	; 0x88c <prvCopyDataFromQueue+0x32>
	{
		pxQueue->u.pcReadFrom += pxQueue->uxItemSize;
     862:	50 e0       	ldi	r21, 0x00	; 0
     864:	26 81       	ldd	r18, Z+6	; 0x06
     866:	37 81       	ldd	r19, Z+7	; 0x07
     868:	24 0f       	add	r18, r20
     86a:	35 1f       	adc	r19, r21
     86c:	37 83       	std	Z+7, r19	; 0x07
     86e:	26 83       	std	Z+6, r18	; 0x06
		if( pxQueue->u.pcReadFrom >= pxQueue->pcTail ) /*lint !e946 MISRA exception justified as use of the relational operator is the cleanest solutions. */
     870:	82 81       	ldd	r24, Z+2	; 0x02
     872:	93 81       	ldd	r25, Z+3	; 0x03
     874:	28 17       	cp	r18, r24
     876:	39 07       	cpc	r19, r25
     878:	20 f0       	brcs	.+8      	; 0x882 <prvCopyDataFromQueue+0x28>
		{
			pxQueue->u.pcReadFrom = pxQueue->pcHead;
     87a:	80 81       	ld	r24, Z
     87c:	91 81       	ldd	r25, Z+1	; 0x01
     87e:	97 83       	std	Z+7, r25	; 0x07
     880:	86 83       	std	Z+6, r24	; 0x06
     882:	cb 01       	movw	r24, r22
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
		( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.pcReadFrom, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports.  Also previous logic ensures a null pointer can only be passed to memcpy() when the count is 0. */
     884:	66 81       	ldd	r22, Z+6	; 0x06
     886:	77 81       	ldd	r23, Z+7	; 0x07
     888:	0e 94 70 0b 	call	0x16e0	; 0x16e0 <memcpy>
     88c:	08 95       	ret

0000088e <prvUnlockQueue>:
	}
}
/*-----------------------------------------------------------*/

static void prvUnlockQueue( Queue_t * const pxQueue )
{
     88e:	0f 93       	push	r16
     890:	1f 93       	push	r17
     892:	cf 93       	push	r28
     894:	df 93       	push	r29
     896:	ec 01       	movw	r28, r24

	/* The lock counts contains the number of extra data items placed or
	removed from the queue while the queue was locked.  When a queue is
	locked items can be added or removed, but the event lists cannot be
	updated. */
	taskENTER_CRITICAL();
     898:	0f b6       	in	r0, 0x3f	; 63
     89a:	f8 94       	cli
     89c:	0f 92       	push	r0
	{
		/* See if data was added to the queue while it was locked. */
		while( pxQueue->xTxLock > queueLOCKED_UNMODIFIED )
     89e:	8e 8d       	ldd	r24, Y+30	; 0x1e
     8a0:	18 16       	cp	r1, r24
     8a2:	fc f4       	brge	.+62     	; 0x8e2 <prvUnlockQueue+0x54>
				{
					/* Tasks that are removed from the event list will get added to
					the pending ready list as the scheduler is still suspended. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     8a4:	8e 01       	movw	r16, r28
     8a6:	0f 5e       	subi	r16, 0xEF	; 239
     8a8:	1f 4f       	sbci	r17, 0xFF	; 255
		{
			/* Data was posted while the queue was locked.  Are any tasks
			blocked waiting for data to become available? */
			#if ( configUSE_QUEUE_SETS == 1 )
			{
				if( pxQueue->pxQueueSetContainer != NULL )
     8aa:	2f 8d       	ldd	r18, Y+31	; 0x1f
     8ac:	38 a1       	ldd	r19, Y+32	; 0x20
     8ae:	23 2b       	or	r18, r19
     8b0:	49 f0       	breq	.+18     	; 0x8c4 <prvUnlockQueue+0x36>
				{
					if( prvNotifyQueueSetContainer( pxQueue, queueSEND_TO_BACK ) == pdTRUE )
     8b2:	60 e0       	ldi	r22, 0x00	; 0
     8b4:	ce 01       	movw	r24, r28
     8b6:	0e 94 f4 03 	call	0x7e8	; 0x7e8 <prvNotifyQueueSetContainer>
     8ba:	81 30       	cpi	r24, 0x01	; 1
     8bc:	61 f4       	brne	.+24     	; 0x8d6 <prvUnlockQueue+0x48>
					{
						/* The queue is a member of a queue set, and posting to
						the queue set caused a higher priority task to unblock.
						A context switch is required. */
						vTaskMissedYield();
     8be:	0e 94 ef 0a 	call	0x15de	; 0x15de <vTaskMissedYield>
     8c2:	09 c0       	rjmp	.+18     	; 0x8d6 <prvUnlockQueue+0x48>
				}
				else
				{
					/* Tasks that are removed from the event list will get added to
					the pending ready list as the scheduler is still suspended. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     8c4:	99 89       	ldd	r25, Y+17	; 0x11
     8c6:	99 23       	and	r25, r25
     8c8:	61 f0       	breq	.+24     	; 0x8e2 <prvUnlockQueue+0x54>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     8ca:	c8 01       	movw	r24, r16
     8cc:	0e 94 63 0a 	call	0x14c6	; 0x14c6 <xTaskRemoveFromEventList>
     8d0:	81 11       	cpse	r24, r1
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							vTaskMissedYield();
     8d2:	0e 94 ef 0a 	call	0x15de	; 0x15de <vTaskMissedYield>
					break;
				}
			}
			#endif /* configUSE_QUEUE_SETS */

			--( pxQueue->xTxLock );
     8d6:	9e 8d       	ldd	r25, Y+30	; 0x1e
     8d8:	91 50       	subi	r25, 0x01	; 1
     8da:	9e 8f       	std	Y+30, r25	; 0x1e
	locked items can be added or removed, but the event lists cannot be
	updated. */
	taskENTER_CRITICAL();
	{
		/* See if data was added to the queue while it was locked. */
		while( pxQueue->xTxLock > queueLOCKED_UNMODIFIED )
     8dc:	9e 8d       	ldd	r25, Y+30	; 0x1e
     8de:	19 16       	cp	r1, r25
     8e0:	24 f3       	brlt	.-56     	; 0x8aa <prvUnlockQueue+0x1c>
			#endif /* configUSE_QUEUE_SETS */

			--( pxQueue->xTxLock );
		}

		pxQueue->xTxLock = queueUNLOCKED;
     8e2:	8f ef       	ldi	r24, 0xFF	; 255
     8e4:	8e 8f       	std	Y+30, r24	; 0x1e
	}
	taskEXIT_CRITICAL();
     8e6:	0f 90       	pop	r0
     8e8:	0f be       	out	0x3f, r0	; 63

	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
     8ea:	0f b6       	in	r0, 0x3f	; 63
     8ec:	f8 94       	cli
     8ee:	0f 92       	push	r0
	{
		while( pxQueue->xRxLock > queueLOCKED_UNMODIFIED )
     8f0:	8d 8d       	ldd	r24, Y+29	; 0x1d
     8f2:	18 16       	cp	r1, r24
     8f4:	bc f4       	brge	.+46     	; 0x924 <__stack+0x25>
		{
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     8f6:	88 85       	ldd	r24, Y+8	; 0x08
     8f8:	81 11       	cpse	r24, r1
     8fa:	05 c0       	rjmp	.+10     	; 0x906 <__stack+0x7>
     8fc:	13 c0       	rjmp	.+38     	; 0x924 <__stack+0x25>
     8fe:	98 85       	ldd	r25, Y+8	; 0x08
     900:	91 11       	cpse	r25, r1
     902:	04 c0       	rjmp	.+8      	; 0x90c <__stack+0xd>
     904:	0f c0       	rjmp	.+30     	; 0x924 <__stack+0x25>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     906:	8e 01       	movw	r16, r28
     908:	08 5f       	subi	r16, 0xF8	; 248
     90a:	1f 4f       	sbci	r17, 0xFF	; 255
     90c:	c8 01       	movw	r24, r16
     90e:	0e 94 63 0a 	call	0x14c6	; 0x14c6 <xTaskRemoveFromEventList>
     912:	81 11       	cpse	r24, r1
				{
					vTaskMissedYield();
     914:	0e 94 ef 0a 	call	0x15de	; 0x15de <vTaskMissedYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				--( pxQueue->xRxLock );
     918:	9d 8d       	ldd	r25, Y+29	; 0x1d
     91a:	91 50       	subi	r25, 0x01	; 1
     91c:	9d 8f       	std	Y+29, r25	; 0x1d
	taskEXIT_CRITICAL();

	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
	{
		while( pxQueue->xRxLock > queueLOCKED_UNMODIFIED )
     91e:	9d 8d       	ldd	r25, Y+29	; 0x1d
     920:	19 16       	cp	r1, r25
     922:	6c f3       	brlt	.-38     	; 0x8fe <prvUnlockQueue+0x70>
			{
				break;
			}
		}

		pxQueue->xRxLock = queueUNLOCKED;
     924:	8f ef       	ldi	r24, 0xFF	; 255
     926:	8d 8f       	std	Y+29, r24	; 0x1d
	}
	taskEXIT_CRITICAL();
     928:	0f 90       	pop	r0
     92a:	0f be       	out	0x3f, r0	; 63
}
     92c:	df 91       	pop	r29
     92e:	cf 91       	pop	r28
     930:	1f 91       	pop	r17
     932:	0f 91       	pop	r16
     934:	08 95       	ret

00000936 <xQueueGenericReset>:
	}														\
	taskEXIT_CRITICAL()
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue )
{
     936:	cf 93       	push	r28
     938:	df 93       	push	r29
     93a:	ec 01       	movw	r28, r24
Queue_t * const pxQueue = ( Queue_t * ) xQueue;

	configASSERT( pxQueue );

	taskENTER_CRITICAL();
     93c:	0f b6       	in	r0, 0x3f	; 63
     93e:	f8 94       	cli
     940:	0f 92       	push	r0
	{
		pxQueue->pcTail = pxQueue->pcHead + ( pxQueue->uxLength * pxQueue->uxItemSize );
     942:	48 81       	ld	r20, Y
     944:	59 81       	ldd	r21, Y+1	; 0x01
     946:	2c 8d       	ldd	r18, Y+28	; 0x1c
     948:	30 e0       	ldi	r19, 0x00	; 0
     94a:	7b 8d       	ldd	r23, Y+27	; 0x1b
     94c:	72 9f       	mul	r23, r18
     94e:	c0 01       	movw	r24, r0
     950:	73 9f       	mul	r23, r19
     952:	90 0d       	add	r25, r0
     954:	11 24       	eor	r1, r1
     956:	fa 01       	movw	r30, r20
     958:	e8 0f       	add	r30, r24
     95a:	f9 1f       	adc	r31, r25
     95c:	fb 83       	std	Y+3, r31	; 0x03
     95e:	ea 83       	std	Y+2, r30	; 0x02
		pxQueue->uxMessagesWaiting = ( UBaseType_t ) 0U;
     960:	1a 8e       	std	Y+26, r1	; 0x1a
		pxQueue->pcWriteTo = pxQueue->pcHead;
     962:	5d 83       	std	Y+5, r21	; 0x05
     964:	4c 83       	std	Y+4, r20	; 0x04
		pxQueue->u.pcReadFrom = pxQueue->pcHead + ( ( pxQueue->uxLength - ( UBaseType_t ) 1U ) * pxQueue->uxItemSize );
     966:	82 1b       	sub	r24, r18
     968:	93 0b       	sbc	r25, r19
     96a:	84 0f       	add	r24, r20
     96c:	95 1f       	adc	r25, r21
     96e:	9f 83       	std	Y+7, r25	; 0x07
     970:	8e 83       	std	Y+6, r24	; 0x06
		pxQueue->xRxLock = queueUNLOCKED;
     972:	8f ef       	ldi	r24, 0xFF	; 255
     974:	8d 8f       	std	Y+29, r24	; 0x1d
		pxQueue->xTxLock = queueUNLOCKED;
     976:	8e 8f       	std	Y+30, r24	; 0x1e

		if( xNewQueue == pdFALSE )
     978:	61 11       	cpse	r22, r1
     97a:	0c c0       	rjmp	.+24     	; 0x994 <xQueueGenericReset+0x5e>
			/* If there are tasks blocked waiting to read from the queue, then
			the tasks will remain blocked as after this function exits the queue
			will still be empty.  If there are tasks blocked waiting to write to
			the queue, then one should be unblocked as after this function exits
			it will be possible to write to it. */
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     97c:	88 85       	ldd	r24, Y+8	; 0x08
     97e:	88 23       	and	r24, r24
     980:	89 f0       	breq	.+34     	; 0x9a4 <xQueueGenericReset+0x6e>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) == pdTRUE )
     982:	ce 01       	movw	r24, r28
     984:	08 96       	adiw	r24, 0x08	; 8
     986:	0e 94 63 0a 	call	0x14c6	; 0x14c6 <xTaskRemoveFromEventList>
     98a:	81 30       	cpi	r24, 0x01	; 1
     98c:	59 f4       	brne	.+22     	; 0x9a4 <xQueueGenericReset+0x6e>
				{
					queueYIELD_IF_USING_PREEMPTION();
     98e:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>
     992:	08 c0       	rjmp	.+16     	; 0x9a4 <xQueueGenericReset+0x6e>
			}
		}
		else
		{
			/* Ensure the event queues start in the correct state. */
			vListInitialise( &( pxQueue->xTasksWaitingToSend ) );
     994:	ce 01       	movw	r24, r28
     996:	08 96       	adiw	r24, 0x08	; 8
     998:	0e 94 e8 00 	call	0x1d0	; 0x1d0 <vListInitialise>
			vListInitialise( &( pxQueue->xTasksWaitingToReceive ) );
     99c:	ce 01       	movw	r24, r28
     99e:	41 96       	adiw	r24, 0x11	; 17
     9a0:	0e 94 e8 00 	call	0x1d0	; 0x1d0 <vListInitialise>
		}
	}
	taskEXIT_CRITICAL();
     9a4:	0f 90       	pop	r0
     9a6:	0f be       	out	0x3f, r0	; 63

	/* A value is returned for calling semantic consistency with previous
	versions. */
	return pdPASS;
}
     9a8:	81 e0       	ldi	r24, 0x01	; 1
     9aa:	df 91       	pop	r29
     9ac:	cf 91       	pop	r28
     9ae:	08 95       	ret

000009b0 <xQueueGenericCreate>:
/*-----------------------------------------------------------*/

QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType )
{
     9b0:	0f 93       	push	r16
     9b2:	1f 93       	push	r17
     9b4:	cf 93       	push	r28
     9b6:	df 93       	push	r29
     9b8:	08 2f       	mov	r16, r24
     9ba:	16 2f       	mov	r17, r22
	configUSE_TRACE_FACILITY not be set to 1. */
	( void ) ucQueueType;

	configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

	if( uxItemSize == ( UBaseType_t ) 0 )
     9bc:	66 23       	and	r22, r22
     9be:	c9 f0       	breq	.+50     	; 0x9f2 <xQueueGenericCreate+0x42>
	}
	else
	{
		/* The queue is one byte longer than asked for to make wrap checking
		easier/faster. */
		xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ) + ( size_t ) 1; /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     9c0:	86 9f       	mul	r24, r22
     9c2:	c0 01       	movw	r24, r0
     9c4:	11 24       	eor	r1, r1
	}

	/* Allocate the new queue structure and storage area. */
	pcAllocatedBuffer = ( int8_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes );
     9c6:	82 96       	adiw	r24, 0x22	; 34
     9c8:	0e 94 da 02 	call	0x5b4	; 0x5b4 <pvPortMalloc>
     9cc:	ec 01       	movw	r28, r24

	if( pcAllocatedBuffer != NULL )
     9ce:	00 97       	sbiw	r24, 0x00	; 0
     9d0:	21 f4       	brne	.+8      	; 0x9da <xQueueGenericCreate+0x2a>
     9d2:	16 c0       	rjmp	.+44     	; 0xa00 <xQueueGenericCreate+0x50>
		{
			/* No RAM was allocated for the queue storage area, but PC head
			cannot be set to NULL because NULL is used as a key to say the queue
			is used as a mutex.  Therefore just set pcHead to point to the queue
			as a benign value that is known to be within the memory map. */
			pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
     9d4:	d9 83       	std	Y+1, r29	; 0x01
     9d6:	c8 83       	st	Y, r28
     9d8:	03 c0       	rjmp	.+6      	; 0x9e0 <xQueueGenericCreate+0x30>
		}
		else
		{
			/* Jump past the queue structure to find the location of the queue
			storage area - adding the padding bytes to get a better alignment. */
			pxNewQueue->pcHead = pcAllocatedBuffer + sizeof( Queue_t );
     9da:	81 96       	adiw	r24, 0x21	; 33
     9dc:	99 83       	std	Y+1, r25	; 0x01
     9de:	88 83       	st	Y, r24
		}

		/* Initialise the queue members as described above where the queue type
		is defined. */
		pxNewQueue->uxLength = uxQueueLength;
     9e0:	0b 8f       	std	Y+27, r16	; 0x1b
		pxNewQueue->uxItemSize = uxItemSize;
     9e2:	1c 8f       	std	Y+28, r17	; 0x1c
		( void ) xQueueGenericReset( pxNewQueue, pdTRUE );
     9e4:	61 e0       	ldi	r22, 0x01	; 1
     9e6:	ce 01       	movw	r24, r28
     9e8:	0e 94 9b 04 	call	0x936	; 0x936 <xQueueGenericReset>
		}
		#endif /* configUSE_TRACE_FACILITY */

		#if( configUSE_QUEUE_SETS == 1 )
		{
			pxNewQueue->pxQueueSetContainer = NULL;
     9ec:	18 a2       	std	Y+32, r1	; 0x20
     9ee:	1f 8e       	std	Y+31, r1	; 0x1f
     9f0:	07 c0       	rjmp	.+14     	; 0xa00 <xQueueGenericCreate+0x50>
		easier/faster. */
		xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ) + ( size_t ) 1; /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
	}

	/* Allocate the new queue structure and storage area. */
	pcAllocatedBuffer = ( int8_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes );
     9f2:	81 e2       	ldi	r24, 0x21	; 33
     9f4:	90 e0       	ldi	r25, 0x00	; 0
     9f6:	0e 94 da 02 	call	0x5b4	; 0x5b4 <pvPortMalloc>
     9fa:	ec 01       	movw	r28, r24

	if( pcAllocatedBuffer != NULL )
     9fc:	89 2b       	or	r24, r25
     9fe:	51 f7       	brne	.-44     	; 0x9d4 <xQueueGenericCreate+0x24>
	}

	configASSERT( xReturn );

	return xReturn;
}
     a00:	ce 01       	movw	r24, r28
     a02:	df 91       	pop	r29
     a04:	cf 91       	pop	r28
     a06:	1f 91       	pop	r17
     a08:	0f 91       	pop	r16
     a0a:	08 95       	ret

00000a0c <xQueueGenericSend>:

#endif /* configUSE_COUNTING_SEMAPHORES */
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition )
{
     a0c:	9f 92       	push	r9
     a0e:	af 92       	push	r10
     a10:	bf 92       	push	r11
     a12:	cf 92       	push	r12
     a14:	df 92       	push	r13
     a16:	ef 92       	push	r14
     a18:	ff 92       	push	r15
     a1a:	0f 93       	push	r16
     a1c:	1f 93       	push	r17
     a1e:	cf 93       	push	r28
     a20:	df 93       	push	r29
     a22:	00 d0       	rcall	.+0      	; 0xa24 <xQueueGenericSend+0x18>
     a24:	00 d0       	rcall	.+0      	; 0xa26 <xQueueGenericSend+0x1a>
     a26:	1f 92       	push	r1
     a28:	cd b7       	in	r28, 0x3d	; 61
     a2a:	de b7       	in	r29, 0x3e	; 62
     a2c:	8c 01       	movw	r16, r24
     a2e:	6b 01       	movw	r12, r22
     a30:	5d 83       	std	Y+5, r21	; 0x05
     a32:	4c 83       	std	Y+4, r20	; 0x04
     a34:	a2 2e       	mov	r10, r18
BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;
     a36:	b1 2c       	mov	r11, r1
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
     a38:	99 24       	eor	r9, r9
     a3a:	93 94       	inc	r9
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
     a3c:	7c 01       	movw	r14, r24
     a3e:	88 e0       	ldi	r24, 0x08	; 8
     a40:	e8 0e       	add	r14, r24
     a42:	f1 1c       	adc	r15, r1
	/* This function relaxes the coding standard somewhat to allow return
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
     a44:	0f b6       	in	r0, 0x3f	; 63
     a46:	f8 94       	cli
     a48:	0f 92       	push	r0
		{
			/* Is there room on the queue now?  The running task must be the
			highest priority task wanting to access the queue.  If the head item
			in the queue is to be overwritten then it does not matter if the
			queue is full. */
			if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
     a4a:	f8 01       	movw	r30, r16
     a4c:	32 8d       	ldd	r19, Z+26	; 0x1a
     a4e:	93 8d       	ldd	r25, Z+27	; 0x1b
     a50:	39 17       	cp	r19, r25
     a52:	18 f0       	brcs	.+6      	; 0xa5a <xQueueGenericSend+0x4e>
     a54:	f2 e0       	ldi	r31, 0x02	; 2
     a56:	af 12       	cpse	r10, r31
     a58:	27 c0       	rjmp	.+78     	; 0xaa8 <xQueueGenericSend+0x9c>
			{
				traceQUEUE_SEND( pxQueue );
				xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
     a5a:	4a 2d       	mov	r20, r10
     a5c:	b6 01       	movw	r22, r12
     a5e:	c8 01       	movw	r24, r16
     a60:	0e 94 a7 03 	call	0x74e	; 0x74e <prvCopyDataToQueue>

				#if ( configUSE_QUEUE_SETS == 1 )
				{
					if( pxQueue->pxQueueSetContainer != NULL )
     a64:	f8 01       	movw	r30, r16
     a66:	27 8d       	ldd	r18, Z+31	; 0x1f
     a68:	30 a1       	ldd	r19, Z+32	; 0x20
     a6a:	23 2b       	or	r18, r19
     a6c:	49 f0       	breq	.+18     	; 0xa80 <xQueueGenericSend+0x74>
					{
						if( prvNotifyQueueSetContainer( pxQueue, xCopyPosition ) == pdTRUE )
     a6e:	6a 2d       	mov	r22, r10
     a70:	c8 01       	movw	r24, r16
     a72:	0e 94 f4 03 	call	0x7e8	; 0x7e8 <prvNotifyQueueSetContainer>
     a76:	81 30       	cpi	r24, 0x01	; 1
     a78:	99 f4       	brne	.+38     	; 0xaa0 <xQueueGenericSend+0x94>
						{
							/* The queue is a member of a queue set, and posting
							to the queue set caused a higher priority task to
							unblock. A context switch is required. */
							queueYIELD_IF_USING_PREEMPTION();
     a7a:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>
     a7e:	10 c0       	rjmp	.+32     	; 0xaa0 <xQueueGenericSend+0x94>
					}
					else
					{
						/* If there was a task waiting for data to arrive on the
						queue then unblock it now. */
						if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     a80:	f8 01       	movw	r30, r16
     a82:	91 89       	ldd	r25, Z+17	; 0x11
     a84:	99 23       	and	r25, r25
     a86:	49 f0       	breq	.+18     	; 0xa9a <xQueueGenericSend+0x8e>
						{
							if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) == pdTRUE )
     a88:	c8 01       	movw	r24, r16
     a8a:	41 96       	adiw	r24, 0x11	; 17
     a8c:	0e 94 63 0a 	call	0x14c6	; 0x14c6 <xTaskRemoveFromEventList>
     a90:	81 30       	cpi	r24, 0x01	; 1
     a92:	31 f4       	brne	.+12     	; 0xaa0 <xQueueGenericSend+0x94>
							{
								/* The unblocked task has a priority higher than
								our own so yield immediately.  Yes it is ok to
								do this from within the critical section - the
								kernel takes care of that. */
								queueYIELD_IF_USING_PREEMPTION();
     a94:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>
     a98:	03 c0       	rjmp	.+6      	; 0xaa0 <xQueueGenericSend+0x94>
							else
							{
								mtCOVERAGE_TEST_MARKER();
							}
						}
						else if( xYieldRequired != pdFALSE )
     a9a:	81 11       	cpse	r24, r1
						{
							/* This path is a special case that will only get
							executed if the task was holding multiple mutexes
							and the mutexes were given back in an order that is
							different to that in which they were taken. */
							queueYIELD_IF_USING_PREEMPTION();
     a9c:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif /* configUSE_QUEUE_SETS */

				taskEXIT_CRITICAL();
     aa0:	0f 90       	pop	r0
     aa2:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
     aa4:	81 e0       	ldi	r24, 0x01	; 1
     aa6:	50 c0       	rjmp	.+160    	; 0xb48 <xQueueGenericSend+0x13c>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
     aa8:	ec 81       	ldd	r30, Y+4	; 0x04
     aaa:	fd 81       	ldd	r31, Y+5	; 0x05
     aac:	ef 2b       	or	r30, r31
     aae:	21 f4       	brne	.+8      	; 0xab8 <xQueueGenericSend+0xac>
				{
					/* The queue was full and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
     ab0:	0f 90       	pop	r0
     ab2:	0f be       	out	0x3f, r0	; 63

					/* Return to the original privilege level before exiting
					the function. */
					traceQUEUE_SEND_FAILED( pxQueue );
					return errQUEUE_FULL;
     ab4:	80 e0       	ldi	r24, 0x00	; 0
     ab6:	48 c0       	rjmp	.+144    	; 0xb48 <xQueueGenericSend+0x13c>
				}
				else if( xEntryTimeSet == pdFALSE )
     ab8:	b1 10       	cpse	r11, r1
     aba:	05 c0       	rjmp	.+10     	; 0xac6 <xQueueGenericSend+0xba>
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
     abc:	ce 01       	movw	r24, r28
     abe:	01 96       	adiw	r24, 0x01	; 1
     ac0:	0e 94 ab 0a 	call	0x1556	; 0x1556 <vTaskSetTimeOutState>
					xEntryTimeSet = pdTRUE;
     ac4:	b9 2c       	mov	r11, r9
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
     ac6:	0f 90       	pop	r0
     ac8:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
     aca:	0e 94 fb 07 	call	0xff6	; 0xff6 <vTaskSuspendAll>
		prvLockQueue( pxQueue );
     ace:	0f b6       	in	r0, 0x3f	; 63
     ad0:	f8 94       	cli
     ad2:	0f 92       	push	r0
     ad4:	f8 01       	movw	r30, r16
     ad6:	85 8d       	ldd	r24, Z+29	; 0x1d
     ad8:	8f 3f       	cpi	r24, 0xFF	; 255
     ada:	09 f4       	brne	.+2      	; 0xade <xQueueGenericSend+0xd2>
     adc:	15 8e       	std	Z+29, r1	; 0x1d
     ade:	f8 01       	movw	r30, r16
     ae0:	86 8d       	ldd	r24, Z+30	; 0x1e
     ae2:	8f 3f       	cpi	r24, 0xFF	; 255
     ae4:	09 f4       	brne	.+2      	; 0xae8 <xQueueGenericSend+0xdc>
     ae6:	16 8e       	std	Z+30, r1	; 0x1e
     ae8:	0f 90       	pop	r0
     aea:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
     aec:	be 01       	movw	r22, r28
     aee:	6c 5f       	subi	r22, 0xFC	; 252
     af0:	7f 4f       	sbci	r23, 0xFF	; 255
     af2:	ce 01       	movw	r24, r28
     af4:	01 96       	adiw	r24, 0x01	; 1
     af6:	0e 94 b6 0a 	call	0x156c	; 0x156c <xTaskCheckForTimeOut>
     afa:	81 11       	cpse	r24, r1
     afc:	1f c0       	rjmp	.+62     	; 0xb3c <xQueueGenericSend+0x130>

static BaseType_t prvIsQueueFull( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
     afe:	0f b6       	in	r0, 0x3f	; 63
     b00:	f8 94       	cli
     b02:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
     b04:	f8 01       	movw	r30, r16
     b06:	92 8d       	ldd	r25, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     b08:	0f 90       	pop	r0
     b0a:	0f be       	out	0x3f, r0	; 63
		prvLockQueue( pxQueue );

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
     b0c:	83 8d       	ldd	r24, Z+27	; 0x1b
     b0e:	98 13       	cpse	r25, r24
     b10:	0f c0       	rjmp	.+30     	; 0xb30 <xQueueGenericSend+0x124>
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
     b12:	6c 81       	ldd	r22, Y+4	; 0x04
     b14:	7d 81       	ldd	r23, Y+5	; 0x05
     b16:	c7 01       	movw	r24, r14
     b18:	0e 94 36 0a 	call	0x146c	; 0x146c <vTaskPlaceOnEventList>
				/* Unlocking the queue means queue events can effect the
				event list.  It is possible	that interrupts occurring now
				remove this task from the event	list again - but as the
				scheduler is suspended the task will go onto the pending
				ready last instead of the actual ready list. */
				prvUnlockQueue( pxQueue );
     b1c:	c8 01       	movw	r24, r16
     b1e:	0e 94 47 04 	call	0x88e	; 0x88e <prvUnlockQueue>
				/* Resuming the scheduler will move tasks from the pending
				ready list into the ready list - so it is feasible that this
				task is already in a ready list before it yields - in which
				case the yield will not cause a context switch unless there
				is also a higher priority task in the pending ready list. */
				if( xTaskResumeAll() == pdFALSE )
     b22:	0e 94 c8 08 	call	0x1190	; 0x1190 <xTaskResumeAll>
     b26:	81 11       	cpse	r24, r1
     b28:	8d cf       	rjmp	.-230    	; 0xa44 <xQueueGenericSend+0x38>
				{
					portYIELD_WITHIN_API();
     b2a:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>
     b2e:	8a cf       	rjmp	.-236    	; 0xa44 <xQueueGenericSend+0x38>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
     b30:	c8 01       	movw	r24, r16
     b32:	0e 94 47 04 	call	0x88e	; 0x88e <prvUnlockQueue>
				( void ) xTaskResumeAll();
     b36:	0e 94 c8 08 	call	0x1190	; 0x1190 <xTaskResumeAll>
     b3a:	84 cf       	rjmp	.-248    	; 0xa44 <xQueueGenericSend+0x38>
			}
		}
		else
		{
			/* The timeout has expired. */
			prvUnlockQueue( pxQueue );
     b3c:	c8 01       	movw	r24, r16
     b3e:	0e 94 47 04 	call	0x88e	; 0x88e <prvUnlockQueue>
			( void ) xTaskResumeAll();
     b42:	0e 94 c8 08 	call	0x1190	; 0x1190 <xTaskResumeAll>

			/* Return to the original privilege level before exiting the
			function. */
			traceQUEUE_SEND_FAILED( pxQueue );
			return errQUEUE_FULL;
     b46:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
}
     b48:	0f 90       	pop	r0
     b4a:	0f 90       	pop	r0
     b4c:	0f 90       	pop	r0
     b4e:	0f 90       	pop	r0
     b50:	0f 90       	pop	r0
     b52:	df 91       	pop	r29
     b54:	cf 91       	pop	r28
     b56:	1f 91       	pop	r17
     b58:	0f 91       	pop	r16
     b5a:	ff 90       	pop	r15
     b5c:	ef 90       	pop	r14
     b5e:	df 90       	pop	r13
     b60:	cf 90       	pop	r12
     b62:	bf 90       	pop	r11
     b64:	af 90       	pop	r10
     b66:	9f 90       	pop	r9
     b68:	08 95       	ret

00000b6a <xQueueGenericReceive>:
	return xReturn;
}
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait, const BaseType_t xJustPeeking )
{
     b6a:	9f 92       	push	r9
     b6c:	af 92       	push	r10
     b6e:	bf 92       	push	r11
     b70:	cf 92       	push	r12
     b72:	df 92       	push	r13
     b74:	ef 92       	push	r14
     b76:	ff 92       	push	r15
     b78:	0f 93       	push	r16
     b7a:	1f 93       	push	r17
     b7c:	cf 93       	push	r28
     b7e:	df 93       	push	r29
     b80:	00 d0       	rcall	.+0      	; 0xb82 <xQueueGenericReceive+0x18>
     b82:	00 d0       	rcall	.+0      	; 0xb84 <xQueueGenericReceive+0x1a>
     b84:	1f 92       	push	r1
     b86:	cd b7       	in	r28, 0x3d	; 61
     b88:	de b7       	in	r29, 0x3e	; 62
     b8a:	8c 01       	movw	r16, r24
     b8c:	6b 01       	movw	r12, r22
     b8e:	5d 83       	std	Y+5, r21	; 0x05
     b90:	4c 83       	std	Y+4, r20	; 0x04
     b92:	92 2e       	mov	r9, r18
BaseType_t xEntryTimeSet = pdFALSE;
     b94:	b1 2c       	mov	r11, r1
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
     b96:	aa 24       	eor	r10, r10
     b98:	a3 94       	inc	r10
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
     b9a:	7c 01       	movw	r14, r24
     b9c:	81 e1       	ldi	r24, 0x11	; 17
     b9e:	e8 0e       	add	r14, r24
     ba0:	f1 1c       	adc	r15, r1
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */

	for( ;; )
	{
		taskENTER_CRITICAL();
     ba2:	0f b6       	in	r0, 0x3f	; 63
     ba4:	f8 94       	cli
     ba6:	0f 92       	push	r0
		{
			/* Is there data in the queue now?  To be running the calling task
			must be	the highest priority task wanting to access the queue. */
			if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
     ba8:	f8 01       	movw	r30, r16
     baa:	92 8d       	ldd	r25, Z+26	; 0x1a
     bac:	99 23       	and	r25, r25
     bae:	49 f1       	breq	.+82     	; 0xc02 <xQueueGenericReceive+0x98>
			{
				/* Remember the read position in case the queue is only being
				peeked. */
				pcOriginalReadPosition = pxQueue->u.pcReadFrom;
     bb0:	e6 80       	ldd	r14, Z+6	; 0x06
     bb2:	f7 80       	ldd	r15, Z+7	; 0x07

				prvCopyDataFromQueue( pxQueue, pvBuffer );
     bb4:	b6 01       	movw	r22, r12
     bb6:	c8 01       	movw	r24, r16
     bb8:	0e 94 2d 04 	call	0x85a	; 0x85a <prvCopyDataFromQueue>

				if( xJustPeeking == pdFALSE )
     bbc:	91 10       	cpse	r9, r1
     bbe:	10 c0       	rjmp	.+32     	; 0xbe0 <xQueueGenericReceive+0x76>
				{
					traceQUEUE_RECEIVE( pxQueue );

					/* Actually removing data, not just peeking. */
					--( pxQueue->uxMessagesWaiting );
     bc0:	f8 01       	movw	r30, r16
     bc2:	82 8d       	ldd	r24, Z+26	; 0x1a
     bc4:	81 50       	subi	r24, 0x01	; 1
     bc6:	82 8f       	std	Z+26, r24	; 0x1a
							mtCOVERAGE_TEST_MARKER();
						}
					}
					#endif /* configUSE_MUTEXES */

					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     bc8:	80 85       	ldd	r24, Z+8	; 0x08
     bca:	88 23       	and	r24, r24
     bcc:	b1 f0       	breq	.+44     	; 0xbfa <xQueueGenericReceive+0x90>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) == pdTRUE )
     bce:	c8 01       	movw	r24, r16
     bd0:	08 96       	adiw	r24, 0x08	; 8
     bd2:	0e 94 63 0a 	call	0x14c6	; 0x14c6 <xTaskRemoveFromEventList>
     bd6:	81 30       	cpi	r24, 0x01	; 1
     bd8:	81 f4       	brne	.+32     	; 0xbfa <xQueueGenericReceive+0x90>
						{
							queueYIELD_IF_USING_PREEMPTION();
     bda:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>
     bde:	0d c0       	rjmp	.+26     	; 0xbfa <xQueueGenericReceive+0x90>
				{
					traceQUEUE_PEEK( pxQueue );

					/* The data is not being removed, so reset the read
					pointer. */
					pxQueue->u.pcReadFrom = pcOriginalReadPosition;
     be0:	f8 01       	movw	r30, r16
     be2:	f7 82       	std	Z+7, r15	; 0x07
     be4:	e6 82       	std	Z+6, r14	; 0x06

					/* The data is being left in the queue, so see if there are
					any other tasks waiting for the data. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     be6:	81 89       	ldd	r24, Z+17	; 0x11
     be8:	88 23       	and	r24, r24
     bea:	39 f0       	breq	.+14     	; 0xbfa <xQueueGenericReceive+0x90>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     bec:	c8 01       	movw	r24, r16
     bee:	41 96       	adiw	r24, 0x11	; 17
     bf0:	0e 94 63 0a 	call	0x14c6	; 0x14c6 <xTaskRemoveFromEventList>
     bf4:	81 11       	cpse	r24, r1
						{
							/* The task waiting has a higher priority than this task. */
							queueYIELD_IF_USING_PREEMPTION();
     bf6:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				taskEXIT_CRITICAL();
     bfa:	0f 90       	pop	r0
     bfc:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
     bfe:	81 e0       	ldi	r24, 0x01	; 1
     c00:	4f c0       	rjmp	.+158    	; 0xca0 <xQueueGenericReceive+0x136>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
     c02:	4c 81       	ldd	r20, Y+4	; 0x04
     c04:	5d 81       	ldd	r21, Y+5	; 0x05
     c06:	45 2b       	or	r20, r21
     c08:	21 f4       	brne	.+8      	; 0xc12 <xQueueGenericReceive+0xa8>
				{
					/* The queue was empty and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
     c0a:	0f 90       	pop	r0
     c0c:	0f be       	out	0x3f, r0	; 63
					traceQUEUE_RECEIVE_FAILED( pxQueue );
					return errQUEUE_EMPTY;
     c0e:	80 e0       	ldi	r24, 0x00	; 0
     c10:	47 c0       	rjmp	.+142    	; 0xca0 <xQueueGenericReceive+0x136>
				}
				else if( xEntryTimeSet == pdFALSE )
     c12:	b1 10       	cpse	r11, r1
     c14:	05 c0       	rjmp	.+10     	; 0xc20 <xQueueGenericReceive+0xb6>
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskSetTimeOutState( &xTimeOut );
     c16:	ce 01       	movw	r24, r28
     c18:	01 96       	adiw	r24, 0x01	; 1
     c1a:	0e 94 ab 0a 	call	0x1556	; 0x1556 <vTaskSetTimeOutState>
					xEntryTimeSet = pdTRUE;
     c1e:	ba 2c       	mov	r11, r10
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
     c20:	0f 90       	pop	r0
     c22:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
     c24:	0e 94 fb 07 	call	0xff6	; 0xff6 <vTaskSuspendAll>
		prvLockQueue( pxQueue );
     c28:	0f b6       	in	r0, 0x3f	; 63
     c2a:	f8 94       	cli
     c2c:	0f 92       	push	r0
     c2e:	f8 01       	movw	r30, r16
     c30:	85 8d       	ldd	r24, Z+29	; 0x1d
     c32:	8f 3f       	cpi	r24, 0xFF	; 255
     c34:	09 f4       	brne	.+2      	; 0xc38 <xQueueGenericReceive+0xce>
     c36:	15 8e       	std	Z+29, r1	; 0x1d
     c38:	f8 01       	movw	r30, r16
     c3a:	96 8d       	ldd	r25, Z+30	; 0x1e
     c3c:	9f 3f       	cpi	r25, 0xFF	; 255
     c3e:	09 f4       	brne	.+2      	; 0xc42 <xQueueGenericReceive+0xd8>
     c40:	16 8e       	std	Z+30, r1	; 0x1e
     c42:	0f 90       	pop	r0
     c44:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
     c46:	be 01       	movw	r22, r28
     c48:	6c 5f       	subi	r22, 0xFC	; 252
     c4a:	7f 4f       	sbci	r23, 0xFF	; 255
     c4c:	ce 01       	movw	r24, r28
     c4e:	01 96       	adiw	r24, 0x01	; 1
     c50:	0e 94 b6 0a 	call	0x156c	; 0x156c <xTaskCheckForTimeOut>
     c54:	81 11       	cpse	r24, r1
     c56:	1e c0       	rjmp	.+60     	; 0xc94 <xQueueGenericReceive+0x12a>

static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
     c58:	0f b6       	in	r0, 0x3f	; 63
     c5a:	f8 94       	cli
     c5c:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
     c5e:	f8 01       	movw	r30, r16
     c60:	82 8d       	ldd	r24, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     c62:	0f 90       	pop	r0
     c64:	0f be       	out	0x3f, r0	; 63
		prvLockQueue( pxQueue );

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
     c66:	81 11       	cpse	r24, r1
     c68:	0f c0       	rjmp	.+30     	; 0xc88 <xQueueGenericReceive+0x11e>
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
     c6a:	6c 81       	ldd	r22, Y+4	; 0x04
     c6c:	7d 81       	ldd	r23, Y+5	; 0x05
     c6e:	c7 01       	movw	r24, r14
     c70:	0e 94 36 0a 	call	0x146c	; 0x146c <vTaskPlaceOnEventList>
				prvUnlockQueue( pxQueue );
     c74:	c8 01       	movw	r24, r16
     c76:	0e 94 47 04 	call	0x88e	; 0x88e <prvUnlockQueue>
				if( xTaskResumeAll() == pdFALSE )
     c7a:	0e 94 c8 08 	call	0x1190	; 0x1190 <xTaskResumeAll>
     c7e:	81 11       	cpse	r24, r1
     c80:	90 cf       	rjmp	.-224    	; 0xba2 <xQueueGenericReceive+0x38>
				{
					portYIELD_WITHIN_API();
     c82:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>
     c86:	8d cf       	rjmp	.-230    	; 0xba2 <xQueueGenericReceive+0x38>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
     c88:	c8 01       	movw	r24, r16
     c8a:	0e 94 47 04 	call	0x88e	; 0x88e <prvUnlockQueue>
				( void ) xTaskResumeAll();
     c8e:	0e 94 c8 08 	call	0x1190	; 0x1190 <xTaskResumeAll>
     c92:	87 cf       	rjmp	.-242    	; 0xba2 <xQueueGenericReceive+0x38>
			}
		}
		else
		{
			prvUnlockQueue( pxQueue );
     c94:	c8 01       	movw	r24, r16
     c96:	0e 94 47 04 	call	0x88e	; 0x88e <prvUnlockQueue>
			( void ) xTaskResumeAll();
     c9a:	0e 94 c8 08 	call	0x1190	; 0x1190 <xTaskResumeAll>
			traceQUEUE_RECEIVE_FAILED( pxQueue );
			return errQUEUE_EMPTY;
     c9e:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
}
     ca0:	0f 90       	pop	r0
     ca2:	0f 90       	pop	r0
     ca4:	0f 90       	pop	r0
     ca6:	0f 90       	pop	r0
     ca8:	0f 90       	pop	r0
     caa:	df 91       	pop	r29
     cac:	cf 91       	pop	r28
     cae:	1f 91       	pop	r17
     cb0:	0f 91       	pop	r16
     cb2:	ff 90       	pop	r15
     cb4:	ef 90       	pop	r14
     cb6:	df 90       	pop	r13
     cb8:	cf 90       	pop	r12
     cba:	bf 90       	pop	r11
     cbc:	af 90       	pop	r10
     cbe:	9f 90       	pop	r9
     cc0:	08 95       	ret

00000cc2 <uxQueueMessagesWaiting>:
{
UBaseType_t uxReturn;

	configASSERT( xQueue );

	taskENTER_CRITICAL();
     cc2:	0f b6       	in	r0, 0x3f	; 63
     cc4:	f8 94       	cli
     cc6:	0f 92       	push	r0
	{
		uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
     cc8:	fc 01       	movw	r30, r24
     cca:	82 8d       	ldd	r24, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
     ccc:	0f 90       	pop	r0
     cce:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
     cd0:	08 95       	ret

00000cd2 <prvResetNextTaskUnblockTime>:

static void prvResetNextTaskUnblockTime( void )
{
TCB_t *pxTCB;

	if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
     cd2:	e0 91 c1 07 	lds	r30, 0x07C1
     cd6:	f0 91 c2 07 	lds	r31, 0x07C2
     cda:	80 81       	ld	r24, Z
     cdc:	81 11       	cpse	r24, r1
     cde:	07 c0       	rjmp	.+14     	; 0xcee <prvResetNextTaskUnblockTime+0x1c>
	{
		/* The new current delayed list is empty.  Set xNextTaskUnblockTime to
		the maximum possible value so it is	extremely unlikely that the
		if( xTickCount >= xNextTaskUnblockTime ) test will pass until
		there is an item in the delayed list. */
		xNextTaskUnblockTime = portMAX_DELAY;
     ce0:	8f ef       	ldi	r24, 0xFF	; 255
     ce2:	9f ef       	ldi	r25, 0xFF	; 255
     ce4:	90 93 03 01 	sts	0x0103, r25
     ce8:	80 93 02 01 	sts	0x0102, r24
     cec:	08 95       	ret
	{
		/* The new current delayed list is not empty, get the value of
		the item at the head of the delayed list.  This is the time at
		which the task at the head of the delayed list should be removed
		from the Blocked state. */
		( pxTCB ) = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
     cee:	e0 91 c1 07 	lds	r30, 0x07C1
     cf2:	f0 91 c2 07 	lds	r31, 0x07C2
     cf6:	05 80       	ldd	r0, Z+5	; 0x05
     cf8:	f6 81       	ldd	r31, Z+6	; 0x06
     cfa:	e0 2d       	mov	r30, r0
		xNextTaskUnblockTime = listGET_LIST_ITEM_VALUE( &( ( pxTCB )->xGenericListItem ) );
     cfc:	06 80       	ldd	r0, Z+6	; 0x06
     cfe:	f7 81       	ldd	r31, Z+7	; 0x07
     d00:	e0 2d       	mov	r30, r0
     d02:	82 81       	ldd	r24, Z+2	; 0x02
     d04:	93 81       	ldd	r25, Z+3	; 0x03
     d06:	90 93 03 01 	sts	0x0103, r25
     d0a:	80 93 02 01 	sts	0x0102, r24
     d0e:	08 95       	ret

00000d10 <prvAddCurrentTaskToDelayedList>:
	#endif /* vTaskDelete */
}
/*-----------------------------------------------------------*/

static void prvAddCurrentTaskToDelayedList( const TickType_t xTimeToWake )
{
     d10:	cf 93       	push	r28
     d12:	df 93       	push	r29
     d14:	ec 01       	movw	r28, r24
	/* The list item will be inserted in wake time order. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xGenericListItem ), xTimeToWake );
     d16:	e0 91 f9 07 	lds	r30, 0x07F9
     d1a:	f0 91 fa 07 	lds	r31, 0x07FA
     d1e:	93 83       	std	Z+3, r25	; 0x03
     d20:	82 83       	std	Z+2, r24	; 0x02

	if( xTimeToWake < xTickCount )
     d22:	80 91 a0 07 	lds	r24, 0x07A0
     d26:	90 91 a1 07 	lds	r25, 0x07A1
     d2a:	c8 17       	cp	r28, r24
     d2c:	d9 07       	cpc	r29, r25
     d2e:	68 f4       	brcc	.+26     	; 0xd4a <prvAddCurrentTaskToDelayedList+0x3a>
	{
		/* Wake time has overflowed.  Place this item in the overflow list. */
		vListInsert( pxOverflowDelayedTaskList, &( pxCurrentTCB->xGenericListItem ) );
     d30:	60 91 f9 07 	lds	r22, 0x07F9
     d34:	70 91 fa 07 	lds	r23, 0x07FA
     d38:	80 91 bf 07 	lds	r24, 0x07BF
     d3c:	90 91 c0 07 	lds	r25, 0x07C0
     d40:	6e 5f       	subi	r22, 0xFE	; 254
     d42:	7f 4f       	sbci	r23, 0xFF	; 255
     d44:	0e 94 1b 01 	call	0x236	; 0x236 <vListInsert>
     d48:	17 c0       	rjmp	.+46     	; 0xd78 <prvAddCurrentTaskToDelayedList+0x68>
	}
	else
	{
		/* The wake time has not overflowed, so the current block list is used. */
		vListInsert( pxDelayedTaskList, &( pxCurrentTCB->xGenericListItem ) );
     d4a:	60 91 f9 07 	lds	r22, 0x07F9
     d4e:	70 91 fa 07 	lds	r23, 0x07FA
     d52:	80 91 c1 07 	lds	r24, 0x07C1
     d56:	90 91 c2 07 	lds	r25, 0x07C2
     d5a:	6e 5f       	subi	r22, 0xFE	; 254
     d5c:	7f 4f       	sbci	r23, 0xFF	; 255
     d5e:	0e 94 1b 01 	call	0x236	; 0x236 <vListInsert>

		/* If the task entering the blocked state was placed at the head of the
		list of blocked tasks then xNextTaskUnblockTime needs to be updated
		too. */
		if( xTimeToWake < xNextTaskUnblockTime )
     d62:	80 91 02 01 	lds	r24, 0x0102
     d66:	90 91 03 01 	lds	r25, 0x0103
     d6a:	c8 17       	cp	r28, r24
     d6c:	d9 07       	cpc	r29, r25
     d6e:	20 f4       	brcc	.+8      	; 0xd78 <prvAddCurrentTaskToDelayedList+0x68>
		{
			xNextTaskUnblockTime = xTimeToWake;
     d70:	d0 93 03 01 	sts	0x0103, r29
     d74:	c0 93 02 01 	sts	0x0102, r28
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
}
     d78:	df 91       	pop	r29
     d7a:	cf 91       	pop	r28
     d7c:	08 95       	ret

00000d7e <xTaskGenericCreate>:

#endif
/*-----------------------------------------------------------*/

BaseType_t xTaskGenericCreate( TaskFunction_t pxTaskCode, const char * const pcName, const uint16_t usStackDepth, void * const pvParameters, UBaseType_t uxPriority, TaskHandle_t * const pxCreatedTask, StackType_t * const puxStackBuffer, const MemoryRegion_t * const xRegions ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
{
     d7e:	4f 92       	push	r4
     d80:	5f 92       	push	r5
     d82:	6f 92       	push	r6
     d84:	7f 92       	push	r7
     d86:	8f 92       	push	r8
     d88:	9f 92       	push	r9
     d8a:	af 92       	push	r10
     d8c:	bf 92       	push	r11
     d8e:	cf 92       	push	r12
     d90:	df 92       	push	r13
     d92:	ef 92       	push	r14
     d94:	ff 92       	push	r15
     d96:	0f 93       	push	r16
     d98:	1f 93       	push	r17
     d9a:	cf 93       	push	r28
     d9c:	df 93       	push	r29
     d9e:	4c 01       	movw	r8, r24
     da0:	eb 01       	movw	r28, r22
     da2:	5a 01       	movw	r10, r20
     da4:	29 01       	movw	r4, r18
	#else /* portSTACK_GROWTH */
	{
	StackType_t *pxStack;

		/* Allocate space for the stack used by the task being created. */
		pxStack = ( StackType_t * ) pvPortMallocAligned( ( ( ( size_t ) usStackDepth ) * sizeof( StackType_t ) ), puxStackBuffer ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     da6:	c1 14       	cp	r12, r1
     da8:	d1 04       	cpc	r13, r1
     daa:	39 f4       	brne	.+14     	; 0xdba <xTaskGenericCreate+0x3c>
     dac:	ca 01       	movw	r24, r20
     dae:	0e 94 da 02 	call	0x5b4	; 0x5b4 <pvPortMalloc>
     db2:	6c 01       	movw	r12, r24

		if( pxStack != NULL )
     db4:	89 2b       	or	r24, r25
     db6:	09 f4       	brne	.+2      	; 0xdba <xTaskGenericCreate+0x3c>
     db8:	e1 c0       	rjmp	.+450    	; 0xf7c <xTaskGenericCreate+0x1fe>
		{
			/* Allocate space for the TCB.  Where the memory comes from depends
			on the implementation of the port malloc function. */
			pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) );
     dba:	86 e2       	ldi	r24, 0x26	; 38
     dbc:	90 e0       	ldi	r25, 0x00	; 0
     dbe:	0e 94 da 02 	call	0x5b4	; 0x5b4 <pvPortMalloc>
     dc2:	3c 01       	movw	r6, r24

			if( pxNewTCB != NULL )
     dc4:	00 97       	sbiw	r24, 0x00	; 0
     dc6:	79 f0       	breq	.+30     	; 0xde6 <xTaskGenericCreate+0x68>
			{
				/* Store the stack location in the TCB. */
				pxNewTCB->pxStack = pxStack;
     dc8:	fc 01       	movw	r30, r24
     dca:	d0 8e       	std	Z+24, r13	; 0x18
     dcc:	c7 8a       	std	Z+23, r12	; 0x17
		stack grows from high memory to low (as per the 80x86) or vice versa.
		portSTACK_GROWTH is used to make the result positive or negative as
		required by the port. */
		#if( portSTACK_GROWTH < 0 )
		{
			pxTopOfStack = pxNewTCB->pxStack + ( usStackDepth - ( uint16_t ) 1 );
     dce:	f1 e0       	ldi	r31, 0x01	; 1
     dd0:	af 1a       	sub	r10, r31
     dd2:	b1 08       	sbc	r11, r1
     dd4:	ca 0c       	add	r12, r10
     dd6:	db 1c       	adc	r13, r11
UBaseType_t x;

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
	{
		pxTCB->pcTaskName[ x ] = pcName[ x ];
     dd8:	88 81       	ld	r24, Y
     dda:	f3 01       	movw	r30, r6
     ddc:	81 8f       	std	Z+25, r24	; 0x19

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == 0x00 )
     dde:	88 81       	ld	r24, Y
     de0:	81 11       	cpse	r24, r1
     de2:	05 c0       	rjmp	.+10     	; 0xdee <xTaskGenericCreate+0x70>
     de4:	14 c0       	rjmp	.+40     	; 0xe0e <xTaskGenericCreate+0x90>
			}
			else
			{
				/* The stack cannot be used as the TCB was not created.  Free it
				again. */
				vPortFree( pxStack );
     de6:	c6 01       	movw	r24, r12
     de8:	0e 94 74 03 	call	0x6e8	; 0x6e8 <vPortFree>
     dec:	c7 c0       	rjmp	.+398    	; 0xf7c <xTaskGenericCreate+0x1fe>
     dee:	d3 01       	movw	r26, r6
     df0:	5a 96       	adiw	r26, 0x1a	; 26
     df2:	fe 01       	movw	r30, r28
     df4:	31 96       	adiw	r30, 0x01	; 1
     df6:	9e 01       	movw	r18, r28
     df8:	28 5f       	subi	r18, 0xF8	; 248
     dfa:	3f 4f       	sbci	r19, 0xFF	; 255
     dfc:	ef 01       	movw	r28, r30
UBaseType_t x;

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
	{
		pxTCB->pcTaskName[ x ] = pcName[ x ];
     dfe:	81 91       	ld	r24, Z+
     e00:	8d 93       	st	X+, r24

		/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
		configMAX_TASK_NAME_LEN characters just in case the memory after the
		string is not accessible (extremely unlikely). */
		if( pcName[ x ] == 0x00 )
     e02:	88 81       	ld	r24, Y
     e04:	88 23       	and	r24, r24
     e06:	19 f0       	breq	.+6      	; 0xe0e <xTaskGenericCreate+0x90>
static void prvInitialiseTCBVariables( TCB_t * const pxTCB, const char * const pcName, UBaseType_t uxPriority, const MemoryRegion_t * const xRegions, const uint16_t usStackDepth ) /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
{
UBaseType_t x;

	/* Store the task name in the TCB. */
	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
     e08:	e2 17       	cp	r30, r18
     e0a:	f3 07       	cpc	r31, r19
     e0c:	b9 f7       	brne	.-18     	; 0xdfc <xTaskGenericCreate+0x7e>
		}
	}

	/* Ensure the name string is terminated in the case that the string length
	was greater or equal to configMAX_TASK_NAME_LEN. */
	pxTCB->pcTaskName[ configMAX_TASK_NAME_LEN - 1 ] = '\0';
     e0e:	f3 01       	movw	r30, r6
     e10:	10 a2       	std	Z+32, r1	; 0x20
     e12:	10 2f       	mov	r17, r16
     e14:	04 30       	cpi	r16, 0x04	; 4
     e16:	08 f0       	brcs	.+2      	; 0xe1a <xTaskGenericCreate+0x9c>
     e18:	13 e0       	ldi	r17, 0x03	; 3
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxTCB->uxPriority = uxPriority;
     e1a:	f3 01       	movw	r30, r6
     e1c:	16 8b       	std	Z+22, r17	; 0x16
		pxTCB->uxBasePriority = uxPriority;
		pxTCB->uxMutexesHeld = 0;
	}
	#endif /* configUSE_MUTEXES */

	vListInitialiseItem( &( pxTCB->xGenericListItem ) );
     e1e:	e3 01       	movw	r28, r6
     e20:	22 96       	adiw	r28, 0x02	; 2
     e22:	ce 01       	movw	r24, r28
     e24:	0e 94 f6 00 	call	0x1ec	; 0x1ec <vListInitialiseItem>
	vListInitialiseItem( &( pxTCB->xEventListItem ) );
     e28:	c3 01       	movw	r24, r6
     e2a:	0c 96       	adiw	r24, 0x0c	; 12
     e2c:	0e 94 f6 00 	call	0x1ec	; 0x1ec <vListInitialiseItem>

	/* Set the pxTCB as a link back from the ListItem_t.  This is so we can get
	back to	the containing TCB from a generic item in a list. */
	listSET_LIST_ITEM_OWNER( &( pxTCB->xGenericListItem ), pxTCB );
     e30:	f3 01       	movw	r30, r6
     e32:	71 86       	std	Z+9, r7	; 0x09
     e34:	60 86       	std	Z+8, r6	; 0x08

	/* Event lists are always in priority order. */
	listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
     e36:	84 e0       	ldi	r24, 0x04	; 4
     e38:	90 e0       	ldi	r25, 0x00	; 0
     e3a:	81 1b       	sub	r24, r17
     e3c:	91 09       	sbc	r25, r1
     e3e:	95 87       	std	Z+13, r25	; 0x0d
     e40:	84 87       	std	Z+12, r24	; 0x0c
	listSET_LIST_ITEM_OWNER( &( pxTCB->xEventListItem ), pxTCB );
     e42:	73 8a       	std	Z+19, r7	; 0x13
     e44:	62 8a       	std	Z+18, r6	; 0x12
	}
	#endif

	#if ( configUSE_TASK_NOTIFICATIONS == 1 )
	{
		pxTCB->ulNotifiedValue = 0;
     e46:	11 a2       	std	Z+33, r1	; 0x21
     e48:	12 a2       	std	Z+34, r1	; 0x22
     e4a:	13 a2       	std	Z+35, r1	; 0x23
     e4c:	14 a2       	std	Z+36, r1	; 0x24
		pxTCB->eNotifyState = eNotWaitingNotification;
     e4e:	15 a2       	std	Z+37, r1	; 0x25
		{
			pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters, xRunPrivileged );
		}
		#else /* portUSING_MPU_WRAPPERS */
		{
			pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters );
     e50:	a2 01       	movw	r20, r4
     e52:	b4 01       	movw	r22, r8
     e54:	c6 01       	movw	r24, r12
     e56:	0e 94 72 01 	call	0x2e4	; 0x2e4 <pxPortInitialiseStack>
     e5a:	f3 01       	movw	r30, r6
     e5c:	91 83       	std	Z+1, r25	; 0x01
     e5e:	80 83       	st	Z, r24
		}
		#endif /* portUSING_MPU_WRAPPERS */

		if( ( void * ) pxCreatedTask != NULL )
     e60:	e1 14       	cp	r14, r1
     e62:	f1 04       	cpc	r15, r1
     e64:	19 f0       	breq	.+6      	; 0xe6c <xTaskGenericCreate+0xee>
		{
			/* Pass the TCB out - in an anonymous way.  The calling function/
			task can use this as a handle to delete the task later if
			required.*/
			*pxCreatedTask = ( TaskHandle_t ) pxNewTCB;
     e66:	f7 01       	movw	r30, r14
     e68:	71 82       	std	Z+1, r7	; 0x01
     e6a:	60 82       	st	Z, r6
			mtCOVERAGE_TEST_MARKER();
		}

		/* Ensure interrupts don't access the task lists while they are being
		updated. */
		taskENTER_CRITICAL();
     e6c:	0f b6       	in	r0, 0x3f	; 63
     e6e:	f8 94       	cli
     e70:	0f 92       	push	r0
		{
			uxCurrentNumberOfTasks++;
     e72:	80 91 a2 07 	lds	r24, 0x07A2
     e76:	8f 5f       	subi	r24, 0xFF	; 255
     e78:	80 93 a2 07 	sts	0x07A2, r24
			if( pxCurrentTCB == NULL )
     e7c:	80 91 f9 07 	lds	r24, 0x07F9
     e80:	90 91 fa 07 	lds	r25, 0x07FA
     e84:	89 2b       	or	r24, r25
     e86:	d1 f5       	brne	.+116    	; 0xefc <xTaskGenericCreate+0x17e>
			{
				/* There are no other tasks, or all the other tasks are in
				the suspended state - make this the current task. */
				pxCurrentTCB =  pxNewTCB;
     e88:	70 92 fa 07 	sts	0x07FA, r7
     e8c:	60 92 f9 07 	sts	0x07F9, r6

				if( uxCurrentNumberOfTasks == ( UBaseType_t ) 1 )
     e90:	80 91 a2 07 	lds	r24, 0x07A2
     e94:	81 30       	cpi	r24, 0x01	; 1
     e96:	09 f0       	breq	.+2      	; 0xe9a <xTaskGenericCreate+0x11c>
     e98:	40 c0       	rjmp	.+128    	; 0xf1a <xTaskGenericCreate+0x19c>
{
UBaseType_t uxPriority;

	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
	{
		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
     e9a:	85 ed       	ldi	r24, 0xD5	; 213
     e9c:	97 e0       	ldi	r25, 0x07	; 7
     e9e:	0e 94 e8 00 	call	0x1d0	; 0x1d0 <vListInitialise>
     ea2:	8e ed       	ldi	r24, 0xDE	; 222
     ea4:	97 e0       	ldi	r25, 0x07	; 7
     ea6:	0e 94 e8 00 	call	0x1d0	; 0x1d0 <vListInitialise>
     eaa:	87 ee       	ldi	r24, 0xE7	; 231
     eac:	97 e0       	ldi	r25, 0x07	; 7
     eae:	0e 94 e8 00 	call	0x1d0	; 0x1d0 <vListInitialise>
     eb2:	80 ef       	ldi	r24, 0xF0	; 240
     eb4:	97 e0       	ldi	r25, 0x07	; 7
     eb6:	0e 94 e8 00 	call	0x1d0	; 0x1d0 <vListInitialise>
	}

	vListInitialise( &xDelayedTaskList1 );
     eba:	8c ec       	ldi	r24, 0xCC	; 204
     ebc:	97 e0       	ldi	r25, 0x07	; 7
     ebe:	0e 94 e8 00 	call	0x1d0	; 0x1d0 <vListInitialise>
	vListInitialise( &xDelayedTaskList2 );
     ec2:	83 ec       	ldi	r24, 0xC3	; 195
     ec4:	97 e0       	ldi	r25, 0x07	; 7
     ec6:	0e 94 e8 00 	call	0x1d0	; 0x1d0 <vListInitialise>
	vListInitialise( &xPendingReadyList );
     eca:	86 eb       	ldi	r24, 0xB6	; 182
     ecc:	97 e0       	ldi	r25, 0x07	; 7
     ece:	0e 94 e8 00 	call	0x1d0	; 0x1d0 <vListInitialise>

	#if ( INCLUDE_vTaskDelete == 1 )
	{
		vListInitialise( &xTasksWaitingTermination );
     ed2:	8d ea       	ldi	r24, 0xAD	; 173
     ed4:	97 e0       	ldi	r25, 0x07	; 7
     ed6:	0e 94 e8 00 	call	0x1d0	; 0x1d0 <vListInitialise>
	}
	#endif /* INCLUDE_vTaskDelete */

	#if ( INCLUDE_vTaskSuspend == 1 )
	{
		vListInitialise( &xSuspendedTaskList );
     eda:	83 ea       	ldi	r24, 0xA3	; 163
     edc:	97 e0       	ldi	r25, 0x07	; 7
     ede:	0e 94 e8 00 	call	0x1d0	; 0x1d0 <vListInitialise>
	}
	#endif /* INCLUDE_vTaskSuspend */

	/* Start with pxDelayedTaskList using list1 and the pxOverflowDelayedTaskList
	using list2. */
	pxDelayedTaskList = &xDelayedTaskList1;
     ee2:	8c ec       	ldi	r24, 0xCC	; 204
     ee4:	97 e0       	ldi	r25, 0x07	; 7
     ee6:	90 93 c2 07 	sts	0x07C2, r25
     eea:	80 93 c1 07 	sts	0x07C1, r24
	pxOverflowDelayedTaskList = &xDelayedTaskList2;
     eee:	83 ec       	ldi	r24, 0xC3	; 195
     ef0:	97 e0       	ldi	r25, 0x07	; 7
     ef2:	90 93 c0 07 	sts	0x07C0, r25
     ef6:	80 93 bf 07 	sts	0x07BF, r24
     efa:	0f c0       	rjmp	.+30     	; 0xf1a <xTaskGenericCreate+0x19c>
			else
			{
				/* If the scheduler is not already running, make this task the
				current task if it is the highest priority task to be created
				so far. */
				if( xSchedulerRunning == pdFALSE )
     efc:	80 91 9e 07 	lds	r24, 0x079E
     f00:	81 11       	cpse	r24, r1
     f02:	0b c0       	rjmp	.+22     	; 0xf1a <xTaskGenericCreate+0x19c>
				{
					if( pxCurrentTCB->uxPriority <= uxPriority )
     f04:	e0 91 f9 07 	lds	r30, 0x07F9
     f08:	f0 91 fa 07 	lds	r31, 0x07FA
     f0c:	86 89       	ldd	r24, Z+22	; 0x16
     f0e:	08 17       	cp	r16, r24
     f10:	20 f0       	brcs	.+8      	; 0xf1a <xTaskGenericCreate+0x19c>
					{
						pxCurrentTCB = pxNewTCB;
     f12:	70 92 fa 07 	sts	0x07FA, r7
     f16:	60 92 f9 07 	sts	0x07F9, r6
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}

			uxTaskNumber++;
     f1a:	80 91 9a 07 	lds	r24, 0x079A
     f1e:	8f 5f       	subi	r24, 0xFF	; 255
     f20:	80 93 9a 07 	sts	0x079A, r24
				pxNewTCB->uxTCBNumber = uxTaskNumber;
			}
			#endif /* configUSE_TRACE_FACILITY */
			traceTASK_CREATE( pxNewTCB );

			prvAddTaskToReadyList( pxNewTCB );
     f24:	f3 01       	movw	r30, r6
     f26:	86 89       	ldd	r24, Z+22	; 0x16
     f28:	90 91 9f 07 	lds	r25, 0x079F
     f2c:	98 17       	cp	r25, r24
     f2e:	10 f4       	brcc	.+4      	; 0xf34 <xTaskGenericCreate+0x1b6>
     f30:	80 93 9f 07 	sts	0x079F, r24
     f34:	90 e0       	ldi	r25, 0x00	; 0
     f36:	9c 01       	movw	r18, r24
     f38:	22 0f       	add	r18, r18
     f3a:	33 1f       	adc	r19, r19
     f3c:	22 0f       	add	r18, r18
     f3e:	33 1f       	adc	r19, r19
     f40:	22 0f       	add	r18, r18
     f42:	33 1f       	adc	r19, r19
     f44:	82 0f       	add	r24, r18
     f46:	93 1f       	adc	r25, r19
     f48:	be 01       	movw	r22, r28
     f4a:	8b 52       	subi	r24, 0x2B	; 43
     f4c:	98 4f       	sbci	r25, 0xF8	; 248
     f4e:	0e 94 fa 00 	call	0x1f4	; 0x1f4 <vListInsertEnd>

			xReturn = pdPASS;
			portSETUP_TCB( pxNewTCB );
		}
		taskEXIT_CRITICAL();
     f52:	0f 90       	pop	r0
     f54:	0f be       	out	0x3f, r0	; 63
		traceTASK_CREATE_FAILED();
	}

	if( xReturn == pdPASS )
	{
		if( xSchedulerRunning != pdFALSE )
     f56:	80 91 9e 07 	lds	r24, 0x079E
     f5a:	88 23       	and	r24, r24
     f5c:	59 f0       	breq	.+22     	; 0xf74 <xTaskGenericCreate+0x1f6>
		{
			/* If the created task is of a higher priority than the current task
			then it should run now. */
			if( pxCurrentTCB->uxPriority < uxPriority )
     f5e:	e0 91 f9 07 	lds	r30, 0x07F9
     f62:	f0 91 fa 07 	lds	r31, 0x07FA
     f66:	86 89       	ldd	r24, Z+22	; 0x16
     f68:	80 17       	cp	r24, r16
     f6a:	30 f4       	brcc	.+12     	; 0xf78 <xTaskGenericCreate+0x1fa>
			{
				taskYIELD_IF_USING_PREEMPTION();
     f6c:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>
     f70:	81 e0       	ldi	r24, 0x01	; 1
     f72:	05 c0       	rjmp	.+10     	; 0xf7e <xTaskGenericCreate+0x200>
     f74:	81 e0       	ldi	r24, 0x01	; 1
     f76:	03 c0       	rjmp	.+6      	; 0xf7e <xTaskGenericCreate+0x200>
     f78:	81 e0       	ldi	r24, 0x01	; 1
     f7a:	01 c0       	rjmp	.+2      	; 0xf7e <xTaskGenericCreate+0x200>
		}
		taskEXIT_CRITICAL();
	}
	else
	{
		xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
     f7c:	8f ef       	ldi	r24, 0xFF	; 255
			mtCOVERAGE_TEST_MARKER();
		}
	}

	return xReturn;
}
     f7e:	df 91       	pop	r29
     f80:	cf 91       	pop	r28
     f82:	1f 91       	pop	r17
     f84:	0f 91       	pop	r16
     f86:	ff 90       	pop	r15
     f88:	ef 90       	pop	r14
     f8a:	df 90       	pop	r13
     f8c:	cf 90       	pop	r12
     f8e:	bf 90       	pop	r11
     f90:	af 90       	pop	r10
     f92:	9f 90       	pop	r9
     f94:	8f 90       	pop	r8
     f96:	7f 90       	pop	r7
     f98:	6f 90       	pop	r6
     f9a:	5f 90       	pop	r5
     f9c:	4f 90       	pop	r4
     f9e:	08 95       	ret

00000fa0 <vTaskStartScheduler>:

#endif /* ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) ) */
/*-----------------------------------------------------------*/

void vTaskStartScheduler( void )
{
     fa0:	af 92       	push	r10
     fa2:	bf 92       	push	r11
     fa4:	cf 92       	push	r12
     fa6:	df 92       	push	r13
     fa8:	ef 92       	push	r14
     faa:	ff 92       	push	r15
     fac:	0f 93       	push	r16
		xReturn = xTaskCreate( prvIdleTask, "IDLE", tskIDLE_STACK_SIZE, ( void * ) NULL, ( tskIDLE_PRIORITY | portPRIVILEGE_BIT ), &xIdleTaskHandle ); /*lint !e961 MISRA exception, justified as it is not a redundant explicit cast to all supported compilers. */
	}
	#else
	{
		/* Create the idle task without storing its handle. */
		xReturn = xTaskCreate( prvIdleTask, "IDLE", tskIDLE_STACK_SIZE, ( void * ) NULL, ( tskIDLE_PRIORITY | portPRIVILEGE_BIT ), NULL );  /*lint !e961 MISRA exception, justified as it is not a redundant explicit cast to all supported compilers. */
     fae:	a1 2c       	mov	r10, r1
     fb0:	b1 2c       	mov	r11, r1
     fb2:	c1 2c       	mov	r12, r1
     fb4:	d1 2c       	mov	r13, r1
     fb6:	e1 2c       	mov	r14, r1
     fb8:	f1 2c       	mov	r15, r1
     fba:	00 e0       	ldi	r16, 0x00	; 0
     fbc:	20 e0       	ldi	r18, 0x00	; 0
     fbe:	30 e0       	ldi	r19, 0x00	; 0
     fc0:	45 e5       	ldi	r20, 0x55	; 85
     fc2:	50 e0       	ldi	r21, 0x00	; 0
     fc4:	6e ea       	ldi	r22, 0xAE	; 174
     fc6:	71 e0       	ldi	r23, 0x01	; 1
     fc8:	8c e8       	ldi	r24, 0x8C	; 140
     fca:	99 e0       	ldi	r25, 0x09	; 9
     fcc:	0e 94 bf 06 	call	0xd7e	; 0xd7e <xTaskGenericCreate>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	#endif /* configUSE_TIMERS */

	if( xReturn == pdPASS )
     fd0:	81 30       	cpi	r24, 0x01	; 1
     fd2:	49 f4       	brne	.+18     	; 0xfe6 <vTaskStartScheduler+0x46>
		/* Interrupts are turned off here, to ensure a tick does not occur
		before or during the call to xPortStartScheduler().  The stacks of
		the created tasks contain a status word with interrupts switched on
		so interrupts will automatically get re-enabled when the first task
		starts to run. */
		portDISABLE_INTERRUPTS();
     fd4:	f8 94       	cli
			structure specific to the task that will run first. */
			_impure_ptr = &( pxCurrentTCB->xNewLib_reent );
		}
		#endif /* configUSE_NEWLIB_REENTRANT */

		xSchedulerRunning = pdTRUE;
     fd6:	80 93 9e 07 	sts	0x079E, r24
		xTickCount = ( TickType_t ) 0U;
     fda:	10 92 a1 07 	sts	0x07A1, r1
     fde:	10 92 a0 07 	sts	0x07A0, r1
		the run time counter time base. */
		portCONFIGURE_TIMER_FOR_RUN_TIME_STATS();

		/* Setting up the timer tick is hardware specific and thus in the
		portable interface. */
		if( xPortStartScheduler() != pdFALSE )
     fe2:	0e 94 de 01 	call	0x3bc	; 0x3bc <xPortStartScheduler>
		/* This line will only be reached if the kernel could not be started,
		because there was not enough FreeRTOS heap to create the idle task
		or the timer task. */
		configASSERT( xReturn );
	}
}
     fe6:	0f 91       	pop	r16
     fe8:	ff 90       	pop	r15
     fea:	ef 90       	pop	r14
     fec:	df 90       	pop	r13
     fee:	cf 90       	pop	r12
     ff0:	bf 90       	pop	r11
     ff2:	af 90       	pop	r10
     ff4:	08 95       	ret

00000ff6 <vTaskSuspendAll>:
{
	/* A critical section is not required as the variable is of type
	BaseType_t.  Please read Richard Barry's reply in the following link to a
	post in the FreeRTOS support forum before reporting this as a bug! -
	http://goo.gl/wu4acr */
	++uxSchedulerSuspended;
     ff6:	80 91 99 07 	lds	r24, 0x0799
     ffa:	8f 5f       	subi	r24, 0xFF	; 255
     ffc:	80 93 99 07 	sts	0x0799, r24
    1000:	08 95       	ret

00001002 <xTaskGetTickCount>:
TickType_t xTaskGetTickCount( void )
{
TickType_t xTicks;

	/* Critical section required if running on a 16 bit processor. */
	portTICK_TYPE_ENTER_CRITICAL();
    1002:	0f b6       	in	r0, 0x3f	; 63
    1004:	f8 94       	cli
    1006:	0f 92       	push	r0
	{
		xTicks = xTickCount;
    1008:	80 91 a0 07 	lds	r24, 0x07A0
    100c:	90 91 a1 07 	lds	r25, 0x07A1
	}
	portTICK_TYPE_EXIT_CRITICAL();
    1010:	0f 90       	pop	r0
    1012:	0f be       	out	0x3f, r0	; 63

	return xTicks;
}
    1014:	08 95       	ret

00001016 <xTaskIncrementTick>:

#endif /* configUSE_TICKLESS_IDLE */
/*----------------------------------------------------------*/

BaseType_t xTaskIncrementTick( void )
{
    1016:	cf 92       	push	r12
    1018:	df 92       	push	r13
    101a:	ef 92       	push	r14
    101c:	ff 92       	push	r15
    101e:	0f 93       	push	r16
    1020:	1f 93       	push	r17
    1022:	cf 93       	push	r28
    1024:	df 93       	push	r29

	/* Called by the portable layer each time a tick interrupt occurs.
	Increments the tick then checks to see if the new tick value will cause any
	tasks to be unblocked. */
	traceTASK_INCREMENT_TICK( xTickCount );
	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1026:	80 91 99 07 	lds	r24, 0x0799
    102a:	81 11       	cpse	r24, r1
    102c:	9b c0       	rjmp	.+310    	; 0x1164 <xTaskIncrementTick+0x14e>
	{
		/* Increment the RTOS tick, switching the delayed and overflowed
		delayed lists if it wraps to 0. */
		++xTickCount;
    102e:	80 91 a0 07 	lds	r24, 0x07A0
    1032:	90 91 a1 07 	lds	r25, 0x07A1
    1036:	01 96       	adiw	r24, 0x01	; 1
    1038:	90 93 a1 07 	sts	0x07A1, r25
    103c:	80 93 a0 07 	sts	0x07A0, r24

		{
			/* Minor optimisation.  The tick count cannot change in this
			block. */
			const TickType_t xConstTickCount = xTickCount;
    1040:	e0 90 a0 07 	lds	r14, 0x07A0
    1044:	f0 90 a1 07 	lds	r15, 0x07A1

			if( xConstTickCount == ( TickType_t ) 0U )
    1048:	e1 14       	cp	r14, r1
    104a:	f1 04       	cpc	r15, r1
    104c:	b9 f4       	brne	.+46     	; 0x107c <xTaskIncrementTick+0x66>
			{
				taskSWITCH_DELAYED_LISTS();
    104e:	80 91 c1 07 	lds	r24, 0x07C1
    1052:	90 91 c2 07 	lds	r25, 0x07C2
    1056:	20 91 bf 07 	lds	r18, 0x07BF
    105a:	30 91 c0 07 	lds	r19, 0x07C0
    105e:	30 93 c2 07 	sts	0x07C2, r19
    1062:	20 93 c1 07 	sts	0x07C1, r18
    1066:	90 93 c0 07 	sts	0x07C0, r25
    106a:	80 93 bf 07 	sts	0x07BF, r24
    106e:	80 91 9b 07 	lds	r24, 0x079B
    1072:	8f 5f       	subi	r24, 0xFF	; 255
    1074:	80 93 9b 07 	sts	0x079B, r24
    1078:	0e 94 69 06 	call	0xcd2	; 0xcd2 <prvResetNextTaskUnblockTime>

			/* See if this tick has made a timeout expire.  Tasks are stored in
			the	queue in the order of their wake time - meaning once one task
			has been found whose block time has not expired there is no need to
			look any further down the list. */
			if( xConstTickCount >= xNextTaskUnblockTime )
    107c:	80 91 02 01 	lds	r24, 0x0102
    1080:	90 91 03 01 	lds	r25, 0x0103
    1084:	e8 16       	cp	r14, r24
    1086:	f9 06       	cpc	r15, r25
    1088:	10 f4       	brcc	.+4      	; 0x108e <xTaskIncrementTick+0x78>

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    108a:	d1 2c       	mov	r13, r1
    108c:	53 c0       	rjmp	.+166    	; 0x1134 <xTaskIncrementTick+0x11e>
    108e:	d1 2c       	mov	r13, r1
							only be performed if the unblocked task has a
							priority that is equal to or higher than the
							currently executing task. */
							if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
							{
								xSwitchRequired = pdTRUE;
    1090:	cc 24       	eor	r12, r12
    1092:	c3 94       	inc	r12
			look any further down the list. */
			if( xConstTickCount >= xNextTaskUnblockTime )
			{
				for( ;; )
				{
					if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
    1094:	e0 91 c1 07 	lds	r30, 0x07C1
    1098:	f0 91 c2 07 	lds	r31, 0x07C2
    109c:	90 81       	ld	r25, Z
    109e:	91 11       	cpse	r25, r1
    10a0:	07 c0       	rjmp	.+14     	; 0x10b0 <xTaskIncrementTick+0x9a>
						/* The delayed list is empty.  Set xNextTaskUnblockTime
						to the maximum possible value so it is extremely
						unlikely that the
						if( xTickCount >= xNextTaskUnblockTime ) test will pass
						next time through. */
						xNextTaskUnblockTime = portMAX_DELAY;
    10a2:	8f ef       	ldi	r24, 0xFF	; 255
    10a4:	9f ef       	ldi	r25, 0xFF	; 255
    10a6:	90 93 03 01 	sts	0x0103, r25
    10aa:	80 93 02 01 	sts	0x0102, r24
						break;
    10ae:	42 c0       	rjmp	.+132    	; 0x1134 <xTaskIncrementTick+0x11e>
					{
						/* The delayed list is not empty, get the value of the
						item at the head of the delayed list.  This is the time
						at which the task at the head of the delayed list must
						be removed from the Blocked state. */
						pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
    10b0:	e0 91 c1 07 	lds	r30, 0x07C1
    10b4:	f0 91 c2 07 	lds	r31, 0x07C2
    10b8:	05 80       	ldd	r0, Z+5	; 0x05
    10ba:	f6 81       	ldd	r31, Z+6	; 0x06
    10bc:	e0 2d       	mov	r30, r0
    10be:	c6 81       	ldd	r28, Z+6	; 0x06
    10c0:	d7 81       	ldd	r29, Z+7	; 0x07
						xItemValue = listGET_LIST_ITEM_VALUE( &( pxTCB->xGenericListItem ) );
    10c2:	2a 81       	ldd	r18, Y+2	; 0x02
    10c4:	3b 81       	ldd	r19, Y+3	; 0x03

						if( xConstTickCount < xItemValue )
    10c6:	e2 16       	cp	r14, r18
    10c8:	f3 06       	cpc	r15, r19
    10ca:	28 f4       	brcc	.+10     	; 0x10d6 <xTaskIncrementTick+0xc0>
							/* It is not time to unblock this item yet, but the
							item value is the time at which the task at the head
							of the blocked list must be removed from the Blocked
							state -	so record the item value in
							xNextTaskUnblockTime. */
							xNextTaskUnblockTime = xItemValue;
    10cc:	30 93 03 01 	sts	0x0103, r19
    10d0:	20 93 02 01 	sts	0x0102, r18
							break;
    10d4:	2f c0       	rjmp	.+94     	; 0x1134 <xTaskIncrementTick+0x11e>
						{
							mtCOVERAGE_TEST_MARKER();
						}

						/* It is time to remove the item from the Blocked state. */
						( void ) uxListRemove( &( pxTCB->xGenericListItem ) );
    10d6:	8e 01       	movw	r16, r28
    10d8:	0e 5f       	subi	r16, 0xFE	; 254
    10da:	1f 4f       	sbci	r17, 0xFF	; 255
    10dc:	c8 01       	movw	r24, r16
    10de:	0e 94 4c 01 	call	0x298	; 0x298 <uxListRemove>

						/* Is the task waiting on an event also?  If so remove
						it from the event list. */
						if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    10e2:	8c 89       	ldd	r24, Y+20	; 0x14
    10e4:	9d 89       	ldd	r25, Y+21	; 0x15
    10e6:	89 2b       	or	r24, r25
    10e8:	21 f0       	breq	.+8      	; 0x10f2 <xTaskIncrementTick+0xdc>
						{
							( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    10ea:	ce 01       	movw	r24, r28
    10ec:	0c 96       	adiw	r24, 0x0c	; 12
    10ee:	0e 94 4c 01 	call	0x298	; 0x298 <uxListRemove>
							mtCOVERAGE_TEST_MARKER();
						}

						/* Place the unblocked task into the appropriate ready
						list. */
						prvAddTaskToReadyList( pxTCB );
    10f2:	2e 89       	ldd	r18, Y+22	; 0x16
    10f4:	80 91 9f 07 	lds	r24, 0x079F
    10f8:	82 17       	cp	r24, r18
    10fa:	10 f4       	brcc	.+4      	; 0x1100 <xTaskIncrementTick+0xea>
    10fc:	20 93 9f 07 	sts	0x079F, r18
    1100:	30 e0       	ldi	r19, 0x00	; 0
    1102:	c9 01       	movw	r24, r18
    1104:	88 0f       	add	r24, r24
    1106:	99 1f       	adc	r25, r25
    1108:	88 0f       	add	r24, r24
    110a:	99 1f       	adc	r25, r25
    110c:	88 0f       	add	r24, r24
    110e:	99 1f       	adc	r25, r25
    1110:	82 0f       	add	r24, r18
    1112:	93 1f       	adc	r25, r19
    1114:	b8 01       	movw	r22, r16
    1116:	8b 52       	subi	r24, 0x2B	; 43
    1118:	98 4f       	sbci	r25, 0xF8	; 248
    111a:	0e 94 fa 00 	call	0x1f4	; 0x1f4 <vListInsertEnd>
						{
							/* Preemption is on, but a context switch should
							only be performed if the unblocked task has a
							priority that is equal to or higher than the
							currently executing task. */
							if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    111e:	e0 91 f9 07 	lds	r30, 0x07F9
    1122:	f0 91 fa 07 	lds	r31, 0x07FA
    1126:	9e 89       	ldd	r25, Y+22	; 0x16
    1128:	86 89       	ldd	r24, Z+22	; 0x16
    112a:	98 17       	cp	r25, r24
    112c:	08 f4       	brcc	.+2      	; 0x1130 <xTaskIncrementTick+0x11a>
    112e:	b2 cf       	rjmp	.-156    	; 0x1094 <xTaskIncrementTick+0x7e>
							{
								xSwitchRequired = pdTRUE;
    1130:	dc 2c       	mov	r13, r12
    1132:	b0 cf       	rjmp	.-160    	; 0x1094 <xTaskIncrementTick+0x7e>
		/* Tasks of equal priority to the currently running task will share
		processing time (time slice) if preemption is on, and the application
		writer has not explicitly turned time slicing off. */
		#if ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) )
		{
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ pxCurrentTCB->uxPriority ] ) ) > ( UBaseType_t ) 1 )
    1134:	e0 91 f9 07 	lds	r30, 0x07F9
    1138:	f0 91 fa 07 	lds	r31, 0x07FA
    113c:	86 89       	ldd	r24, Z+22	; 0x16
    113e:	90 e0       	ldi	r25, 0x00	; 0
    1140:	fc 01       	movw	r30, r24
    1142:	ee 0f       	add	r30, r30
    1144:	ff 1f       	adc	r31, r31
    1146:	ee 0f       	add	r30, r30
    1148:	ff 1f       	adc	r31, r31
    114a:	ee 0f       	add	r30, r30
    114c:	ff 1f       	adc	r31, r31
    114e:	8e 0f       	add	r24, r30
    1150:	9f 1f       	adc	r25, r31
    1152:	fc 01       	movw	r30, r24
    1154:	eb 52       	subi	r30, 0x2B	; 43
    1156:	f8 4f       	sbci	r31, 0xF8	; 248
    1158:	80 81       	ld	r24, Z
    115a:	82 30       	cpi	r24, 0x02	; 2
    115c:	48 f0       	brcs	.+18     	; 0x1170 <xTaskIncrementTick+0x15a>
			{
				xSwitchRequired = pdTRUE;
    115e:	dd 24       	eor	r13, r13
    1160:	d3 94       	inc	r13
    1162:	06 c0       	rjmp	.+12     	; 0x1170 <xTaskIncrementTick+0x15a>
		}
		#endif /* configUSE_TICK_HOOK */
	}
	else
	{
		++uxPendedTicks;
    1164:	80 91 9d 07 	lds	r24, 0x079D
    1168:	8f 5f       	subi	r24, 0xFF	; 255
    116a:	80 93 9d 07 	sts	0x079D, r24

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    116e:	d1 2c       	mov	r13, r1
		#endif
	}

	#if ( configUSE_PREEMPTION == 1 )
	{
		if( xYieldPending != pdFALSE )
    1170:	80 91 9c 07 	lds	r24, 0x079C
    1174:	88 23       	and	r24, r24
    1176:	11 f0       	breq	.+4      	; 0x117c <xTaskIncrementTick+0x166>
		{
			xSwitchRequired = pdTRUE;
    1178:	dd 24       	eor	r13, r13
    117a:	d3 94       	inc	r13
		}
	}
	#endif /* configUSE_PREEMPTION */

	return xSwitchRequired;
}
    117c:	8d 2d       	mov	r24, r13
    117e:	df 91       	pop	r29
    1180:	cf 91       	pop	r28
    1182:	1f 91       	pop	r17
    1184:	0f 91       	pop	r16
    1186:	ff 90       	pop	r15
    1188:	ef 90       	pop	r14
    118a:	df 90       	pop	r13
    118c:	cf 90       	pop	r12
    118e:	08 95       	ret

00001190 <xTaskResumeAll>:

#endif /* configUSE_TICKLESS_IDLE */
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
    1190:	df 92       	push	r13
    1192:	ef 92       	push	r14
    1194:	ff 92       	push	r15
    1196:	0f 93       	push	r16
    1198:	1f 93       	push	r17
    119a:	cf 93       	push	r28
    119c:	df 93       	push	r29
	/* It is possible that an ISR caused a task to be removed from an event
	list while the scheduler was suspended.  If this was the case then the
	removed task will have been added to the xPendingReadyList.  Once the
	scheduler has been resumed it is safe to move all the pending ready
	tasks from this list into their appropriate ready list. */
	taskENTER_CRITICAL();
    119e:	0f b6       	in	r0, 0x3f	; 63
    11a0:	f8 94       	cli
    11a2:	0f 92       	push	r0
	{
		--uxSchedulerSuspended;
    11a4:	80 91 99 07 	lds	r24, 0x0799
    11a8:	81 50       	subi	r24, 0x01	; 1
    11aa:	80 93 99 07 	sts	0x0799, r24

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    11ae:	80 91 99 07 	lds	r24, 0x0799
    11b2:	81 11       	cpse	r24, r1
    11b4:	62 c0       	rjmp	.+196    	; 0x127a <xTaskResumeAll+0xea>
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
    11b6:	80 91 a2 07 	lds	r24, 0x07A2
    11ba:	81 11       	cpse	r24, r1
    11bc:	33 c0       	rjmp	.+102    	; 0x1224 <xTaskResumeAll+0x94>
    11be:	60 c0       	rjmp	.+192    	; 0x1280 <xTaskResumeAll+0xf0>
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
				{
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xPendingReadyList ) );
    11c0:	d7 01       	movw	r26, r14
    11c2:	15 96       	adiw	r26, 0x05	; 5
    11c4:	ed 91       	ld	r30, X+
    11c6:	fc 91       	ld	r31, X
    11c8:	16 97       	sbiw	r26, 0x06	; 6
    11ca:	c6 81       	ldd	r28, Z+6	; 0x06
    11cc:	d7 81       	ldd	r29, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    11ce:	ce 01       	movw	r24, r28
    11d0:	0c 96       	adiw	r24, 0x0c	; 12
    11d2:	0e 94 4c 01 	call	0x298	; 0x298 <uxListRemove>
					( void ) uxListRemove( &( pxTCB->xGenericListItem ) );
    11d6:	8e 01       	movw	r16, r28
    11d8:	0e 5f       	subi	r16, 0xFE	; 254
    11da:	1f 4f       	sbci	r17, 0xFF	; 255
    11dc:	c8 01       	movw	r24, r16
    11de:	0e 94 4c 01 	call	0x298	; 0x298 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    11e2:	2e 89       	ldd	r18, Y+22	; 0x16
    11e4:	80 91 9f 07 	lds	r24, 0x079F
    11e8:	82 17       	cp	r24, r18
    11ea:	10 f4       	brcc	.+4      	; 0x11f0 <xTaskResumeAll+0x60>
    11ec:	20 93 9f 07 	sts	0x079F, r18
    11f0:	30 e0       	ldi	r19, 0x00	; 0
    11f2:	c9 01       	movw	r24, r18
    11f4:	88 0f       	add	r24, r24
    11f6:	99 1f       	adc	r25, r25
    11f8:	88 0f       	add	r24, r24
    11fa:	99 1f       	adc	r25, r25
    11fc:	88 0f       	add	r24, r24
    11fe:	99 1f       	adc	r25, r25
    1200:	82 0f       	add	r24, r18
    1202:	93 1f       	adc	r25, r19
    1204:	b8 01       	movw	r22, r16
    1206:	8b 52       	subi	r24, 0x2B	; 43
    1208:	98 4f       	sbci	r25, 0xF8	; 248
    120a:	0e 94 fa 00 	call	0x1f4	; 0x1f4 <vListInsertEnd>

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    120e:	e0 91 f9 07 	lds	r30, 0x07F9
    1212:	f0 91 fa 07 	lds	r31, 0x07FA
    1216:	9e 89       	ldd	r25, Y+22	; 0x16
    1218:	86 89       	ldd	r24, Z+22	; 0x16
    121a:	98 17       	cp	r25, r24
    121c:	58 f0       	brcs	.+22     	; 0x1234 <xTaskResumeAll+0xa4>
					{
						xYieldPending = pdTRUE;
    121e:	d0 92 9c 07 	sts	0x079C, r13
    1222:	08 c0       	rjmp	.+16     	; 0x1234 <xTaskResumeAll+0xa4>
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    1224:	0f 2e       	mov	r0, r31
    1226:	f6 eb       	ldi	r31, 0xB6	; 182
    1228:	ef 2e       	mov	r14, r31
    122a:	f7 e0       	ldi	r31, 0x07	; 7
    122c:	ff 2e       	mov	r15, r31
    122e:	f0 2d       	mov	r31, r0

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
					{
						xYieldPending = pdTRUE;
    1230:	dd 24       	eor	r13, r13
    1232:	d3 94       	inc	r13
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    1234:	f7 01       	movw	r30, r14
    1236:	80 81       	ld	r24, Z
    1238:	81 11       	cpse	r24, r1
    123a:	c2 cf       	rjmp	.-124    	; 0x11c0 <xTaskResumeAll+0x30>

				/* If any ticks occurred while the scheduler was suspended then
				they should be processed now.  This ensures the tick count does
				not	slip, and that any delayed tasks are resumed at the correct
				time. */
				if( uxPendedTicks > ( UBaseType_t ) 0U )
    123c:	80 91 9d 07 	lds	r24, 0x079D
    1240:	88 23       	and	r24, r24
    1242:	99 f0       	breq	.+38     	; 0x126a <xTaskResumeAll+0xda>
				{
					while( uxPendedTicks > ( UBaseType_t ) 0U )
    1244:	80 91 9d 07 	lds	r24, 0x079D
    1248:	88 23       	and	r24, r24
    124a:	79 f0       	breq	.+30     	; 0x126a <xTaskResumeAll+0xda>
					{
						if( xTaskIncrementTick() != pdFALSE )
						{
							xYieldPending = pdTRUE;
    124c:	c1 e0       	ldi	r28, 0x01	; 1
				time. */
				if( uxPendedTicks > ( UBaseType_t ) 0U )
				{
					while( uxPendedTicks > ( UBaseType_t ) 0U )
					{
						if( xTaskIncrementTick() != pdFALSE )
    124e:	0e 94 0b 08 	call	0x1016	; 0x1016 <xTaskIncrementTick>
    1252:	81 11       	cpse	r24, r1
						{
							xYieldPending = pdTRUE;
    1254:	c0 93 9c 07 	sts	0x079C, r28
						}
						else
						{
							mtCOVERAGE_TEST_MARKER();
						}
						--uxPendedTicks;
    1258:	80 91 9d 07 	lds	r24, 0x079D
    125c:	81 50       	subi	r24, 0x01	; 1
    125e:	80 93 9d 07 	sts	0x079D, r24
				they should be processed now.  This ensures the tick count does
				not	slip, and that any delayed tasks are resumed at the correct
				time. */
				if( uxPendedTicks > ( UBaseType_t ) 0U )
				{
					while( uxPendedTicks > ( UBaseType_t ) 0U )
    1262:	80 91 9d 07 	lds	r24, 0x079D
    1266:	81 11       	cpse	r24, r1
    1268:	f2 cf       	rjmp	.-28     	; 0x124e <xTaskResumeAll+0xbe>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				if( xYieldPending == pdTRUE )
    126a:	80 91 9c 07 	lds	r24, 0x079C
    126e:	81 30       	cpi	r24, 0x01	; 1
    1270:	31 f4       	brne	.+12     	; 0x127e <xTaskResumeAll+0xee>
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
					}
					#endif
					taskYIELD_IF_USING_PREEMPTION();
    1272:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>

				if( xYieldPending == pdTRUE )
				{
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
    1276:	81 e0       	ldi	r24, 0x01	; 1
    1278:	03 c0       	rjmp	.+6      	; 0x1280 <xTaskResumeAll+0xf0>
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
TCB_t *pxTCB;
BaseType_t xAlreadyYielded = pdFALSE;
    127a:	80 e0       	ldi	r24, 0x00	; 0
    127c:	01 c0       	rjmp	.+2      	; 0x1280 <xTaskResumeAll+0xf0>
    127e:	80 e0       	ldi	r24, 0x00	; 0
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
	taskEXIT_CRITICAL();
    1280:	0f 90       	pop	r0
    1282:	0f be       	out	0x3f, r0	; 63

	return xAlreadyYielded;
}
    1284:	df 91       	pop	r29
    1286:	cf 91       	pop	r28
    1288:	1f 91       	pop	r17
    128a:	0f 91       	pop	r16
    128c:	ff 90       	pop	r15
    128e:	ef 90       	pop	r14
    1290:	df 90       	pop	r13
    1292:	08 95       	ret

00001294 <vTaskDelayUntil>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelayUntil == 1 )

	void vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement )
	{
    1294:	0f 93       	push	r16
    1296:	1f 93       	push	r17
    1298:	cf 93       	push	r28
    129a:	df 93       	push	r29
    129c:	8c 01       	movw	r16, r24
    129e:	eb 01       	movw	r28, r22

		configASSERT( pxPreviousWakeTime );
		configASSERT( ( xTimeIncrement > 0U ) );
		configASSERT( uxSchedulerSuspended == 0 );

		vTaskSuspendAll();
    12a0:	0e 94 fb 07 	call	0xff6	; 0xff6 <vTaskSuspendAll>
		{
			/* Minor optimisation.  The tick count cannot change in this
			block. */
			const TickType_t xConstTickCount = xTickCount;
    12a4:	80 91 a0 07 	lds	r24, 0x07A0
    12a8:	90 91 a1 07 	lds	r25, 0x07A1

			/* Generate the tick time at which the task wants to wake. */
			xTimeToWake = *pxPreviousWakeTime + xTimeIncrement;
    12ac:	f8 01       	movw	r30, r16
    12ae:	20 81       	ld	r18, Z
    12b0:	31 81       	ldd	r19, Z+1	; 0x01
    12b2:	c2 0f       	add	r28, r18
    12b4:	d3 1f       	adc	r29, r19

			if( xConstTickCount < *pxPreviousWakeTime )
    12b6:	82 17       	cp	r24, r18
    12b8:	93 07       	cpc	r25, r19
    12ba:	48 f4       	brcc	.+18     	; 0x12ce <vTaskDelayUntil+0x3a>
				/* The tick count has overflowed since this function was
				lasted called.  In this case the only time we should ever
				actually delay is if the wake time has also	overflowed,
				and the wake time is greater than the tick time.  When this
				is the case it is as if neither time had overflowed. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) && ( xTimeToWake > xConstTickCount ) )
    12bc:	c2 17       	cp	r28, r18
    12be:	d3 07       	cpc	r29, r19
    12c0:	10 f5       	brcc	.+68     	; 0x1306 <vTaskDelayUntil+0x72>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    12c2:	d1 83       	std	Z+1, r29	; 0x01
    12c4:	c0 83       	st	Z, r28

			if( xShouldDelay != pdFALSE )
    12c6:	8c 17       	cp	r24, r28
    12c8:	9d 07       	cpc	r25, r29
    12ca:	90 f4       	brcc	.+36     	; 0x12f0 <vTaskDelayUntil+0x5c>
    12cc:	07 c0       	rjmp	.+14     	; 0x12dc <vTaskDelayUntil+0x48>
			else
			{
				/* The tick time has not overflowed.  In this case we will
				delay if either the wake time has overflowed, and/or the
				tick time is less than the wake time. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) || ( xTimeToWake > xConstTickCount ) )
    12ce:	c2 17       	cp	r28, r18
    12d0:	d3 07       	cpc	r29, r19
    12d2:	a8 f0       	brcs	.+42     	; 0x12fe <vTaskDelayUntil+0x6a>
    12d4:	8c 17       	cp	r24, r28
    12d6:	9d 07       	cpc	r25, r29
    12d8:	90 f0       	brcs	.+36     	; 0x12fe <vTaskDelayUntil+0x6a>
    12da:	15 c0       	rjmp	.+42     	; 0x1306 <vTaskDelayUntil+0x72>
			{
				traceTASK_DELAY_UNTIL();

				/* Remove the task from the ready list before adding it to the
				blocked list as the same list item is used for both lists. */
				if( uxListRemove( &( pxCurrentTCB->xGenericListItem ) ) == ( UBaseType_t ) 0 )
    12dc:	80 91 f9 07 	lds	r24, 0x07F9
    12e0:	90 91 fa 07 	lds	r25, 0x07FA
    12e4:	02 96       	adiw	r24, 0x02	; 2
    12e6:	0e 94 4c 01 	call	0x298	; 0x298 <uxListRemove>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				prvAddCurrentTaskToDelayedList( xTimeToWake );
    12ea:	ce 01       	movw	r24, r28
    12ec:	0e 94 88 06 	call	0xd10	; 0xd10 <prvAddCurrentTaskToDelayedList>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		xAlreadyYielded = xTaskResumeAll();
    12f0:	0e 94 c8 08 	call	0x1190	; 0x1190 <xTaskResumeAll>

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
    12f4:	81 11       	cpse	r24, r1
    12f6:	0b c0       	rjmp	.+22     	; 0x130e <vTaskDelayUntil+0x7a>
		{
			portYIELD_WITHIN_API();
    12f8:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>
    12fc:	08 c0       	rjmp	.+16     	; 0x130e <vTaskDelayUntil+0x7a>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    12fe:	f8 01       	movw	r30, r16
    1300:	d1 83       	std	Z+1, r29	; 0x01
    1302:	c0 83       	st	Z, r28
    1304:	eb cf       	rjmp	.-42     	; 0x12dc <vTaskDelayUntil+0x48>
    1306:	f8 01       	movw	r30, r16
    1308:	d1 83       	std	Z+1, r29	; 0x01
    130a:	c0 83       	st	Z, r28
    130c:	f1 cf       	rjmp	.-30     	; 0x12f0 <vTaskDelayUntil+0x5c>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    130e:	df 91       	pop	r29
    1310:	cf 91       	pop	r28
    1312:	1f 91       	pop	r17
    1314:	0f 91       	pop	r16
    1316:	08 95       	ret

00001318 <prvIdleTask>:
		too often in the idle task. */
		while( uxTasksDeleted > ( UBaseType_t ) 0U )
		{
			vTaskSuspendAll();
			{
				xListIsEmpty = listLIST_IS_EMPTY( &xTasksWaitingTermination );
    1318:	0d ea       	ldi	r16, 0xAD	; 173
    131a:	17 e0       	ldi	r17, 0x07	; 7

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    131c:	0f 2e       	mov	r0, r31
    131e:	f5 ed       	ldi	r31, 0xD5	; 213
    1320:	ef 2e       	mov	r14, r31
    1322:	f7 e0       	ldi	r31, 0x07	; 7
    1324:	ff 2e       	mov	r15, r31
    1326:	f0 2d       	mov	r31, r0
    1328:	29 c0       	rjmp	.+82     	; 0x137c <prvIdleTask+0x64>

		/* ucTasksDeleted is used to prevent vTaskSuspendAll() being called
		too often in the idle task. */
		while( uxTasksDeleted > ( UBaseType_t ) 0U )
		{
			vTaskSuspendAll();
    132a:	0e 94 fb 07 	call	0xff6	; 0xff6 <vTaskSuspendAll>
			{
				xListIsEmpty = listLIST_IS_EMPTY( &xTasksWaitingTermination );
    132e:	d8 01       	movw	r26, r16
    1330:	cc 91       	ld	r28, X
			}
			( void ) xTaskResumeAll();
    1332:	0e 94 c8 08 	call	0x1190	; 0x1190 <xTaskResumeAll>

			if( xListIsEmpty == pdFALSE )
    1336:	cc 23       	and	r28, r28
    1338:	09 f1       	breq	.+66     	; 0x137c <prvIdleTask+0x64>
			{
				TCB_t *pxTCB;

				taskENTER_CRITICAL();
    133a:	0f b6       	in	r0, 0x3f	; 63
    133c:	f8 94       	cli
    133e:	0f 92       	push	r0
				{
					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xTasksWaitingTermination ) );
    1340:	d8 01       	movw	r26, r16
    1342:	15 96       	adiw	r26, 0x05	; 5
    1344:	ed 91       	ld	r30, X+
    1346:	fc 91       	ld	r31, X
    1348:	16 97       	sbiw	r26, 0x06	; 6
    134a:	c6 81       	ldd	r28, Z+6	; 0x06
    134c:	d7 81       	ldd	r29, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xGenericListItem ) );
    134e:	ce 01       	movw	r24, r28
    1350:	02 96       	adiw	r24, 0x02	; 2
    1352:	0e 94 4c 01 	call	0x298	; 0x298 <uxListRemove>
					--uxCurrentNumberOfTasks;
    1356:	80 91 a2 07 	lds	r24, 0x07A2
    135a:	81 50       	subi	r24, 0x01	; 1
    135c:	80 93 a2 07 	sts	0x07A2, r24
					--uxTasksDeleted;
    1360:	80 91 ac 07 	lds	r24, 0x07AC
    1364:	81 50       	subi	r24, 0x01	; 1
    1366:	80 93 ac 07 	sts	0x07AC, r24
				}
				taskEXIT_CRITICAL();
    136a:	0f 90       	pop	r0
    136c:	0f be       	out	0x3f, r0	; 63
				vPortFreeAligned( pxTCB->pxStack );
			}
		}
		#else
		{
			vPortFreeAligned( pxTCB->pxStack );
    136e:	8f 89       	ldd	r24, Y+23	; 0x17
    1370:	98 8d       	ldd	r25, Y+24	; 0x18
    1372:	0e 94 74 03 	call	0x6e8	; 0x6e8 <vPortFree>
		}
		#endif

		vPortFree( pxTCB );
    1376:	ce 01       	movw	r24, r28
    1378:	0e 94 74 03 	call	0x6e8	; 0x6e8 <vPortFree>
	{
		BaseType_t xListIsEmpty;

		/* ucTasksDeleted is used to prevent vTaskSuspendAll() being called
		too often in the idle task. */
		while( uxTasksDeleted > ( UBaseType_t ) 0U )
    137c:	80 91 ac 07 	lds	r24, 0x07AC
    1380:	81 11       	cpse	r24, r1
    1382:	d3 cf       	rjmp	.-90     	; 0x132a <prvIdleTask+0x12>

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    1384:	f7 01       	movw	r30, r14
    1386:	80 81       	ld	r24, Z
    1388:	82 30       	cpi	r24, 0x02	; 2
    138a:	c0 f3       	brcs	.-16     	; 0x137c <prvIdleTask+0x64>
			{
				taskYIELD();
    138c:	0e 94 18 02 	call	0x430	; 0x430 <vPortYield>
    1390:	f5 cf       	rjmp	.-22     	; 0x137c <prvIdleTask+0x64>

00001392 <vTaskSwitchContext>:
#endif /* configUSE_APPLICATION_TASK_TAG */
/*-----------------------------------------------------------*/

void vTaskSwitchContext( void )
{
	if( uxSchedulerSuspended != ( UBaseType_t ) pdFALSE )
    1392:	80 91 99 07 	lds	r24, 0x0799
    1396:	88 23       	and	r24, r24
    1398:	21 f0       	breq	.+8      	; 0x13a2 <vTaskSwitchContext+0x10>
	{
		/* The scheduler is currently suspended - do not allow a context
		switch. */
		xYieldPending = pdTRUE;
    139a:	81 e0       	ldi	r24, 0x01	; 1
    139c:	80 93 9c 07 	sts	0x079C, r24
    13a0:	08 95       	ret
	}
	else
	{
		xYieldPending = pdFALSE;
    13a2:	10 92 9c 07 	sts	0x079C, r1
		taskFIRST_CHECK_FOR_STACK_OVERFLOW();
		taskSECOND_CHECK_FOR_STACK_OVERFLOW();

		/* Select a new task to run using either the generic C or port
		optimised asm code. */
		taskSELECT_HIGHEST_PRIORITY_TASK();
    13a6:	80 91 9f 07 	lds	r24, 0x079F
    13aa:	90 e0       	ldi	r25, 0x00	; 0
    13ac:	fc 01       	movw	r30, r24
    13ae:	ee 0f       	add	r30, r30
    13b0:	ff 1f       	adc	r31, r31
    13b2:	ee 0f       	add	r30, r30
    13b4:	ff 1f       	adc	r31, r31
    13b6:	ee 0f       	add	r30, r30
    13b8:	ff 1f       	adc	r31, r31
    13ba:	8e 0f       	add	r24, r30
    13bc:	9f 1f       	adc	r25, r31
    13be:	fc 01       	movw	r30, r24
    13c0:	eb 52       	subi	r30, 0x2B	; 43
    13c2:	f8 4f       	sbci	r31, 0xF8	; 248
    13c4:	80 81       	ld	r24, Z
    13c6:	81 11       	cpse	r24, r1
    13c8:	17 c0       	rjmp	.+46     	; 0x13f8 <vTaskSwitchContext+0x66>
    13ca:	80 91 9f 07 	lds	r24, 0x079F
    13ce:	81 50       	subi	r24, 0x01	; 1
    13d0:	80 93 9f 07 	sts	0x079F, r24
    13d4:	80 91 9f 07 	lds	r24, 0x079F
    13d8:	90 e0       	ldi	r25, 0x00	; 0
    13da:	fc 01       	movw	r30, r24
    13dc:	ee 0f       	add	r30, r30
    13de:	ff 1f       	adc	r31, r31
    13e0:	ee 0f       	add	r30, r30
    13e2:	ff 1f       	adc	r31, r31
    13e4:	ee 0f       	add	r30, r30
    13e6:	ff 1f       	adc	r31, r31
    13e8:	8e 0f       	add	r24, r30
    13ea:	9f 1f       	adc	r25, r31
    13ec:	fc 01       	movw	r30, r24
    13ee:	eb 52       	subi	r30, 0x2B	; 43
    13f0:	f8 4f       	sbci	r31, 0xF8	; 248
    13f2:	80 81       	ld	r24, Z
    13f4:	88 23       	and	r24, r24
    13f6:	49 f3       	breq	.-46     	; 0x13ca <vTaskSwitchContext+0x38>
    13f8:	80 91 9f 07 	lds	r24, 0x079F
    13fc:	90 e0       	ldi	r25, 0x00	; 0
    13fe:	9c 01       	movw	r18, r24
    1400:	22 0f       	add	r18, r18
    1402:	33 1f       	adc	r19, r19
    1404:	22 0f       	add	r18, r18
    1406:	33 1f       	adc	r19, r19
    1408:	22 0f       	add	r18, r18
    140a:	33 1f       	adc	r19, r19
    140c:	28 0f       	add	r18, r24
    140e:	39 1f       	adc	r19, r25
    1410:	d9 01       	movw	r26, r18
    1412:	ab 52       	subi	r26, 0x2B	; 43
    1414:	b8 4f       	sbci	r27, 0xF8	; 248
    1416:	11 96       	adiw	r26, 0x01	; 1
    1418:	ed 91       	ld	r30, X+
    141a:	fc 91       	ld	r31, X
    141c:	12 97       	sbiw	r26, 0x02	; 2
    141e:	02 80       	ldd	r0, Z+2	; 0x02
    1420:	f3 81       	ldd	r31, Z+3	; 0x03
    1422:	e0 2d       	mov	r30, r0
    1424:	12 96       	adiw	r26, 0x02	; 2
    1426:	fc 93       	st	X, r31
    1428:	ee 93       	st	-X, r30
    142a:	11 97       	sbiw	r26, 0x01	; 1
    142c:	28 52       	subi	r18, 0x28	; 40
    142e:	38 4f       	sbci	r19, 0xF8	; 248
    1430:	e2 17       	cp	r30, r18
    1432:	f3 07       	cpc	r31, r19
    1434:	29 f4       	brne	.+10     	; 0x1440 <vTaskSwitchContext+0xae>
    1436:	22 81       	ldd	r18, Z+2	; 0x02
    1438:	33 81       	ldd	r19, Z+3	; 0x03
    143a:	fd 01       	movw	r30, r26
    143c:	32 83       	std	Z+2, r19	; 0x02
    143e:	21 83       	std	Z+1, r18	; 0x01
    1440:	fc 01       	movw	r30, r24
    1442:	ee 0f       	add	r30, r30
    1444:	ff 1f       	adc	r31, r31
    1446:	ee 0f       	add	r30, r30
    1448:	ff 1f       	adc	r31, r31
    144a:	ee 0f       	add	r30, r30
    144c:	ff 1f       	adc	r31, r31
    144e:	8e 0f       	add	r24, r30
    1450:	9f 1f       	adc	r25, r31
    1452:	fc 01       	movw	r30, r24
    1454:	eb 52       	subi	r30, 0x2B	; 43
    1456:	f8 4f       	sbci	r31, 0xF8	; 248
    1458:	01 80       	ldd	r0, Z+1	; 0x01
    145a:	f2 81       	ldd	r31, Z+2	; 0x02
    145c:	e0 2d       	mov	r30, r0
    145e:	86 81       	ldd	r24, Z+6	; 0x06
    1460:	97 81       	ldd	r25, Z+7	; 0x07
    1462:	90 93 fa 07 	sts	0x07FA, r25
    1466:	80 93 f9 07 	sts	0x07F9, r24
    146a:	08 95       	ret

0000146c <vTaskPlaceOnEventList>:
	}
}
/*-----------------------------------------------------------*/

void vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait )
{
    146c:	cf 93       	push	r28
    146e:	df 93       	push	r29
    1470:	eb 01       	movw	r28, r22

	/* Place the event list item of the TCB in the appropriate event list.
	This is placed in the list in priority order so the highest priority task
	is the first to be woken by the event.  The queue that contains the event
	list is locked, preventing simultaneous access from interrupts. */
	vListInsert( pxEventList, &( pxCurrentTCB->xEventListItem ) );
    1472:	20 91 f9 07 	lds	r18, 0x07F9
    1476:	30 91 fa 07 	lds	r19, 0x07FA
    147a:	b9 01       	movw	r22, r18
    147c:	64 5f       	subi	r22, 0xF4	; 244
    147e:	7f 4f       	sbci	r23, 0xFF	; 255
    1480:	0e 94 1b 01 	call	0x236	; 0x236 <vListInsert>

	/* The task must be removed from from the ready list before it is added to
	the blocked list as the same list item is used for both lists.  Exclusive
	access to the ready lists guaranteed because the scheduler is locked. */
	if( uxListRemove( &( pxCurrentTCB->xGenericListItem ) ) == ( UBaseType_t ) 0 )
    1484:	80 91 f9 07 	lds	r24, 0x07F9
    1488:	90 91 fa 07 	lds	r25, 0x07FA
    148c:	02 96       	adiw	r24, 0x02	; 2
    148e:	0e 94 4c 01 	call	0x298	; 0x298 <uxListRemove>
		mtCOVERAGE_TEST_MARKER();
	}

	#if ( INCLUDE_vTaskSuspend == 1 )
	{
		if( xTicksToWait == portMAX_DELAY )
    1492:	cf 3f       	cpi	r28, 0xFF	; 255
    1494:	8f ef       	ldi	r24, 0xFF	; 255
    1496:	d8 07       	cpc	r29, r24
    1498:	59 f4       	brne	.+22     	; 0x14b0 <vTaskPlaceOnEventList+0x44>
		{
			/* Add the task to the suspended task list instead of a delayed task
			list to ensure the task is not woken by a timing event.  It will
			block indefinitely. */
			vListInsertEnd( &xSuspendedTaskList, &( pxCurrentTCB->xGenericListItem ) );
    149a:	60 91 f9 07 	lds	r22, 0x07F9
    149e:	70 91 fa 07 	lds	r23, 0x07FA
    14a2:	6e 5f       	subi	r22, 0xFE	; 254
    14a4:	7f 4f       	sbci	r23, 0xFF	; 255
    14a6:	83 ea       	ldi	r24, 0xA3	; 163
    14a8:	97 e0       	ldi	r25, 0x07	; 7
    14aa:	0e 94 fa 00 	call	0x1f4	; 0x1f4 <vListInsertEnd>
    14ae:	08 c0       	rjmp	.+16     	; 0x14c0 <vTaskPlaceOnEventList+0x54>
		else
		{
			/* Calculate the time at which the task should be woken if the event
			does not occur.  This may overflow but this doesn't matter, the
			scheduler will handle it. */
			xTimeToWake = xTickCount + xTicksToWait;
    14b0:	80 91 a0 07 	lds	r24, 0x07A0
    14b4:	90 91 a1 07 	lds	r25, 0x07A1
			prvAddCurrentTaskToDelayedList( xTimeToWake );
    14b8:	8c 0f       	add	r24, r28
    14ba:	9d 1f       	adc	r25, r29
    14bc:	0e 94 88 06 	call	0xd10	; 0xd10 <prvAddCurrentTaskToDelayedList>
			will handle it. */
			xTimeToWake = xTickCount + xTicksToWait;
			prvAddCurrentTaskToDelayedList( xTimeToWake );
	}
	#endif /* INCLUDE_vTaskSuspend */
}
    14c0:	df 91       	pop	r29
    14c2:	cf 91       	pop	r28
    14c4:	08 95       	ret

000014c6 <xTaskRemoveFromEventList>:

#endif /* configUSE_TIMERS */
/*-----------------------------------------------------------*/

BaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList )
{
    14c6:	0f 93       	push	r16
    14c8:	1f 93       	push	r17
    14ca:	cf 93       	push	r28
    14cc:	df 93       	push	r29
	get called - the lock count on the queue will get modified instead.  This
	means exclusive access to the event list is guaranteed here.

	This function assumes that a check has already been made to ensure that
	pxEventList is not empty. */
	pxUnblockedTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxEventList );
    14ce:	dc 01       	movw	r26, r24
    14d0:	15 96       	adiw	r26, 0x05	; 5
    14d2:	ed 91       	ld	r30, X+
    14d4:	fc 91       	ld	r31, X
    14d6:	16 97       	sbiw	r26, 0x06	; 6
    14d8:	c6 81       	ldd	r28, Z+6	; 0x06
    14da:	d7 81       	ldd	r29, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( &( pxUnblockedTCB->xEventListItem ) );
    14dc:	8e 01       	movw	r16, r28
    14de:	04 5f       	subi	r16, 0xF4	; 244
    14e0:	1f 4f       	sbci	r17, 0xFF	; 255
    14e2:	c8 01       	movw	r24, r16
    14e4:	0e 94 4c 01 	call	0x298	; 0x298 <uxListRemove>

	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    14e8:	80 91 99 07 	lds	r24, 0x0799
    14ec:	81 11       	cpse	r24, r1
    14ee:	1c c0       	rjmp	.+56     	; 0x1528 <xTaskRemoveFromEventList+0x62>
	{
		( void ) uxListRemove( &( pxUnblockedTCB->xGenericListItem ) );
    14f0:	0a 50       	subi	r16, 0x0A	; 10
    14f2:	11 09       	sbc	r17, r1
    14f4:	c8 01       	movw	r24, r16
    14f6:	0e 94 4c 01 	call	0x298	; 0x298 <uxListRemove>
		prvAddTaskToReadyList( pxUnblockedTCB );
    14fa:	2e 89       	ldd	r18, Y+22	; 0x16
    14fc:	80 91 9f 07 	lds	r24, 0x079F
    1500:	82 17       	cp	r24, r18
    1502:	10 f4       	brcc	.+4      	; 0x1508 <xTaskRemoveFromEventList+0x42>
    1504:	20 93 9f 07 	sts	0x079F, r18
    1508:	30 e0       	ldi	r19, 0x00	; 0
    150a:	c9 01       	movw	r24, r18
    150c:	88 0f       	add	r24, r24
    150e:	99 1f       	adc	r25, r25
    1510:	88 0f       	add	r24, r24
    1512:	99 1f       	adc	r25, r25
    1514:	88 0f       	add	r24, r24
    1516:	99 1f       	adc	r25, r25
    1518:	82 0f       	add	r24, r18
    151a:	93 1f       	adc	r25, r19
    151c:	b8 01       	movw	r22, r16
    151e:	8b 52       	subi	r24, 0x2B	; 43
    1520:	98 4f       	sbci	r25, 0xF8	; 248
    1522:	0e 94 fa 00 	call	0x1f4	; 0x1f4 <vListInsertEnd>
    1526:	05 c0       	rjmp	.+10     	; 0x1532 <xTaskRemoveFromEventList+0x6c>
	}
	else
	{
		/* The delayed and ready lists cannot be accessed, so hold this task
		pending until the scheduler is resumed. */
		vListInsertEnd( &( xPendingReadyList ), &( pxUnblockedTCB->xEventListItem ) );
    1528:	b8 01       	movw	r22, r16
    152a:	86 eb       	ldi	r24, 0xB6	; 182
    152c:	97 e0       	ldi	r25, 0x07	; 7
    152e:	0e 94 fa 00 	call	0x1f4	; 0x1f4 <vListInsertEnd>
	}

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
    1532:	e0 91 f9 07 	lds	r30, 0x07F9
    1536:	f0 91 fa 07 	lds	r31, 0x07FA
    153a:	9e 89       	ldd	r25, Y+22	; 0x16
    153c:	86 89       	ldd	r24, Z+22	; 0x16
    153e:	89 17       	cp	r24, r25
    1540:	20 f4       	brcc	.+8      	; 0x154a <xTaskRemoveFromEventList+0x84>
		it should force a context switch now. */
		xReturn = pdTRUE;

		/* Mark that a yield is pending in case the user is not using the
		"xHigherPriorityTaskWoken" parameter to an ISR safe FreeRTOS function. */
		xYieldPending = pdTRUE;
    1542:	81 e0       	ldi	r24, 0x01	; 1
    1544:	80 93 9c 07 	sts	0x079C, r24
    1548:	01 c0       	rjmp	.+2      	; 0x154c <xTaskRemoveFromEventList+0x86>
	}
	else
	{
		xReturn = pdFALSE;
    154a:	80 e0       	ldi	r24, 0x00	; 0
		prvResetNextTaskUnblockTime();
	}
	#endif

	return xReturn;
}
    154c:	df 91       	pop	r29
    154e:	cf 91       	pop	r28
    1550:	1f 91       	pop	r17
    1552:	0f 91       	pop	r16
    1554:	08 95       	ret

00001556 <vTaskSetTimeOutState>:
/*-----------------------------------------------------------*/

void vTaskSetTimeOutState( TimeOut_t * const pxTimeOut )
{
	configASSERT( pxTimeOut );
	pxTimeOut->xOverflowCount = xNumOfOverflows;
    1556:	20 91 9b 07 	lds	r18, 0x079B
    155a:	fc 01       	movw	r30, r24
    155c:	20 83       	st	Z, r18
	pxTimeOut->xTimeOnEntering = xTickCount;
    155e:	20 91 a0 07 	lds	r18, 0x07A0
    1562:	30 91 a1 07 	lds	r19, 0x07A1
    1566:	32 83       	std	Z+2, r19	; 0x02
    1568:	21 83       	std	Z+1, r18	; 0x01
    156a:	08 95       	ret

0000156c <xTaskCheckForTimeOut>:
BaseType_t xReturn;

	configASSERT( pxTimeOut );
	configASSERT( pxTicksToWait );

	taskENTER_CRITICAL();
    156c:	0f b6       	in	r0, 0x3f	; 63
    156e:	f8 94       	cli
    1570:	0f 92       	push	r0
	{
		/* Minor optimisation.  The tick count cannot change in this block. */
		const TickType_t xConstTickCount = xTickCount;
    1572:	40 91 a0 07 	lds	r20, 0x07A0
    1576:	50 91 a1 07 	lds	r21, 0x07A1

		#if ( INCLUDE_vTaskSuspend == 1 )
			/* If INCLUDE_vTaskSuspend is set to 1 and the block time specified is
			the maximum block time then the task should block indefinitely, and
			therefore never time out. */
			if( *pxTicksToWait == portMAX_DELAY )
    157a:	db 01       	movw	r26, r22
    157c:	2d 91       	ld	r18, X+
    157e:	3c 91       	ld	r19, X
    1580:	2f 3f       	cpi	r18, 0xFF	; 255
    1582:	bf ef       	ldi	r27, 0xFF	; 255
    1584:	3b 07       	cpc	r19, r27
    1586:	19 f1       	breq	.+70     	; 0x15ce <xTaskCheckForTimeOut+0x62>
				xReturn = pdFALSE;
			}
			else /* We are not blocking indefinitely, perform the checks below. */
		#endif

		if( ( xNumOfOverflows != pxTimeOut->xOverflowCount ) && ( xConstTickCount >= pxTimeOut->xTimeOnEntering ) ) /*lint !e525 Indentation preferred as is to make code within pre-processor directives clearer. */
    1588:	e0 91 9b 07 	lds	r30, 0x079B
    158c:	dc 01       	movw	r26, r24
    158e:	fc 91       	ld	r31, X
    1590:	fe 17       	cp	r31, r30
    1592:	39 f0       	breq	.+14     	; 0x15a2 <xTaskCheckForTimeOut+0x36>
    1594:	11 96       	adiw	r26, 0x01	; 1
    1596:	ed 91       	ld	r30, X+
    1598:	fc 91       	ld	r31, X
    159a:	12 97       	sbiw	r26, 0x02	; 2
    159c:	4e 17       	cp	r20, r30
    159e:	5f 07       	cpc	r21, r31
    15a0:	c0 f4       	brcc	.+48     	; 0x15d2 <xTaskCheckForTimeOut+0x66>
			was called, but has also overflowed since vTaskSetTimeOut() was called.
			It must have wrapped all the way around and gone past us again. This
			passed since vTaskSetTimeout() was called. */
			xReturn = pdTRUE;
		}
		else if( ( xConstTickCount - pxTimeOut->xTimeOnEntering ) < *pxTicksToWait )
    15a2:	dc 01       	movw	r26, r24
    15a4:	11 96       	adiw	r26, 0x01	; 1
    15a6:	ed 91       	ld	r30, X+
    15a8:	fc 91       	ld	r31, X
    15aa:	12 97       	sbiw	r26, 0x02	; 2
    15ac:	da 01       	movw	r26, r20
    15ae:	ae 1b       	sub	r26, r30
    15b0:	bf 0b       	sbc	r27, r31
    15b2:	a2 17       	cp	r26, r18
    15b4:	b3 07       	cpc	r27, r19
    15b6:	78 f4       	brcc	.+30     	; 0x15d6 <xTaskCheckForTimeOut+0x6a>
    15b8:	db 01       	movw	r26, r22
		{
			/* Not a genuine timeout. Adjust parameters for time remaining. */
			*pxTicksToWait -= ( xConstTickCount -  pxTimeOut->xTimeOnEntering );
    15ba:	e4 1b       	sub	r30, r20
    15bc:	f5 0b       	sbc	r31, r21
    15be:	2e 0f       	add	r18, r30
    15c0:	3f 1f       	adc	r19, r31
    15c2:	2d 93       	st	X+, r18
    15c4:	3c 93       	st	X, r19
			vTaskSetTimeOutState( pxTimeOut );
    15c6:	0e 94 ab 0a 	call	0x1556	; 0x1556 <vTaskSetTimeOutState>
			xReturn = pdFALSE;
    15ca:	80 e0       	ldi	r24, 0x00	; 0
    15cc:	05 c0       	rjmp	.+10     	; 0x15d8 <xTaskCheckForTimeOut+0x6c>
			/* If INCLUDE_vTaskSuspend is set to 1 and the block time specified is
			the maximum block time then the task should block indefinitely, and
			therefore never time out. */
			if( *pxTicksToWait == portMAX_DELAY )
			{
				xReturn = pdFALSE;
    15ce:	80 e0       	ldi	r24, 0x00	; 0
    15d0:	03 c0       	rjmp	.+6      	; 0x15d8 <xTaskCheckForTimeOut+0x6c>
		{
			/* The tick count is greater than the time at which vTaskSetTimeout()
			was called, but has also overflowed since vTaskSetTimeOut() was called.
			It must have wrapped all the way around and gone past us again. This
			passed since vTaskSetTimeout() was called. */
			xReturn = pdTRUE;
    15d2:	81 e0       	ldi	r24, 0x01	; 1
    15d4:	01 c0       	rjmp	.+2      	; 0x15d8 <xTaskCheckForTimeOut+0x6c>
			vTaskSetTimeOutState( pxTimeOut );
			xReturn = pdFALSE;
		}
		else
		{
			xReturn = pdTRUE;
    15d6:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	taskEXIT_CRITICAL();
    15d8:	0f 90       	pop	r0
    15da:	0f be       	out	0x3f, r0	; 63

	return xReturn;
}
    15dc:	08 95       	ret

000015de <vTaskMissedYield>:
/*-----------------------------------------------------------*/

void vTaskMissedYield( void )
{
	xYieldPending = pdTRUE;
    15de:	81 e0       	ldi	r24, 0x01	; 1
    15e0:	80 93 9c 07 	sts	0x079C, r24
    15e4:	08 95       	ret

000015e6 <__vector_1>:
    intFunc[EXTERNAL_INT_7]();
}

#else

ISR(INT0_vect) {
    15e6:	1f 92       	push	r1
    15e8:	0f 92       	push	r0
    15ea:	0f b6       	in	r0, 0x3f	; 63
    15ec:	0f 92       	push	r0
    15ee:	11 24       	eor	r1, r1
    15f0:	2f 93       	push	r18
    15f2:	3f 93       	push	r19
    15f4:	4f 93       	push	r20
    15f6:	5f 93       	push	r21
    15f8:	6f 93       	push	r22
    15fa:	7f 93       	push	r23
    15fc:	8f 93       	push	r24
    15fe:	9f 93       	push	r25
    1600:	af 93       	push	r26
    1602:	bf 93       	push	r27
    1604:	ef 93       	push	r30
    1606:	ff 93       	push	r31
  if(intFunc[EXTERNAL_INT_0])
    1608:	80 91 fb 07 	lds	r24, 0x07FB
    160c:	90 91 fc 07 	lds	r25, 0x07FC
    1610:	89 2b       	or	r24, r25
    1612:	29 f0       	breq	.+10     	; 0x161e <__vector_1+0x38>
    intFunc[EXTERNAL_INT_0]();
    1614:	e0 91 fb 07 	lds	r30, 0x07FB
    1618:	f0 91 fc 07 	lds	r31, 0x07FC
    161c:	09 95       	icall
}
    161e:	ff 91       	pop	r31
    1620:	ef 91       	pop	r30
    1622:	bf 91       	pop	r27
    1624:	af 91       	pop	r26
    1626:	9f 91       	pop	r25
    1628:	8f 91       	pop	r24
    162a:	7f 91       	pop	r23
    162c:	6f 91       	pop	r22
    162e:	5f 91       	pop	r21
    1630:	4f 91       	pop	r20
    1632:	3f 91       	pop	r19
    1634:	2f 91       	pop	r18
    1636:	0f 90       	pop	r0
    1638:	0f be       	out	0x3f, r0	; 63
    163a:	0f 90       	pop	r0
    163c:	1f 90       	pop	r1
    163e:	18 95       	reti

00001640 <__vector_2>:

ISR(INT1_vect) {
    1640:	1f 92       	push	r1
    1642:	0f 92       	push	r0
    1644:	0f b6       	in	r0, 0x3f	; 63
    1646:	0f 92       	push	r0
    1648:	11 24       	eor	r1, r1
    164a:	2f 93       	push	r18
    164c:	3f 93       	push	r19
    164e:	4f 93       	push	r20
    1650:	5f 93       	push	r21
    1652:	6f 93       	push	r22
    1654:	7f 93       	push	r23
    1656:	8f 93       	push	r24
    1658:	9f 93       	push	r25
    165a:	af 93       	push	r26
    165c:	bf 93       	push	r27
    165e:	ef 93       	push	r30
    1660:	ff 93       	push	r31
  if(intFunc[EXTERNAL_INT_1])
    1662:	80 91 fd 07 	lds	r24, 0x07FD
    1666:	90 91 fe 07 	lds	r25, 0x07FE
    166a:	89 2b       	or	r24, r25
    166c:	29 f0       	breq	.+10     	; 0x1678 <__vector_2+0x38>
    intFunc[EXTERNAL_INT_1]();
    166e:	e0 91 fd 07 	lds	r30, 0x07FD
    1672:	f0 91 fe 07 	lds	r31, 0x07FE
    1676:	09 95       	icall
}
    1678:	ff 91       	pop	r31
    167a:	ef 91       	pop	r30
    167c:	bf 91       	pop	r27
    167e:	af 91       	pop	r26
    1680:	9f 91       	pop	r25
    1682:	8f 91       	pop	r24
    1684:	7f 91       	pop	r23
    1686:	6f 91       	pop	r22
    1688:	5f 91       	pop	r21
    168a:	4f 91       	pop	r20
    168c:	3f 91       	pop	r19
    168e:	2f 91       	pop	r18
    1690:	0f 90       	pop	r0
    1692:	0f be       	out	0x3f, r0	; 63
    1694:	0f 90       	pop	r0
    1696:	1f 90       	pop	r1
    1698:	18 95       	reti

0000169a <USART_init>:



void USART_init(void){
	
	UBRR0H = (uint8_t)(BAUD_PRESCALLER>>8);
    169a:	10 92 c5 00 	sts	0x00C5, r1
	UBRR0L = (uint8_t)(BAUD_PRESCALLER);
    169e:	87 e6       	ldi	r24, 0x67	; 103
    16a0:	80 93 c4 00 	sts	0x00C4, r24
	UCSR0B = (1<<RXEN0)|(1<<TXEN0)|(1<<UCSZ02);
    16a4:	8c e1       	ldi	r24, 0x1C	; 28
    16a6:	80 93 c1 00 	sts	0x00C1, r24
	UCSR0C = ((1<<UCSZ00)|(1<<UCSZ01));
    16aa:	86 e0       	ldi	r24, 0x06	; 6
    16ac:	80 93 c2 00 	sts	0x00C2, r24
    16b0:	08 95       	ret

000016b2 <USART_send>:
	}
}

void USART_send( unsigned char data){
	
	while(!(UCSR0A & (1<<UDRE0)));
    16b2:	e0 ec       	ldi	r30, 0xC0	; 192
    16b4:	f0 e0       	ldi	r31, 0x00	; 0
    16b6:	90 81       	ld	r25, Z
    16b8:	95 ff       	sbrs	r25, 5
    16ba:	fd cf       	rjmp	.-6      	; 0x16b6 <USART_send+0x4>
	UDR0 = data;
    16bc:	80 93 c6 00 	sts	0x00C6, r24
    16c0:	08 95       	ret

000016c2 <USART_sendstr>:
	UCSR0B = (1<<RXEN0)|(1<<TXEN0)|(1<<UCSZ02);
	UCSR0C = ((1<<UCSZ00)|(1<<UCSZ01));
}


void USART_sendstr( unsigned char* str){
    16c2:	cf 93       	push	r28
    16c4:	df 93       	push	r29
    16c6:	ec 01       	movw	r28, r24
	int i =0;
	
	while (str[i] != 0x00)
    16c8:	88 81       	ld	r24, Y
    16ca:	88 23       	and	r24, r24
    16cc:	31 f0       	breq	.+12     	; 0x16da <USART_sendstr+0x18>
    16ce:	21 96       	adiw	r28, 0x01	; 1
	{
		USART_send(str[i]);
    16d0:	0e 94 59 0b 	call	0x16b2	; 0x16b2 <USART_send>


void USART_sendstr( unsigned char* str){
	int i =0;
	
	while (str[i] != 0x00)
    16d4:	89 91       	ld	r24, Y+
    16d6:	81 11       	cpse	r24, r1
    16d8:	fb cf       	rjmp	.-10     	; 0x16d0 <USART_sendstr+0xe>
	{
		USART_send(str[i]);
		i++;
	}
}
    16da:	df 91       	pop	r29
    16dc:	cf 91       	pop	r28
    16de:	08 95       	ret

000016e0 <memcpy>:
    16e0:	fb 01       	movw	r30, r22
    16e2:	dc 01       	movw	r26, r24
    16e4:	02 c0       	rjmp	.+4      	; 0x16ea <memcpy+0xa>
    16e6:	01 90       	ld	r0, Z+
    16e8:	0d 92       	st	X+, r0
    16ea:	41 50       	subi	r20, 0x01	; 1
    16ec:	50 40       	sbci	r21, 0x00	; 0
    16ee:	d8 f7       	brcc	.-10     	; 0x16e6 <memcpy+0x6>
    16f0:	08 95       	ret

000016f2 <_exit>:
    16f2:	f8 94       	cli

000016f4 <__stop_program>:
    16f4:	ff cf       	rjmp	.-2      	; 0x16f4 <__stop_program>
